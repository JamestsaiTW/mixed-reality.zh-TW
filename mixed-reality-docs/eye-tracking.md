---
title: 眼球追蹤
description: 眼球追蹤
author: sostel
ms.author: sostel
ms.date: 04/05/2019
ms.topic: article
ms.localizationpriority: high
keywords: 眼球追蹤, 混合實境, 輸入, 眼睛目光
ms.openlocfilehash: 7298a34a946f86aaf789cfe44ad971169fc8ece3
ms.sourcegitcommit: f20beea6a539d04e1d1fc98116f7601137eebebe
ms.translationtype: HT
ms.contentlocale: zh-TW
ms.lasthandoff: 06/05/2019
ms.locfileid: "66453698"
---
# <a name="eye-tracking-on-hololens-2"></a><span data-ttu-id="99862-104">HoloLens 2 的眼球追蹤</span><span class="sxs-lookup"><span data-stu-id="99862-104">Eye tracking on HoloLens 2</span></span>
<span data-ttu-id="99862-105">HoloLens 2 將全像攝影體驗的內容和人類理解能力帶入了全新境界；它讓開發人員能夠運用使用者視線方向的相關資訊，令人驚嘆。</span><span class="sxs-lookup"><span data-stu-id="99862-105">HoloLens 2 allows for a whole new level of context and human understanding within the holographic experience by providing developers with the incredible ability of using information about what users are looking at.</span></span> <span data-ttu-id="99862-106">此頁面概述開發人員在不同的使用案例中如何受惠於眼球追蹤，以及在設計以眼睛目光為基礎的使用者介面時所應留意的事項。</span><span class="sxs-lookup"><span data-stu-id="99862-106">This page gives an overview of how developers can benefit from eye tracking for various use cases and what to look out for when designing eye-gaze-based user interfaces.</span></span> 

## <a name="use-cases"></a><span data-ttu-id="99862-107">使用案例</span><span class="sxs-lookup"><span data-stu-id="99862-107">Use cases</span></span>
<span data-ttu-id="99862-108">眼球追蹤可讓應用程式即時追蹤使用者的視線方向。</span><span class="sxs-lookup"><span data-stu-id="99862-108">Eye tracking enables applications to track where the user is looking in real time.</span></span> <span data-ttu-id="99862-109">本節將說明將眼球追蹤運用在混合實境中的一些可能的使用案例，和得以實現的新奇互動方式。</span><span class="sxs-lookup"><span data-stu-id="99862-109">This section describes some of the potential use cases and novel interactions that become possible with eye tracking in mixed reality.</span></span>
<span data-ttu-id="99862-110">在開始之前，我們後續將多次提到[混合實境工具組](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html)，因為它可就眼球追蹤的運用提供有趣且有力的例證，例如快速輕鬆的視線導向目標選取，和根據使用者的注視方向自動捲動文件。</span><span class="sxs-lookup"><span data-stu-id="99862-110">Before getting started, in the following we will mention the [Mixed Reality Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) several times as it provides several interesting and powerful examples for using eye tracking such as quick and effortless eye-supported target selections and automatically scrolling through text based on where the user looks at.</span></span> 

### <a name="user-intent"></a><span data-ttu-id="99862-111">使用者意圖</span><span class="sxs-lookup"><span data-stu-id="99862-111">User intent</span></span>    
<span data-ttu-id="99862-112">使用者注視方向的相關資訊可為**其他輸入**提供有力的輔助內容，例如語音、手勢和控制器。</span><span class="sxs-lookup"><span data-stu-id="99862-112">Information about where a user looks at provides a powerful **context for other inputs**, such as voice, hands and controllers.</span></span>
<span data-ttu-id="99862-113">這可以運用在各種不同的工作上。</span><span class="sxs-lookup"><span data-stu-id="99862-113">This can be used for various tasks.</span></span>
<span data-ttu-id="99862-114">舉例來說，這包括在場景中快速輕鬆地**鎖定目標**；其具體方式是，注視某個全像投影並說出 "select" (另請參閱[頭部目光和行動](gaze-and-commit.md))，或是說出「將這個放到...」，然後將視線移到您要放置全像投影之處，再說出「...那裡」。</span><span class="sxs-lookup"><span data-stu-id="99862-114">For example, this may range from quickly and effortlessly **targeting** across the scene by simply looking at a hologram and saying "select" (also see [Head-gaze and commit](gaze-and-commit.md)) or by saying "put this...", then looking over to where you want to place the hologram and say "...there".</span></span> <span data-ttu-id="99862-115">您可以在[混合實境工具組 - 視線導向目標選取](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_TargetSelection.html)和[混合實境工具組 - 視線導向目標定位](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Positioning.html)中找到相關範例。</span><span class="sxs-lookup"><span data-stu-id="99862-115">Examples for this can be found in [Mixed Reality Toolkit - Eye-supported Target Selection](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_TargetSelection.html) and [Mixed Reality Toolkit - Eye-supported Target Positioning](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Positioning.html).</span></span>

<span data-ttu-id="99862-116">使用者意圖的其他範例也可能包括利用使用者視線方向的相關資訊，來強化與具象的虛擬代理人和互動式全像投影之間的互動。</span><span class="sxs-lookup"><span data-stu-id="99862-116">An additional example for user intent may include using information about what users look at to enhance the engagement with embodied virtual agents and interactive holograms.</span></span> <span data-ttu-id="99862-117">例如，虛擬代理人可根據目前檢視的內容調整可用選項及其行為。</span><span class="sxs-lookup"><span data-stu-id="99862-117">For example, virtual agents may adapt available options and their behavior based on currently viewed content.</span></span> 

### <a name="implicit-actions"></a><span data-ttu-id="99862-118">隱含動作</span><span class="sxs-lookup"><span data-stu-id="99862-118">Implicit actions</span></span>
<span data-ttu-id="99862-119">隱含動作的類別與使用者意圖有密切的關係。</span><span class="sxs-lookup"><span data-stu-id="99862-119">The category of implicit actions closely relates to user intent.</span></span>
<span data-ttu-id="99862-120">其概念是，全像投影或使用者介面元素的回應方式帶有直覺性，您可能甚至完全沒感覺到正在與系統互動，而是覺得系統與使用者是同步的。例如，**眼睛目光導向的自動捲動**就是一個很成功的例證。</span><span class="sxs-lookup"><span data-stu-id="99862-120">The idea is that holograms or user interface elements react in a somewhat instinctual way that may not even feel like you are interacting with the system at all, but rather that the system and the user are in sync. For example, one immensely successful example is **eye-gaze-based auto scroll**.</span></span> <span data-ttu-id="99862-121">其概念也很簡單：使用者在閱讀文字時，通常會持續往下閱讀。</span><span class="sxs-lookup"><span data-stu-id="99862-121">The idea is as simple: The user reads a text and can just keep on reading.</span></span> <span data-ttu-id="99862-122">文字會隨著使用者的讀速逐漸往上移。</span><span class="sxs-lookup"><span data-stu-id="99862-122">The text gradually moves up to keep users in their reading flow.</span></span> <span data-ttu-id="99862-123">重要層面之一，是捲動速度須配合使用者的閱讀速度。</span><span class="sxs-lookup"><span data-stu-id="99862-123">A key aspect is that the scrolling speed adapts to the reading speed of the user.</span></span>
<span data-ttu-id="99862-124">另一個範例是**視線導向縮放和平移**，這可讓使用者完全投入其注視的內容。</span><span class="sxs-lookup"><span data-stu-id="99862-124">Another example is **eye-supported zoom and pan** for which the user can feel like diving exactly toward what he or she is focusing at.</span></span> <span data-ttu-id="99862-125">縮放的觸發和縮放速度的控制，可透過語音或手勢輸入來控制，這是提供操控感的要素之一，同時也可避免使用者受到過多干擾 (這些設計準則將在稍後詳細討論)。</span><span class="sxs-lookup"><span data-stu-id="99862-125">Triggering the zoom and controlling the zoom speed can be controlled via voice or hand input which is important about providing the feeling of control and avoid overwhelming the user (we will talk about these design guidelines in more detail below).</span></span> <span data-ttu-id="99862-126">放大之後，舉例來說，使用者可以順暢地瀏覽其住處附近的街景，只是移動眼睛目光即可。</span><span class="sxs-lookup"><span data-stu-id="99862-126">Once zoomed in, the user can then smoothly follow, for example, the course of a street to explore his or her neighborhood just simply by using their eye gaze.</span></span>
<span data-ttu-id="99862-127">您可以在[混合實境工具組 - 視線導向瀏覽](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Navigation.html)範例中找到這類互動的示範。</span><span class="sxs-lookup"><span data-stu-id="99862-127">Demo examples for these types of interactions can be found in the [Mixed Reality Toolkit - Eye-supported Navigation](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Navigation.html) sample.</span></span>

<span data-ttu-id="99862-128">_隱含動作_的其他使用案例可能包括：</span><span class="sxs-lookup"><span data-stu-id="99862-128">Additional use cases for _implicit actions_ may include:</span></span>
- <span data-ttu-id="99862-129">**智慧型通知：** 蹦現的通知遮住您正在注視的內容，很煩人吧？</span><span class="sxs-lookup"><span data-stu-id="99862-129">**Smart notifications:** Ever get annoyed by notifications popping up right where you were focusing?</span></span> <span data-ttu-id="99862-130">您應考量使用者當下所關注的內容為何，而改善這一點。</span><span class="sxs-lookup"><span data-stu-id="99862-130">Taking into account where a user is currently paying attention to, you can make it better!</span></span> <span data-ttu-id="99862-131">通知的顯示位置應避開使用者目前的視線以避免造成干擾，且應在使用者讀完後自動關閉。</span><span class="sxs-lookup"><span data-stu-id="99862-131">Show notifications offset from where the user is currently looking to limit distractions and automatically dismiss them once finished reading.</span></span> 
- <span data-ttu-id="99862-132">**善解人意的全像投影：** 全像投影會隨著您的檢視敏銳地回應。</span><span class="sxs-lookup"><span data-stu-id="99862-132">**Attentive holograms:** Holograms that subtly react when being looked at.</span></span> <span data-ttu-id="99862-133">舉凡發出微光的 UI 元素、逐漸綻放的花朵，和開始回頭看看您，或在長時間凝視後想要避掉您眼睛目光的虛擬寵物，都屬於此類功能。</span><span class="sxs-lookup"><span data-stu-id="99862-133">This may range from slightly glowing UI elements, a slowly blooming flower to a virtual pet starting to look back at you or trying to avoid your eye gaze after a prolonged stare.</span></span> <span data-ttu-id="99862-134">這可為您的應用程式帶來有趣的連結感和滿足感。</span><span class="sxs-lookup"><span data-stu-id="99862-134">This may provide an interesting sense of connectivity and satisfaction in your app.</span></span>

### <a name="attention-tracking"></a><span data-ttu-id="99862-135">注意力追蹤</span><span class="sxs-lookup"><span data-stu-id="99862-135">Attention tracking</span></span>   
<span data-ttu-id="99862-136">使用者注視方向的相關資訊是評估設計可用性的有力工具，同時也可找出工作流程中阻礙效率的問題。</span><span class="sxs-lookup"><span data-stu-id="99862-136">Information about where users look at is an immensely powerful tool to assess usability of designs and to identify problems in efficient work streams.</span></span> <span data-ttu-id="99862-137">時至今日，眼球追蹤的視覺化和分析已成為各類應用領域中常見的實作。</span><span class="sxs-lookup"><span data-stu-id="99862-137">By now,  eye tracking visualization and analytics are already a common practice in various application areas.</span></span> <span data-ttu-id="99862-138">在 HoloLens 2 中，我們為這項理解能力提供了新的維度，讓 3D 全像投影可置於實際環境的內容中，並且受到評估。</span><span class="sxs-lookup"><span data-stu-id="99862-138">With HoloLens 2, we provide a new dimension to this understanding as 3D holograms can be placed in real-world contexts and assessed alongside.</span></span> <span data-ttu-id="99862-139">[混合實境工具組](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html)提供了基本範例，說明如何記錄和載入眼球追蹤資料，以及如何將其視覺化。</span><span class="sxs-lookup"><span data-stu-id="99862-139">The [Mixed Reality Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) provides basic examples for logging and loading eye tracking data and for how to visualize them.</span></span>

<span data-ttu-id="99862-140">同屬此領域的其他應用程式包括：</span><span class="sxs-lookup"><span data-stu-id="99862-140">Other applications in this area may include:</span></span> 
-   <span data-ttu-id="99862-141">**遠端眼睛目光視覺化：** 遠端共同作業者的注視方向視覺化，藉以 (舉例而言) 確認他們是否正確理解並遵循指示。</span><span class="sxs-lookup"><span data-stu-id="99862-141">**Remote eye gaze visualization:** Visualize what remote collaborators are looking at to, for example, ensure whether instructions are correctly understood and followed.</span></span>
-   <span data-ttu-id="99862-142">**使用者行為研究：** 注意力追蹤可用來探索新手和專業使用者以視覺方式分析內容的方式有何不同，或探索他們在執行複雜工作 (例如，分析醫學資料或操作機械) 時的手眼協調性。</span><span class="sxs-lookup"><span data-stu-id="99862-142">**User research studies:** Attention tracking can be used to explore the way novice vs. experts users visually analyze content or their hand-eye-coordination for complex tasks (e.g., for analysis of medical data or while operating machinery).</span></span>
-   <span data-ttu-id="99862-143">**模擬訓練和效能監視：** 實地操作，並更有效地找出工作執行流程中的瓶頸，藉以產生最佳執行流程。</span><span class="sxs-lookup"><span data-stu-id="99862-143">**Training simulations and Performance monitoring:** Practice and optimize the execution of tasks by identifying bottlenecks more effectively in the execution flow.</span></span>
-   <span data-ttu-id="99862-144">**設計評估、廣告和行銷研究：** 眼球追蹤是市場調查中用來評估網站和產品設計的常用工具。</span><span class="sxs-lookup"><span data-stu-id="99862-144">**Design evaluations, advertisement and marketing research:** Eye tracking is a common tool for market research to evaluate website and product designs.</span></span>

### <a name="additional-use-cases"></a><span data-ttu-id="99862-145">其他使用案例</span><span class="sxs-lookup"><span data-stu-id="99862-145">Additional use cases</span></span>
- <span data-ttu-id="99862-146">**遊戲：** 想要擁有超能力嗎？</span><span class="sxs-lookup"><span data-stu-id="99862-146">**Gaming:** Ever wanted to have superpowers?</span></span> <span data-ttu-id="99862-147">機會來了！</span><span class="sxs-lookup"><span data-stu-id="99862-147">Here's your chance!</span></span> <span data-ttu-id="99862-148">全像投影會在您的凝視下漂浮起來。</span><span class="sxs-lookup"><span data-stu-id="99862-148">Levitate holograms by staring at them.</span></span> <span data-ttu-id="99862-149">您的眼睛可以發出雷射光。</span><span class="sxs-lookup"><span data-stu-id="99862-149">Shoot laser beams from your eyes.</span></span> <span data-ttu-id="99862-150">將敵人石化或凍結！</span><span class="sxs-lookup"><span data-stu-id="99862-150">Turn enemies into stone or freeze them!</span></span> <span data-ttu-id="99862-151">您可以用 X 光視線掃描建築物。</span><span class="sxs-lookup"><span data-stu-id="99862-151">Use your x-ray vision to explore buildings.</span></span> <span data-ttu-id="99862-152">您想得到的都行！</span><span class="sxs-lookup"><span data-stu-id="99862-152">Your imagination is the limit!</span></span>  

- <span data-ttu-id="99862-153">**生動的虛擬人偶：** 眼球追蹤可協助您創作更具表達力的 3D 虛擬人偶，只要使用即時的眼球追蹤資料模擬虛擬人偶的眼睛，來指出使用者目前的注視方向即可。</span><span class="sxs-lookup"><span data-stu-id="99862-153">**Expressive avatars:** Eye tracking aids in more expressive 3D avatars by using live eye tracking date to animate the avatar's eyes to indicate what the user is currently looking at.</span></span> <span data-ttu-id="99862-154">此外也可加上眨眼和瞇眼來增添表達力。</span><span class="sxs-lookup"><span data-stu-id="99862-154">It also adds more expressiveness by adding winks and blinks.</span></span> 

- <span data-ttu-id="99862-155">**文字輸入：** 眼球追蹤可作為輕鬆輸入文字的有趣替代方式，尤其是在不方便使用語音或手勢時。</span><span class="sxs-lookup"><span data-stu-id="99862-155">**Text entry:** Eye tracking can be used as an interesting alternative for low-effort text entry especially when speech or hands are inconvenient to use.</span></span> 


## <a name="eye-tracking-api"></a><span data-ttu-id="99862-156">眼球追蹤 API</span><span class="sxs-lookup"><span data-stu-id="99862-156">Eye tracking API</span></span>
<span data-ttu-id="99862-157">在進一步詳細討論眼睛目光互動的具體設計準則之前，我們要先簡單談談 HoloLens 2 眼球追蹤器所提供的功能。</span><span class="sxs-lookup"><span data-stu-id="99862-157">Before going into detail about the specific design guidelines for eye-gaze interaction, we want to briefly point to the capabilities that the HoloLens 2 Eye Tracker is providing.</span></span> <span data-ttu-id="99862-158">[眼球追蹤 API](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.eyespose) 可透過 `Windows.Perception.People.EyesPose` 來存取。</span><span class="sxs-lookup"><span data-stu-id="99862-158">The [Eye Tracking API](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.eyespose) is accessible through: `Windows.Perception.People.EyesPose`.</span></span> <span data-ttu-id="99862-159">它為開發人員提供單一的眼睛目光視線 (視線原點和方向)。</span><span class="sxs-lookup"><span data-stu-id="99862-159">It provides a single eye gaze ray (gaze origin and direction) to developers.</span></span>
<span data-ttu-id="99862-160">眼球追蹤器會以大約 _30 FPS_ 的速率提供資料。</span><span class="sxs-lookup"><span data-stu-id="99862-160">The eye tracker provides data at about _30 FPS_.</span></span>
<span data-ttu-id="99862-161">預測的眼睛目光大約會落在</span><span class="sxs-lookup"><span data-stu-id="99862-161">The predicted eye gaze lies within ca.</span></span> <span data-ttu-id="99862-162">實際觀看目標周圍視角的 1.0 - 1.5 度內。</span><span class="sxs-lookup"><span data-stu-id="99862-162">1.0 - 1.5 degrees in visual angle around the actual looked at target.</span></span> <span data-ttu-id="99862-163">由於預期會有些微偏差，您應為此下限預留緩衝值。</span><span class="sxs-lookup"><span data-stu-id="99862-163">As slight imprecisions are expected, you should plan for some margin around this lower bound value.</span></span> <span data-ttu-id="99862-164">這一點將在稍後詳細討論。</span><span class="sxs-lookup"><span data-stu-id="99862-164">We will discuss this more below.</span></span> <span data-ttu-id="99862-165">為了讓眼球追蹤精準運作，每個使用者都必須接受眼球追蹤使用者校正。</span><span class="sxs-lookup"><span data-stu-id="99862-165">For eye tracking to work accurately, each user is required to go through an eye tracking user calibration.</span></span> 

<span data-ttu-id="99862-166">![距離 2 公尺的最佳目標大小](images/gazetargeting-size-1000px.jpg)</span><span class="sxs-lookup"><span data-stu-id="99862-166">![Optimal target size at 2 meter distance](images/gazetargeting-size-1000px.jpg)</span></span><br>
<span data-ttu-id="99862-167">*距離 2 公尺的最佳目標大小*</span><span class="sxs-lookup"><span data-stu-id="99862-167">*Optimal target size at 2 meter distance*</span></span>


## <a name="eye-gaze-design-guidelines"></a><span data-ttu-id="99862-168">眼睛目光設計指導方針</span><span class="sxs-lookup"><span data-stu-id="99862-168">Eye gaze design guidelines</span></span>
<span data-ttu-id="99862-169">要建置互動，使其利用快速移動的眼球鎖定目標，可能並不容易。</span><span class="sxs-lookup"><span data-stu-id="99862-169">Building an interaction that takes advantage of fast moving eye targeting can be challenging.</span></span> <span data-ttu-id="99862-170">在本節中，我們將摘要說明其主要優點，以及在您設計應用程式時所應考量的課題。</span><span class="sxs-lookup"><span data-stu-id="99862-170">In this section, we summarize the key advantages and challenges to take into account when designing your app.</span></span> 

### <a name="benefits-of-eye-gaze-input"></a><span data-ttu-id="99862-171">眼睛目光輸入的優點</span><span class="sxs-lookup"><span data-stu-id="99862-171">Benefits of eye gaze input</span></span>
- <span data-ttu-id="99862-172">**高速指向。**</span><span class="sxs-lookup"><span data-stu-id="99862-172">**High speed pointing.**</span></span> <span data-ttu-id="99862-173">眼部肌肉是人體中反應速度最快的肌肉。</span><span class="sxs-lookup"><span data-stu-id="99862-173">The eye muscle is the fastest reacting muscle in our body.</span></span> 

- <span data-ttu-id="99862-174">**輕鬆省力。**</span><span class="sxs-lookup"><span data-stu-id="99862-174">**Low effort.**</span></span> <span data-ttu-id="99862-175">幾乎不需要任何人為動作。</span><span class="sxs-lookup"><span data-stu-id="99862-175">Barely any physical movements are necessary.</span></span> 

- <span data-ttu-id="99862-176">**隱含性。**</span><span class="sxs-lookup"><span data-stu-id="99862-176">**Implicitness.**</span></span> <span data-ttu-id="99862-177">使用者常稱之為「讀心術」，使用者眼球移動的相關資訊可讓系統得知使用者想要操作的目標。</span><span class="sxs-lookup"><span data-stu-id="99862-177">Often described by users as "mind reading", information about a user's eye movements lets the system know which target the user plans to engage with.</span></span> 

- <span data-ttu-id="99862-178">**替代輸入管道。**</span><span class="sxs-lookup"><span data-stu-id="99862-178">**Alternative input channel.**</span></span> <span data-ttu-id="99862-179">眼睛目光可作為有效輔助手動和語音輸入的輸入機制，這奠基於使用者長年來累積的手眼協調經驗。</span><span class="sxs-lookup"><span data-stu-id="99862-179">Eye gaze can provide a powerful supporting input for hand and voice input building on years of experience from users based on their hand-eye coordination.</span></span>

- <span data-ttu-id="99862-180">**視覺注意力。**</span><span class="sxs-lookup"><span data-stu-id="99862-180">**Visual attention.**</span></span> <span data-ttu-id="99862-181">另一個重要優點是可以推斷使用者所關注的標的。</span><span class="sxs-lookup"><span data-stu-id="99862-181">Another important benefit is the possibility to infer what a user's is paying attention to.</span></span> <span data-ttu-id="99862-182">這一點可在多種不同的領域中發揮效用，包括更有效地評估不同的設計、輔助智慧型使用者介面，以及強化遠端通訊的社交暗示等。</span><span class="sxs-lookup"><span data-stu-id="99862-182">This can help in various application areas ranging from more effectively evaluating different designs to aiding in smarter User Interfaces and enhanced social cues for remote communication.</span></span>

<span data-ttu-id="99862-183">簡言之，以眼睛目光進行輸入或許能夠提供快速且輕鬆的線索信息 - 尤其是在搭配*語音*和*手動*輸入等其他輸入來確認使用者的意圖時，效果尤佳。</span><span class="sxs-lookup"><span data-stu-id="99862-183">In a nutshell, using eye gaze as an input potentially offers a fast and effortless contextual signal - This is particularly powerful in combination with other inputs such as *voice* and *manual* input to confirm the user's intent.</span></span>


### <a name="challenges-of-eye-gaze-as-an-input"></a><span data-ttu-id="99862-184">以眼睛目光進行輸入的挑戰</span><span class="sxs-lookup"><span data-stu-id="99862-184">Challenges of eye gaze as an input</span></span>
<span data-ttu-id="99862-185">功能愈強，責任就愈大：雖然眼睛目光可為使用者創造出超能力般的神奇體驗，但同時也務必了解在哪些場合和情境下無法適當發揮此效果。</span><span class="sxs-lookup"><span data-stu-id="99862-185">With lots of power, comes lots of responsibility: While eye gaze can be used to create magical user experiences feeling like a superhero, it is also important to know what it is not good at to account for this appropriately.</span></span> <span data-ttu-id="99862-186">以下我們將討論使用眼睛目光輸入時所應考量的*課題*，及其因應之道：</span><span class="sxs-lookup"><span data-stu-id="99862-186">In the following, we discuss some *challenges* to take into account and how to address them when working with eye gaze input:</span></span> 

- <span data-ttu-id="99862-187">**您的眼睛目光「隨時都在注視」** 只要張開眼睛，您的眼睛就會開始關注環境中的事物。</span><span class="sxs-lookup"><span data-stu-id="99862-187">**Your eye gaze is "always on"** The moment you open your eye lids, your eyes start fixating things in your environment.</span></span> <span data-ttu-id="99862-188">對您的每個注視動作做出回應，甚至因為您注視某個東西太久而非預期地發出動作，可能會導致很糟糕的體驗。</span><span class="sxs-lookup"><span data-stu-id="99862-188">Reacting to every look you make and potentially accidentally issuing actions because you looked at something for too long would result in a terrible experience!</span></span>
<span data-ttu-id="99862-189">正因如此，我們建議眼睛目光應與*語音命令*、*手勢*、*按鈕點按*或延伸說明搭配使用，以正確觸發目標的選取。</span><span class="sxs-lookup"><span data-stu-id="99862-189">This is why we recommend combining eye gaze with a *voice command*, *hand gesture*, *button click* or extended dwell to trigger the selection of a target.</span></span>
<span data-ttu-id="99862-190">此解決方案也可營造出適當模式，讓使用者能夠隨意四處觀看，而不致因為無意觸發的動作而飽受困擾。</span><span class="sxs-lookup"><span data-stu-id="99862-190">This solution also allows for a mode in which the user can freely look around without the overwhelming feeling of involuntarily triggering something.</span></span> <span data-ttu-id="99862-191">在設計單純觀看目標的視覺和聽覺反饋時，也應將此問題納入考量。</span><span class="sxs-lookup"><span data-stu-id="99862-191">This issue should also be taken into account when designing visual and auditory feedback when merely looking at a target.</span></span>
<span data-ttu-id="99862-192">不要讓即時蹦現的效果或暫留的音效干擾到使用者。</span><span class="sxs-lookup"><span data-stu-id="99862-192">Do not overwhelm the user with immediate pop-out effects or hover sounds.</span></span> <span data-ttu-id="99862-193">關鍵在於微妙。</span><span class="sxs-lookup"><span data-stu-id="99862-193">Subtlety is key!</span></span> <span data-ttu-id="99862-194">後續我們在談到設計建議時，將進一步討論一些相關的最佳作法。</span><span class="sxs-lookup"><span data-stu-id="99862-194">We will discuss some best practices for this further below when talking about design recommendations.</span></span>

- <span data-ttu-id="99862-195">**觀察與控制** 設想您想要將牆上的某張相片擺放整齊。</span><span class="sxs-lookup"><span data-stu-id="99862-195">**Observation vs. control** Imagine you want to precisely align a photograph at your wall.</span></span> <span data-ttu-id="99862-196">您檢視了相框及其周圍環境，看看是否妥善對齊。</span><span class="sxs-lookup"><span data-stu-id="99862-196">You look at its borders and its surroundings to see if it aligns well.</span></span> <span data-ttu-id="99862-197">現在請想像一下，如果您同時又要以眼睛目光輸入來移動相片，您該怎麼做。</span><span class="sxs-lookup"><span data-stu-id="99862-197">Now imagine how you would do that when at the same time you want to use your eye gaze as an input to move the picture.</span></span> <span data-ttu-id="99862-198">很難對吧？</span><span class="sxs-lookup"><span data-stu-id="99862-198">Difficult, isn't it?</span></span> <span data-ttu-id="99862-199">這說明了眼睛目光同時用於輸入和控制時，所擔負的雙重角色。</span><span class="sxs-lookup"><span data-stu-id="99862-199">This describes the double role of eye gaze when it is required both for input and control.</span></span> 

- <span data-ttu-id="99862-200">**在點按前即移開目光：** 針對快速目標選取，有研究顯示，使用者的眼睛目光在手動點按 (例如空中點選) 完成之前即可能移開。</span><span class="sxs-lookup"><span data-stu-id="99862-200">**Leave before click:** For quick target selections, research has shown that a user's eye gaze may move on before concluding a manual click (e.g., an airtap).</span></span> <span data-ttu-id="99862-201">在處理快速眼睛目光的訊號與較慢的控制輸入 (例如語音、手勢、控制器) 的同步時，必須多加留意。</span><span class="sxs-lookup"><span data-stu-id="99862-201">Hence, special attention must be paid to synchronizing the fast eye gaze signal with slower control input (e.g., voice, hands, controller).</span></span>

- <span data-ttu-id="99862-202">**小型目標：** 您知道只是因為字有點小就無法舒適閱讀的感受嗎？</span><span class="sxs-lookup"><span data-stu-id="99862-202">**Small targets:** Do you know the feeling when you try to read text that is just a bit too small to comfortably read?</span></span> <span data-ttu-id="99862-203">這種眼睛的不適會迫使您試著重新調整眼球焦距，而讓您感到疲倦不堪嗎？</span><span class="sxs-lookup"><span data-stu-id="99862-203">This straining feeling on your eyes that cause you to feel tired and worn out because you try to readjust your eyes to focus better?</span></span>
<span data-ttu-id="99862-204">如果您迫使使用者必須在您的應用程式中藉由眼睛鎖定來選取太小的目標，他們就會有這種感覺。</span><span class="sxs-lookup"><span data-stu-id="99862-204">This is a feeling you may invoke in your users when forcing them to select too small targets in your app using eye targeting.</span></span>
<span data-ttu-id="99862-205">您的設計若要為使用者營造出愉快而舒適的體驗，我們建議目標的視角至少應為 2°，最好是更大。</span><span class="sxs-lookup"><span data-stu-id="99862-205">For your design, to create a pleasant and comfortable experience for your users, we recommend that targets should be at least 2° in visual angle, preferably larger.</span></span>

- <span data-ttu-id="99862-206">**不規則的眼睛目光移動** 我們的眼球會在不同的注視標的間執行快速移動。</span><span class="sxs-lookup"><span data-stu-id="99862-206">**Ragged eye gaze movements** Our eyes perform rapid movements from fixation to fixation.</span></span> <span data-ttu-id="99862-207">如果您記錄眼球移動的掃描路徑，並加以檢視，您會發現它們呈現為不規則的路徑。</span><span class="sxs-lookup"><span data-stu-id="99862-207">If you look at scan paths of recorded eye movements, you can see that they look ragged.</span></span> <span data-ttu-id="99862-208">相較於*頭部目光*或*手部動作*，眼球移動的速度較快，且同時會跳躍。</span><span class="sxs-lookup"><span data-stu-id="99862-208">Your eyes move quickly and in spontaneous jumps in comparison to *head gaze* or *hand motions*.</span></span>  

- <span data-ttu-id="99862-209">**追蹤可靠性：** 眼球追蹤的精確度可能因光線的變化而略為下降，因為您的眼球必須適應新環境。</span><span class="sxs-lookup"><span data-stu-id="99862-209">**Tracking reliability:** Eye tracking accuracy may degrade a little in changing light as your eye adjust to the new conditions.</span></span>
<span data-ttu-id="99862-210">這不一定會影響您的應用程式設計，因為精確度應該還合乎前述限制 2° 以內。</span><span class="sxs-lookup"><span data-stu-id="99862-210">While this should not necessarily affect your app design, as the accuracy should be within the above mentioned limitation of 2°.</span></span> <span data-ttu-id="99862-211">但這可能表示使用者必須再次執行校正。</span><span class="sxs-lookup"><span data-stu-id="99862-211">It may mean that the user has to run another calibration.</span></span> 


### <a name="design-recommendations"></a><span data-ttu-id="99862-212">設計建議</span><span class="sxs-lookup"><span data-stu-id="99862-212">Design recommendations</span></span>
<span data-ttu-id="99862-213">以下我們根據眼睛目光輸入的前述優點和課題，列出具體的設計建議：</span><span class="sxs-lookup"><span data-stu-id="99862-213">In the following, we list specific design recommendations based on the described advantages and challenges for eye gaze input:</span></span>

1. <span data-ttu-id="99862-214">**眼睛目光不等於頭部目光：**</span><span class="sxs-lookup"><span data-stu-id="99862-214">**Eye gaze != Head gaze:**</span></span>
    - <span data-ttu-id="99862-215">**請考量快速但不規則的眼球移動是否適用於您的輸入工作：** 雖然快速而不規則的眼球移動很適合用來快速選取我們視野內的目標，但對於需要平順輸入軌跡的工作 (例如，標繪或圈選註解的工作)，可能就不那麼適用了。</span><span class="sxs-lookup"><span data-stu-id="99862-215">**Consider whether fast yet ragged eye movements fit your input task:** While our fast and ragged eye movements are great to quickly select targets across our Field of View, it is less applicable for tasks that require smooth input trajectories (e.g., for drawing or encircling annotations).</span></span> <span data-ttu-id="99862-216">在此情況下，手部或頭部指向應該較為合用。</span><span class="sxs-lookup"><span data-stu-id="99862-216">In this case, hand or head pointing should be preferred.</span></span>
  
    - <span data-ttu-id="99862-217">**避免對使用者的眼睛目光直接連結任何項目 (例如滑桿或游標)。**</span><span class="sxs-lookup"><span data-stu-id="99862-217">**Avoid attaching something directly to the user’s eye gaze (e.g., a slider or cursor).**</span></span>
<span data-ttu-id="99862-218">若連結游標，可能會因為投射的眼睛目光訊號略有偏移，而導致「游標脫逸」的效應。</span><span class="sxs-lookup"><span data-stu-id="99862-218">In case of a cursor, this may result in the “fleeing cursor” effect due to slight offsets in the projected eye gaze signal.</span></span> <span data-ttu-id="99862-219">若為滑桿，則會因雙重角色而發生衝突，因為您的眼睛需要控制滑桿，同時又要檢查物件是否在正確的位置。</span><span class="sxs-lookup"><span data-stu-id="99862-219">In case of a slider, it conflicts with the double role of controlling the slider with your eyes while also wanting to check whether the object is at the correct location.</span></span> <span data-ttu-id="99862-220">簡單的說，使用者可能很快就會覺得挫折而困擾，尤其是在訊號對於該使用者並不精確時。</span><span class="sxs-lookup"><span data-stu-id="99862-220">In a nutshell, users may quickly feel overwhelmed and distracted, especially if the signal is imprecise for that user.</span></span> 
  
2. <span data-ttu-id="99862-221">**結合眼睛目光與其他輸入：** 眼球追蹤與其他輸入 (例如手勢、語音命令或按鈕點按) 整合時，會有幾個好處：</span><span class="sxs-lookup"><span data-stu-id="99862-221">**Combine eye gaze with other inputs:** The integration of Eye Tracking with other inputs, such as hand gestures, voice commands or button presses, serves several advantages:</span></span>
    - <span data-ttu-id="99862-222">**允許隨意觀看：** 有鑑於眼睛的主要角色就是觀察周遭環境，請務必讓使用者能夠隨意四處張望，而不會觸發任何 (視覺、聽覺...) 反饋或動作。</span><span class="sxs-lookup"><span data-stu-id="99862-222">**Allow for free observation:** Given that the main role of our eyes is to observe our environment, it is important to allow users to look around without triggering any (visual, auditory, ...) feedback or actions.</span></span> 
    <span data-ttu-id="99862-223">結合 ET (眼球追蹤) 與其他輸入控制項，可讓使用者順暢地在 ET 觀察與輸入控制項模式之間轉換。</span><span class="sxs-lookup"><span data-stu-id="99862-223">Combining ET with another input control allows for smoothly transitioning between ET observation and input control modes.</span></span>
  
    - <span data-ttu-id="99862-224">**強大的內容提供者：** 運用使用者注視方向的相關資訊，同時發出語音命令或執行手勢，可輕鬆地在視野內傳達入。</span><span class="sxs-lookup"><span data-stu-id="99862-224">**Powerful context provider:** Using information about where the user is looking at while uttering a voice command or performing a hand gesture allows for effortlessly channeling the input across the field-of-view.</span></span> <span data-ttu-id="99862-225">範例包含：「把它放在那裡」可讓您快速流暢地在場景內選取並放置全像投影，只需依序看著目標和目的地即可。</span><span class="sxs-lookup"><span data-stu-id="99862-225">Examples include: “Put that there” to quickly and fluently select and position a hologram across the scene by simply looking at a target and destination.</span></span> 

    - <span data-ttu-id="99862-226">**多種樣式的輸入間必須同步 (「在點按前即移開目光」的問題)：** 結合快速眼球移動與較複雜的額外輸入 (例如，較長的語音命令或手勢) 時，您的眼睛目光有可能在額外的輸入命令完成之前即移開。</span><span class="sxs-lookup"><span data-stu-id="99862-226">**Need for synchronizing multimodal inputs (“leave before click” issue):** Combining rapid eye movements with more complex additional inputs (e.g., long voice commands or hand gestures) bears the risk of moving on with your eye gaze before finishing the additional input command.</span></span> <span data-ttu-id="99862-227">因此，如果您自行建立輸入控制項 (例如自訂手勢)，請務必記錄此輸入的開端或約略的持續時間，並將其與使用者過去的關注標的產生關聯。</span><span class="sxs-lookup"><span data-stu-id="99862-227">Hence, if you create your own input controls (e.g., custom hand gestures), make sure to log the onset of this input or approximate duration to correlate it with what a user had fixated on in the past.</span></span>
    
3. <span data-ttu-id="99862-228">**眼球追蹤輸入的微妙反饋：** 在使用者注視目標時提供反饋 (以指出系統如預期運作) 是有其效用的，但應以微妙為原則。</span><span class="sxs-lookup"><span data-stu-id="99862-228">**Subtle feedback for eye tracking input:** It is useful to provide feedback if a target is looked at (to indicate that the system is working as intended) but should be kept subtle.</span></span> <span data-ttu-id="99862-229">這包括混慢混入/混出醒目視覺提示，或執行其他細微的目標行為，例如使用慢動作 (例如，略為放大目標)，指出系統已正確偵測到使用者正在注視目標，但不至於無謂地干擾到使用者目前工作流程。</span><span class="sxs-lookup"><span data-stu-id="99862-229">This may include slowly blending in/out visual highlights or perform other subtle target behaviors, such as slow motions (e.g., slightly increasing the target) to indicate that the system correctly detected that the user is looking at a target, however, without unnecessarily interrupting the user’s current workflow.</span></span> 

4. <span data-ttu-id="99862-230">**避免以不自然的眼球移動進行輸入：** 不要迫使使用者執行特定的眼球移動 (目光姿態) 來觸發您應用程式中的動作。</span><span class="sxs-lookup"><span data-stu-id="99862-230">**Avoid enforcing unnatural eye movements as input:** Do not force users to perform specific eye movements (gaze gestures) to trigger actions in your app.</span></span>

5. <span data-ttu-id="99862-231">**處理不精確的問題：** 我們將使用者可察覺的不精確性分為兩類：偏移和抖動。</span><span class="sxs-lookup"><span data-stu-id="99862-231">**Account for imprecisions:** We distinguish two types of imprecisions which are noticeable to users: Offset and Jitter.</span></span> <span data-ttu-id="99862-232">要處理偏移問題，最簡單的方式是提供夠大的互動目標 (大於 2° 的視角 – 參考資料：當您伸出手臂時，您拇指指甲的視角大約就是 2° (1))。</span><span class="sxs-lookup"><span data-stu-id="99862-232">The easiest way to address offsets is to provide sufficiently large targets to interact with (> 2° in visual angle – as reference: your thumbnail is about 2° in visual angle when you stretch out your arm (1)).</span></span> <span data-ttu-id="99862-233">據此我們提供下列指導方針：</span><span class="sxs-lookup"><span data-stu-id="99862-233">This leads to the following guidance:</span></span>
    - <span data-ttu-id="99862-234">不要迫使使用者選取微小的目標：研究顯示，如果目標夠大 (且系統妥善設計)，使用者就會覺得互動體驗既輕鬆又神奇。</span><span class="sxs-lookup"><span data-stu-id="99862-234">Do not force users to select tiny targets: Research has shown that if targets are sufficiently large (and the system is designed well), users describe the interaction as effortless and magical.</span></span> <span data-ttu-id="99862-235">如果目標太小，則使用者會反映體驗令人疲累又洩氣。</span><span class="sxs-lookup"><span data-stu-id="99862-235">If targets become too small, users describe the experience as fatiguing and frustrating.</span></span>
   

## <a name="see-also"></a><span data-ttu-id="99862-236">請參閱</span><span class="sxs-lookup"><span data-stu-id="99862-236">See also</span></span>
* [<span data-ttu-id="99862-237">頭部目光和行動</span><span class="sxs-lookup"><span data-stu-id="99862-237">Head-gaze and commit</span></span>](gaze-and-commit.md)
* [<span data-ttu-id="99862-238">DirectX 中的頭部和眼睛目光</span><span class="sxs-lookup"><span data-stu-id="99862-238">Head and eye gaze in DirectX</span></span>](gaze-in-directx.md)
* [<span data-ttu-id="99862-239">Unity (混合實境工具組) 中的眼睛目光</span><span class="sxs-lookup"><span data-stu-id="99862-239">Eye gaze in Unity (Mixed Reality Toolkit)</span></span>](https://aka.ms/mrtk-eyes)
* [<span data-ttu-id="99862-240">手勢</span><span class="sxs-lookup"><span data-stu-id="99862-240">Hand gestures</span></span>](gestures.md)
* [<span data-ttu-id="99862-241">語音輸入</span><span class="sxs-lookup"><span data-stu-id="99862-241">Voice input</span></span>](voice-design.md)
* [<span data-ttu-id="99862-242">運動控制器</span><span class="sxs-lookup"><span data-stu-id="99862-242">Motion controllers</span></span>](motion-controllers.md)
* [<span data-ttu-id="99862-243">舒適度</span><span class="sxs-lookup"><span data-stu-id="99862-243">Comfort</span></span>](comfort.md)
