---
title: 眼球追蹤
description: HoloLens 2 將全像攝影體驗的內容和人類理解能力帶入了新境界；它讓開發人員能夠運用使用者視線方向的相關資訊。
author: sostel
ms.author: sostel
ms.date: 10/29/2019
ms.topic: article
keywords: 眼睛追蹤，混合現實，輸入，眼睛眼，校正
ms.openlocfilehash: 60de5ceb9f55ca7e2f74856af9bd75567763e382
ms.sourcegitcommit: a5dc182da237f63f0487d40a2e11894027208b6c
ms.translationtype: MT
ms.contentlocale: zh-TW
ms.lasthandoff: 11/02/2019
ms.locfileid: "73441114"
---
# <a name="eye-tracking-on-hololens-2"></a><span data-ttu-id="a2bea-104">HoloLens 2 的眼球追蹤</span><span class="sxs-lookup"><span data-stu-id="a2bea-104">Eye tracking on HoloLens 2</span></span>

![MRTK 中的眼睛追蹤示範](images/mrtk_et_scenemenu.jpg)

<span data-ttu-id="a2bea-106">HoloLens 2 將全像攝影體驗的內容和人類理解能力帶入了新境界；它讓開發人員能夠運用使用者視線方向的相關資訊。</span><span class="sxs-lookup"><span data-stu-id="a2bea-106">HoloLens 2 allows for a new level of context and human understanding within the holographic experience by providing developers with the ability of using information about what users are looking at.</span></span> <span data-ttu-id="a2bea-107">本頁概述開發人員和設計人員如何從各種使用案例和基本開發人員指引的眼睛追蹤中獲益的新功能。</span><span class="sxs-lookup"><span data-stu-id="a2bea-107">This page provides an overview of this new capability to developers and designers on how they can benefit from eye tracking for various use cases and basic developer guidance.</span></span> 


## <a name="calibration"></a><span data-ttu-id="a2bea-108">效果</span><span class="sxs-lookup"><span data-stu-id="a2bea-108">Calibration</span></span> 
<span data-ttu-id="a2bea-109">為了讓眼追蹤能夠準確地工作，每位使用者都必須經歷[眼睛追蹤使用者校正](calibration.md)，使用者必須查看一組全像攝影目標。</span><span class="sxs-lookup"><span data-stu-id="a2bea-109">For eye tracking to work accurately, each user is required to go through an [eye tracking user calibration](calibration.md) for which the user has to look at a set of holographic targets.</span></span> <span data-ttu-id="a2bea-110">這可讓裝置調整系統，讓使用者能夠更舒適且更高品質的觀賞體驗，並確保同時精確地追蹤。</span><span class="sxs-lookup"><span data-stu-id="a2bea-110">This allows the device to adjust the system for a more comfortable and higher quality viewing experience for the user and to ensure accurate eye tracking at the same time.</span></span> <span data-ttu-id="a2bea-111">眼睛追蹤應該適用于大部分的使用者，但在少數情況下，使用者可能無法成功校準。</span><span class="sxs-lookup"><span data-stu-id="a2bea-111">Eye tracking should work for most users, but there are rare cases in which a user might be unable to calibrate successfully.</span></span>
<span data-ttu-id="a2bea-112">若要深入瞭解校正以及如何確保順暢的體驗，請查看我們的[眼睛追蹤使用者校準](calibration.md)頁面。</span><span class="sxs-lookup"><span data-stu-id="a2bea-112">To learn more about the calibration and about how to ensure a smooth experience, please check our [eye tracking user calibration](calibration.md) page.</span></span>


## <a name="device-support"></a><span data-ttu-id="a2bea-113">裝置支援</span><span class="sxs-lookup"><span data-stu-id="a2bea-113">Device support</span></span>
<table>
<colgroup>
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
</colgroup>
<tr>
     <td><span data-ttu-id="a2bea-114"><strong>特徵</strong></span><span class="sxs-lookup"><span data-stu-id="a2bea-114"><strong>Feature</strong></span></span></td>
     <td><span data-ttu-id="a2bea-115"><a href="hololens-hardware-details.md"><strong>HoloLens (第 1 代)</strong></a></span><span class="sxs-lookup"><span data-stu-id="a2bea-115"><a href="hololens-hardware-details.md"><strong>HoloLens (1st gen)</strong></a></span></span></td>
     <td><span data-ttu-id="a2bea-116"><a href="https://docs.microsoft.com/hololens/hololens2-hardware"><strong>HoloLens 2</strong></span><span class="sxs-lookup"><span data-stu-id="a2bea-116"><a href="https://docs.microsoft.com/hololens/hololens2-hardware"><strong>HoloLens 2</strong></span></span></td>
     <td><span data-ttu-id="a2bea-117"><a href="immersive-headset-hardware-details.md"><strong>沉浸式頭戴裝置</strong></a></span><span class="sxs-lookup"><span data-stu-id="a2bea-117"><a href="immersive-headset-hardware-details.md"><strong>Immersive headsets</strong></a></span></span></td>
</tr>
<tr>
     <td><span data-ttu-id="a2bea-118">眼睛</span><span class="sxs-lookup"><span data-stu-id="a2bea-118">Eye-gaze</span></span></td>
     <td>❌</td>
     <td><span data-ttu-id="a2bea-119">✔️</span><span class="sxs-lookup"><span data-stu-id="a2bea-119">✔️</span></span></td>
     <td>❌</td>
</tr>
</table>

## <a name="available-eye-tracking-data"></a><span data-ttu-id="a2bea-120">可用的眼睛追蹤資料</span><span class="sxs-lookup"><span data-stu-id="a2bea-120">Available eye tracking data</span></span>
<span data-ttu-id="a2bea-121">在深入瞭解眼睛輸入的特定使用案例之前，我們想要簡要指出 HoloLens 2[眼追蹤 API](https://docs.microsoft.com/uwp/api/windows.perception.people.eyespose)所提供的功能。</span><span class="sxs-lookup"><span data-stu-id="a2bea-121">Before going into detail about specific use cases for eye-gaze input, we want to briefly point out the capabilities that the HoloLens 2 [Eye Tracking API](https://docs.microsoft.com/uwp/api/windows.perception.people.eyespose) provides.</span></span> <span data-ttu-id="a2bea-122">開發人員可以在大約_30 FPS （30 Hz）_ 的情況中，存取單一眼睛光線（注視原點和方向）。</span><span class="sxs-lookup"><span data-stu-id="a2bea-122">Developers get access to a single eye-gaze ray (gaze origin and direction) at approximately _30 FPS (30 Hz)_.</span></span>
<span data-ttu-id="a2bea-123">如需有關如何存取眼睛追蹤資料的詳細資訊，請參閱我們的開發人員指南，以瞭解如何使用[DirectX 中的眼睛](gaze-in-directx.md)和[Unity 中的眼睛](https://aka.ms/mrtk-eyes)。</span><span class="sxs-lookup"><span data-stu-id="a2bea-123">For more detailed information about how to access eye tracking data, please refer to our developer guides on using [eye-gaze in DirectX](gaze-in-directx.md) and [eye-gaze in Unity](https://aka.ms/mrtk-eyes).</span></span>

<span data-ttu-id="a2bea-124">預測的眼睛大約是在實際目標周圍以視覺角度的1.5 度為單位（請參閱下圖）。</span><span class="sxs-lookup"><span data-stu-id="a2bea-124">The predicted eye-gaze is approximately within 1.5 degrees in visual angle around the actual target (see the illustration below).</span></span> <span data-ttu-id="a2bea-125">由於預期會有些許 imprecisions，因此開發人員應該規劃此下限值的某些邊界（例如，2.0-3.0 度可能會導致更舒適的體驗）。</span><span class="sxs-lookup"><span data-stu-id="a2bea-125">As slight imprecisions are expected, developers should plan for some margin around this lower bound value (e.g., 2.0-3.0 degrees may result in a much more comfortable experience).</span></span> <span data-ttu-id="a2bea-126">我們將在下面詳細說明如何解決選取的小型目標。</span><span class="sxs-lookup"><span data-stu-id="a2bea-126">We will discuss how to address the selection of small targets in more detail below.</span></span> <span data-ttu-id="a2bea-127">為了讓眼球追蹤精準運作，每個使用者都必須接受眼球追蹤使用者校正。</span><span class="sxs-lookup"><span data-stu-id="a2bea-127">For eye tracking to work accurately, each user is required to go through an eye tracking user calibration.</span></span> 

<span data-ttu-id="a2bea-128">![距離 2 公尺的最佳目標大小](images/gazetargeting-size-1000px.jpg)</span><span class="sxs-lookup"><span data-stu-id="a2bea-128">![Optimal target size at 2 meter distance](images/gazetargeting-size-1000px.jpg)</span></span><br>
<span data-ttu-id="a2bea-129">*雙計量距離的最佳目標大小*</span><span class="sxs-lookup"><span data-stu-id="a2bea-129">*Optimal target size at a 2-meter distance*</span></span>

<br>

## <a name="use-cases"></a><span data-ttu-id="a2bea-130">使用案例</span><span class="sxs-lookup"><span data-stu-id="a2bea-130">Use cases</span></span>
<span data-ttu-id="a2bea-131">眼球追蹤可讓應用程式即時追蹤使用者的視線方向。</span><span class="sxs-lookup"><span data-stu-id="a2bea-131">Eye tracking enables applications to track where the user is looking in real time.</span></span> <span data-ttu-id="a2bea-132">下列使用案例說明在 HoloLens 2 上，混合現實中可能會有的一些互動。</span><span class="sxs-lookup"><span data-stu-id="a2bea-132">The following use cases describe some interactions that are possible with eye tracking on HoloLens 2 in mixed reality.</span></span>
<span data-ttu-id="a2bea-133">請注意，這些使用案例尚未包含在全像攝影介面的體驗中（也就是當您啟動 HoloLens 2 時所看到的介面）。</span><span class="sxs-lookup"><span data-stu-id="a2bea-133">Please note that these use cases are not yet part of the Holographic Shell experience (i.e., the interface that you see when you start up your HoloLens 2).</span></span>
<span data-ttu-id="a2bea-134">您可以在[Mixed Reality 工具](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html)組中試用其中一些專案，其中提供幾個有趣且強大的範例來使用眼睛追蹤，例如快速且輕鬆地支援的目標選取，以及自動以文字為基礎的滾動使用者查看的內容。</span><span class="sxs-lookup"><span data-stu-id="a2bea-134">You can try some of them out in the [Mixed Reality Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) which provides several interesting and powerful examples for using eye tracking, such as quick and effortless eye-supported target selections as well as automatically scrolling through text based on what the user looks at.</span></span> 

### <a name="user-intent"></a><span data-ttu-id="a2bea-135">使用者意圖</span><span class="sxs-lookup"><span data-stu-id="a2bea-135">User intent</span></span>    
<span data-ttu-id="a2bea-136">使用者查看位置和內容的相關資訊，可**為其他輸入**（例如語音、手和控制器）提供強大的內容。</span><span class="sxs-lookup"><span data-stu-id="a2bea-136">Information about where and what a user looks at provides a powerful **context for other inputs**, such as voice, hands and controllers.</span></span>
<span data-ttu-id="a2bea-137">這可以運用在各種不同的工作上。</span><span class="sxs-lookup"><span data-stu-id="a2bea-137">This can be used for various tasks.</span></span>
<span data-ttu-id="a2bea-138">例如，只要查看全像投影並說「*選取*」（也請參閱[注視和認可](gaze-and-commit.md)），或說出「 *put this ...* 」，然後查看使用者的位置，就可以在整個場景中快速且輕鬆地**設定其目標**。想要放置全息的影像，並說「 *。其中有*「。</span><span class="sxs-lookup"><span data-stu-id="a2bea-138">For example, this can range from quickly and effortlessly **targeting** across the scene by simply looking at a hologram and saying *"select"* (also see [gaze and commit](gaze-and-commit.md)) or by saying *"put this..."*, then looking over to where the user wants to place the hologram and say *"...there"*.</span></span> <span data-ttu-id="a2bea-139">您可以在[混合實境工具組 - 視線導向目標選取](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_TargetSelection.html)和[混合實境工具組 - 視線導向目標定位](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Positioning.html)中找到相關範例。</span><span class="sxs-lookup"><span data-stu-id="a2bea-139">Examples for this can be found in [Mixed Reality Toolkit - Eye-supported Target Selection](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_TargetSelection.html) and [Mixed Reality Toolkit - Eye-supported Target Positioning](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Positioning.html).</span></span>

<span data-ttu-id="a2bea-140">此外，使用者意圖的範例可能包括使用使用者查看的相關資訊，以強化與虛擬代理程式和互動式全息式的資料的互動。</span><span class="sxs-lookup"><span data-stu-id="a2bea-140">Additionally, an example for user intent might include using information about what users look at to enhance engagement with embodied virtual agents and interactive holograms.</span></span> <span data-ttu-id="a2bea-141">比方說，虛擬代理程式可能會根據目前所看到的內容，調整可用的選項及其行為。</span><span class="sxs-lookup"><span data-stu-id="a2bea-141">For instance, virtual agents might adapt available options and their behavior based on currently viewed content.</span></span> 

### <a name="implicit-actions"></a><span data-ttu-id="a2bea-142">隱含動作</span><span class="sxs-lookup"><span data-stu-id="a2bea-142">Implicit actions</span></span>
<span data-ttu-id="a2bea-143">隱含動作的類別與使用者意圖有密切的關係。</span><span class="sxs-lookup"><span data-stu-id="a2bea-143">The category of implicit actions closely relates to user intent.</span></span>
<span data-ttu-id="a2bea-144">其概念是，全息影像或使用者介面專案會以本能的方式回應，這可能不會覺得使用者與系統互動，而是讓系統和使用者保持同步。其中一個範例是以**眼睛為基礎的自動滾動**，其中使用者可以讀取長文字，當使用者到達文字方塊底部時，會自動開始滾動，讓使用者不需要進入手指就能繼續閱讀。</span><span class="sxs-lookup"><span data-stu-id="a2bea-144">The idea is that holograms or user interface elements react in an instinctual way that may not even feel like the user is interacting with the system at all, but rather that the system and the user are in sync. One example is **eye-gaze-based auto scroll** where the user can read a long text which automatically starts scrolling once the user gets to the bottom of the textbox to keep the user in the flow of reading without lifting a finger.</span></span>  
<span data-ttu-id="a2bea-145">重點是，捲動速度會適應使用者的閱讀速度。</span><span class="sxs-lookup"><span data-stu-id="a2bea-145">A key aspect of this is that the scrolling speed adapts to the reading speed of the user.</span></span>
<span data-ttu-id="a2bea-146">另一個例子是，**眼睛支援的縮放和平移**，讓使用者可以感受到他或她專注于的樣子。</span><span class="sxs-lookup"><span data-stu-id="a2bea-146">Another example is **eye-supported zoom and pan** where the user can feel like diving exactly toward what he or she is focused on.</span></span> <span data-ttu-id="a2bea-147">觸發縮放和控制縮放速度可以透過語音或手寫輸入來控制，這對於提供使用者感覺控制，同時避免被淹沒的情況很重要。</span><span class="sxs-lookup"><span data-stu-id="a2bea-147">Triggering zoom and controlling zoom speed can be controlled by voice or hand input, which is important for providing the user with the feeling of control while avoiding being overwhelmed.</span></span> <span data-ttu-id="a2bea-148">我們將在下面詳細說明這些設計考慮。</span><span class="sxs-lookup"><span data-stu-id="a2bea-148">We will talk about these design considerations in more detail below.</span></span> <span data-ttu-id="a2bea-149">一旦放大之後，使用者就可以順暢地遵循，例如，使用眼睛眼來探索他的鄰近地區。</span><span class="sxs-lookup"><span data-stu-id="a2bea-149">Once zoomed in, the user can  smoothly follow, for example, the course of a street to explore his or her neighborhood by simply using their eye-gaze.</span></span>
<span data-ttu-id="a2bea-150">您可以在[混合實境工具組 - 視線導向瀏覽](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Navigation.html)範例中找到這類互動的示範。</span><span class="sxs-lookup"><span data-stu-id="a2bea-150">Demo examples for these types of interactions can be found in the [Mixed Reality Toolkit - Eye-supported Navigation](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Navigation.html) sample.</span></span>

<span data-ttu-id="a2bea-151">_隱含動作_的其他使用案例可能包括：</span><span class="sxs-lookup"><span data-stu-id="a2bea-151">Additional use cases for _implicit actions_ may include:</span></span>
- <span data-ttu-id="a2bea-152">**智慧型通知：** 在您要尋找的位置，感到苦惱的通知會立即出現嗎？</span><span class="sxs-lookup"><span data-stu-id="a2bea-152">**Smart notifications:** Ever get annoyed by notifications popping up right where you are looking?</span></span> <span data-ttu-id="a2bea-153">考慮到使用者所需注意的事項，您可以藉由抵銷使用者目前撥雲見日的通知，讓這項體驗更好。</span><span class="sxs-lookup"><span data-stu-id="a2bea-153">Taking into account what a user is paying attention to, you can make this experience better by offsetting notifications from where the user is currently gazing.</span></span> <span data-ttu-id="a2bea-154">這會限制分散注意力，並在使用者完成讀取之後自動予以關閉。</span><span class="sxs-lookup"><span data-stu-id="a2bea-154">This limits distractions and automatically dismisses them once the user is finished reading.</span></span> 
- <span data-ttu-id="a2bea-155">**用心的全息影像：** 在 gazed 時，會稍微反應的全息影像。</span><span class="sxs-lookup"><span data-stu-id="a2bea-155">**Attentive holograms:** Holograms that subtly react when being gazed upon.</span></span> <span data-ttu-id="a2bea-156">其範圍從稍微照亮的 UI 元素，到虛擬狗的緩慢綻放花卉，一開始會回頭查看使用者並 wagging 其結尾。</span><span class="sxs-lookup"><span data-stu-id="a2bea-156">This can range from slightly glowing UI elements, a slowly blooming flower to a virtual dog starting to look back at the user and wagging its tail.</span></span> <span data-ttu-id="a2bea-157">這項互動可能會在您的應用程式中提供有意義的連線和滿意度。</span><span class="sxs-lookup"><span data-stu-id="a2bea-157">This interaction might provide an interesting sense of connectivity and satisfaction in your application.</span></span>

### <a name="attention-tracking"></a><span data-ttu-id="a2bea-158">注意力追蹤</span><span class="sxs-lookup"><span data-stu-id="a2bea-158">Attention tracking</span></span>   
<span data-ttu-id="a2bea-159">使用者查看位置或內容的相關資訊是一種功能強大的工具，可評估設計的可用性，並找出有效率的工作流程中的問題。</span><span class="sxs-lookup"><span data-stu-id="a2bea-159">Information about where or what users look at is an immensely powerful tool to assess usability of designs, and to identify problems in efficient workflows.</span></span> <span data-ttu-id="a2bea-160">目視追蹤視覺效果和分析是各種應用程式領域中的常見做法。</span><span class="sxs-lookup"><span data-stu-id="a2bea-160">Eye tracking visualization and analytics are a common practice in various application areas.</span></span> <span data-ttu-id="a2bea-161">在 HoloLens 2 中，我們會提供新的維度給這項瞭解，因為3D 的全息影像可以放在真實世界的內容中，並據此進行評估。</span><span class="sxs-lookup"><span data-stu-id="a2bea-161">With HoloLens 2, we provide a new dimension to this understanding as 3D holograms can be placed in real-world contexts and assessed accordingly.</span></span> <span data-ttu-id="a2bea-162">[Mixed Reality 工具](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html)組提供記錄和載入眼睛追蹤資料的基本範例，以及如何將其視覺化。</span><span class="sxs-lookup"><span data-stu-id="a2bea-162">The [Mixed Reality Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) provides basic examples for logging and loading eye tracking data and how to visualize them.</span></span>

<span data-ttu-id="a2bea-163">同屬此領域的其他應用程式包括：</span><span class="sxs-lookup"><span data-stu-id="a2bea-163">Other applications in this area may include:</span></span> 
-   <span data-ttu-id="a2bea-164">**遠端眼式視覺效果：** 視覺化遠端共同作業者正在查看哪些內容來增加共用的瞭解。</span><span class="sxs-lookup"><span data-stu-id="a2bea-164">**Remote eye-gaze visualization:** Visualize what remote collaborators are looking at to increase shared understanding.</span></span>
-   <span data-ttu-id="a2bea-165">**使用者研究研究：** 注意追蹤可協助您進一步瞭解我們如何認知並與我們的環境互動，這可能有助於更本能的人類電腦互動。</span><span class="sxs-lookup"><span data-stu-id="a2bea-165">**User research studies:** Attention tracking can help better understanding how we perceive and engage with our environment which may help in better human intent models for more instinctual human-computer-interactions.</span></span> 
-   <span data-ttu-id="a2bea-166">**訓練：** 改善新手的訓練，進一步瞭解專家的視覺效果搜尋模式，以及其對複雜工作的操作方式，例如分析醫療資料或在作業機械。</span><span class="sxs-lookup"><span data-stu-id="a2bea-166">**Training:** Improved training of novices by better understanding experts' visual search patterns and their hand-eye-coordination for complex tasks, such as for analysis of medical data or while operating machinery.</span></span>
-   <span data-ttu-id="a2bea-167">**設計評估和市場研究：** 目視追蹤是在評估網站和產品設計時，用於市場研究的常用工具。</span><span class="sxs-lookup"><span data-stu-id="a2bea-167">**Design evaluations and market research:** Eye tracking is a common tool for market research when evaluating website and product designs.</span></span> <span data-ttu-id="a2bea-168">使用 HoloLens 2，我們可以合併數位產品設計變化與實體環境，將此延伸至3D 空間。</span><span class="sxs-lookup"><span data-stu-id="a2bea-168">With HoloLens 2, we can extend this to 3D spaces by merging digital product design variants with the physical environment.</span></span> 

### <a name="additional-use-cases"></a><span data-ttu-id="a2bea-169">其他使用案例</span><span class="sxs-lookup"><span data-stu-id="a2bea-169">Additional use cases</span></span>
- <span data-ttu-id="a2bea-170">**遊戲：** 您是否想要超能力？</span><span class="sxs-lookup"><span data-stu-id="a2bea-170">**Gaming:** Ever wanted to have superpowers?</span></span> <span data-ttu-id="a2bea-171">機會來了！</span><span class="sxs-lookup"><span data-stu-id="a2bea-171">Here's your chance!</span></span> <span data-ttu-id="a2bea-172">您可以透過開始來 levitate 全像投影。</span><span class="sxs-lookup"><span data-stu-id="a2bea-172">You can levitate holograms by staring at them.</span></span> <span data-ttu-id="a2bea-173">從眼睛中取得鐳射字形狀-試試[RoboRaid 中的 HoloLens 2](https://www.microsoft.com/p/roboraid/9nblggh5fv3j)。</span><span class="sxs-lookup"><span data-stu-id="a2bea-173">Shoot laser beams from your eyes - try it out in [RoboRaid for HoloLens 2](https://www.microsoft.com/p/roboraid/9nblggh5fv3j).</span></span>
<span data-ttu-id="a2bea-174">將敵人變成石頭，或將其凍結。</span><span class="sxs-lookup"><span data-stu-id="a2bea-174">Turn enemies into stone or freeze them.</span></span> <span data-ttu-id="a2bea-175">您可以用 X 光視線掃描建築物。</span><span class="sxs-lookup"><span data-stu-id="a2bea-175">Use your x-ray vision to explore buildings.</span></span> <span data-ttu-id="a2bea-176">您想得到的都行！</span><span class="sxs-lookup"><span data-stu-id="a2bea-176">Your imagination is the limit!</span></span>
<span data-ttu-id="a2bea-177">請注意，使用者不會太多-若要深入瞭解，請參閱我們的[眼睛型輸入設計指導方針](eye-gaze-interaction.md)。</span><span class="sxs-lookup"><span data-stu-id="a2bea-177">Beware of not overwhelming the user though - to find out more, check out our [eye-gaze-based input design guidelines](eye-gaze-interaction.md).</span></span>

- <span data-ttu-id="a2bea-178">**表達虛擬人偶：** 眼睛追蹤有助於更具表達性的3D 虛擬人偶，方法是使用即時監看追蹤資料，以動畫顯示使用者正在查看的內容。</span><span class="sxs-lookup"><span data-stu-id="a2bea-178">**Expressive avatars:** Eye tracking aids in more expressive 3D avatars by using live eye tracking data to animate the avatar's eyes that indicate what the user is looking at.</span></span> 

- <span data-ttu-id="a2bea-179">**文字輸入：** 眼睛追蹤可用來做為低度文字輸入的替代專案，特別是當語音或手不方便使用時。</span><span class="sxs-lookup"><span data-stu-id="a2bea-179">**Text entry:** Eye tracking can be used as an alternative for low-effort text entry, especially when speech or hands are inconvenient to use.</span></span> 

<br>

## <a name="using-eye-gaze-for-interaction"></a><span data-ttu-id="a2bea-180">使用眼睛來互動</span><span class="sxs-lookup"><span data-stu-id="a2bea-180">Using eye-gaze for interaction</span></span>
<span data-ttu-id="a2bea-181">建立利用快速移動眼目標的互動可能是一項挑戰。</span><span class="sxs-lookup"><span data-stu-id="a2bea-181">Building an interaction that takes advantage of fast-moving eye targeting can be challenging.</span></span>
<span data-ttu-id="a2bea-182">一方面，眼睛的移動速度很快，因此您必須小心瞭解如何使用眼睛眼輸入，因為其他使用者可能會發現這種體驗很龐大或混亂。</span><span class="sxs-lookup"><span data-stu-id="a2bea-182">On the one hand, the eyes move so fast that you need to be careful on how to use eye-gaze input, because otherwise user may find the experience overwhelming or distracting.</span></span> <span data-ttu-id="a2bea-183">另一方面，您也可以建立真正的神奇體驗，以激發您的使用者！</span><span class="sxs-lookup"><span data-stu-id="a2bea-183">On the other hand, you can also create truly magical experiences that will excite your users!</span></span> <span data-ttu-id="a2bea-184">為協助您，請查看我們的重要優點、挑戰和設計建議，以瞭解[互動](eye-gaze-interaction.md)。</span><span class="sxs-lookup"><span data-stu-id="a2bea-184">To help you, check out our overview of key advantages, challenges and design recommendations for [eye-gaze for interaction](eye-gaze-interaction.md).</span></span> 

<br>
 
## <a name="dev-guidance-what-if-eye-tracking-is-not-available"></a><span data-ttu-id="a2bea-185">開發人員指導方針：如果無法使用眼睛追蹤，該怎麼辦？</span><span class="sxs-lookup"><span data-stu-id="a2bea-185">Dev guidance: What if eye tracking is not available?</span></span>
<span data-ttu-id="a2bea-186">在某些情況下，您的應用程式可能不會因為各種原因而收到任何眼睛追蹤資料，包括但不限於：</span><span class="sxs-lookup"><span data-stu-id="a2bea-186">There may be situations in which your app will not receive any eye tracking data due to various reasons including but not limited to:</span></span>
* <span data-ttu-id="a2bea-187">使用者已略過眼睛追蹤校準。</span><span class="sxs-lookup"><span data-stu-id="a2bea-187">The user skipped the eye tracking calibration.</span></span>
* <span data-ttu-id="a2bea-188">使用者已校正，但決定不授與您的應用程式使用其眼追蹤資料的許可權。</span><span class="sxs-lookup"><span data-stu-id="a2bea-188">The user calibrated, but decided to not give permission to your app to use their eye tracking data.</span></span>
* <span data-ttu-id="a2bea-189">使用者具有獨特的眼鏡，或系統尚不支援的一些眼睛狀況。</span><span class="sxs-lookup"><span data-stu-id="a2bea-189">The user has unique eyeglasses or some eye condition that the system does not yet support.</span></span>
* <span data-ttu-id="a2bea-190">外部因素會抑制可靠的眼睛追蹤，例如 HoloLens 面板或眼鏡上的塗抹、強烈的直接陽光與遮蔽，因為眼睛前方的頭髮。</span><span class="sxs-lookup"><span data-stu-id="a2bea-190">External factors inhibiting reliable eye tracking such as smudges on the HoloLens visor or eyeglasses, intense direct sunlight and occlusions due to hair in front of the eyes.</span></span>

<span data-ttu-id="a2bea-191">身為應用程式開發人員，這表示您必須考慮如何支援可能無法使用眼追蹤資料的使用者。</span><span class="sxs-lookup"><span data-stu-id="a2bea-191">For you as an app developer, this means that you need to account for how to support users for whom eye tracking data may not be available.</span></span> <span data-ttu-id="a2bea-192">我們會先說明如何偵測眼追蹤是否可用，以及如何解決不同應用程式無法使用的情況。</span><span class="sxs-lookup"><span data-stu-id="a2bea-192">Below we first explain how to detect whether eye tracking is available and how to address when it is not available for different applications.</span></span>

### <a name="1-how-to-detect-that-eye-tracking-is-available"></a><span data-ttu-id="a2bea-193">1. 如何偵測是否有可用的眼睛追蹤</span><span class="sxs-lookup"><span data-stu-id="a2bea-193">1. How to detect that eye tracking is available</span></span>
<span data-ttu-id="a2bea-194">有幾個檢查可判斷是否可以使用眼睛追蹤資料。</span><span class="sxs-lookup"><span data-stu-id="a2bea-194">There are a few checks to determine whether eye tracking data is available.</span></span> <span data-ttu-id="a2bea-195">檢查是否 。</span><span class="sxs-lookup"><span data-stu-id="a2bea-195">Check whether...</span></span>
* <span data-ttu-id="a2bea-196">...系統完全支援眼追蹤。</span><span class="sxs-lookup"><span data-stu-id="a2bea-196">... the system supports eye tracking at all.</span></span> <span data-ttu-id="a2bea-197">呼叫下列*方法*： [EyesPose. IsSupported （）](https://docs.microsoft.com/uwp/api/windows.perception.people.eyespose.issupported#Windows_Perception_People_EyesPose_IsSupported)</span><span class="sxs-lookup"><span data-stu-id="a2bea-197">Call the following *method*: [Windows.Perception.People.EyesPose.IsSupported()](https://docs.microsoft.com/uwp/api/windows.perception.people.eyespose.issupported#Windows_Perception_People_EyesPose_IsSupported)</span></span>

* <span data-ttu-id="a2bea-198">...使用者已校正。</span><span class="sxs-lookup"><span data-stu-id="a2bea-198">... the user is calibrated.</span></span> <span data-ttu-id="a2bea-199">呼叫下列*屬性*： [EyesPose. IsCalibrationValid](https://docs.microsoft.com/uwp/api/windows.perception.people.eyespose.iscalibrationvalid#Windows_Perception_People_EyesPose_IsCalibrationValid)</span><span class="sxs-lookup"><span data-stu-id="a2bea-199">Call the following *property*: [Windows.Perception.People.EyesPose.IsCalibrationValid](https://docs.microsoft.com/uwp/api/windows.perception.people.eyespose.iscalibrationvalid#Windows_Perception_People_EyesPose_IsCalibrationValid)</span></span>

* <span data-ttu-id="a2bea-200">...使用者已提供您的應用程式許可權來使用其眼追蹤資料：取出目前的 _' GazeInputAccessStatus '_ 。</span><span class="sxs-lookup"><span data-stu-id="a2bea-200">... the user has given your app permission to use their eye tracking data: Retrieve the current _'GazeInputAccessStatus'_.</span></span> <span data-ttu-id="a2bea-201">如需如何執行此動作的範例，請前往[要求存取注視輸入](https://docs.microsoft.com/windows/mixed-reality/gaze-in-directX#requesting-access-to-gaze-input)。</span><span class="sxs-lookup"><span data-stu-id="a2bea-201">An example on how to do this is explained at [Requesting access to gaze input](https://docs.microsoft.com/windows/mixed-reality/gaze-in-directX#requesting-access-to-gaze-input).</span></span>

<span data-ttu-id="a2bea-202">此外，您可能會想要藉由在收到的眼睛追蹤資料更新之間加上超時時間來檢查您的眼睛追蹤資料是否過時，如下所述。</span><span class="sxs-lookup"><span data-stu-id="a2bea-202">In addition, you may want to check that your eye tracking data is not stale by adding a timeout between received eye tracking data updates and otherwise fallback to head-gaze as discussed below.</span></span> 

<span data-ttu-id="a2bea-203">如上所述，有幾個原因可能無法使用眼睛追蹤資料。</span><span class="sxs-lookup"><span data-stu-id="a2bea-203">As described above, there are several reasons why eye tracking data may not be available.</span></span> <span data-ttu-id="a2bea-204">雖然有些使用者可能會基本思考模式決定撤銷其眼追蹤資料的存取權，而且可以將較差的使用者體驗取捨到不提供存取其眼追蹤資料的隱私權，在某些情況下，這可能是不慎的。</span><span class="sxs-lookup"><span data-stu-id="a2bea-204">While some users may have consciously decided to revoke access to their eye tracking data and are ok with the trade-off of an inferior user experience to the privacy of not providing access to their eye tracking data, in some cases this may be unintentional.</span></span> <span data-ttu-id="a2bea-205">因此，如果您的應用程式使用眼追蹤，而且這是經驗的重要部分，我們建議您清楚地與使用者溝通。</span><span class="sxs-lookup"><span data-stu-id="a2bea-205">Hence, if your app uses eye tracking, and this is an important part of the experience, we recommend clearly communicating this to the user.</span></span> <span data-ttu-id="a2bea-206">請通知使用者，追蹤對您的應用程式很重要的原因（甚至是列出一些增強的功能），您的應用程式可能會有充分的潛能，協助使用者進一步瞭解所放棄的內容。</span><span class="sxs-lookup"><span data-stu-id="a2bea-206">Kindly informing the user why eye tracking is critical for your application (maybe even listing some enhanced features) to experience the full potential of your application can help the user to better understand what they are giving up.</span></span> <span data-ttu-id="a2bea-207">協助使用者識別眼睛追蹤可能無法運作的原因（根據上述檢查），並提供一些建議以快速疑難排解可能的問題。</span><span class="sxs-lookup"><span data-stu-id="a2bea-207">Help the user to identify why eye tracking may not be working (based on the above checks) and offer some suggestions to quickly troubleshoot potential issues.</span></span> <span data-ttu-id="a2bea-208">例如，如果您可以偵測到系統支援監看追蹤，則使用者會經過校正，甚至也會獲得其許可權，但不會收到任何其他問題，例如一些其他問題，像是塗抹或 pixels occluded 的眼睛。</span><span class="sxs-lookup"><span data-stu-id="a2bea-208">For example, if you can detect that the system supports eye tracking, the user is calibrated and even has given their permission, yet no eye tracking data is received, then this may point to some other issues such as smudges or the eyes being occluded.</span></span> <span data-ttu-id="a2bea-209">請注意，在少數情況下，使用者可能會無法正常執行眼追蹤。</span><span class="sxs-lookup"><span data-stu-id="a2bea-209">Please note though that there are rare cases of users for whom eye tracking may simply not work.</span></span> <span data-ttu-id="a2bea-210">因此，請重視，允許關閉或甚至停用提醒，以在應用程式中啟用眼睛追蹤。</span><span class="sxs-lookup"><span data-stu-id="a2bea-210">Hence, please be respectful of that by allowing to dismiss or even disable reminders for enabling eye tracking in your app.</span></span>

### <a name="2-fallback-for-apps-using-eye-gaze-as-a-primary-input-pointer"></a><span data-ttu-id="a2bea-211">2. 使用眼睛作為主要輸入指標的應用程式的 Fallback</span><span class="sxs-lookup"><span data-stu-id="a2bea-211">2. Fallback for apps using eye-gaze as a primary input pointer</span></span>
<span data-ttu-id="a2bea-212">如果您的應用程式使用眼睛眼做為指標輸入，以快速選取場景中的全像投影，但眼睛追蹤資料無法使用，建議您回到前端，並開始顯示列印頭游標。</span><span class="sxs-lookup"><span data-stu-id="a2bea-212">If your app uses eye-gaze as a pointer input to quickly select holograms across the scene, yet eye tracking data is unavailable, we recommend falling back to head-gaze and start showing the head-gaze cursor.</span></span> <span data-ttu-id="a2bea-213">我們建議使用 timeout （例如500–1500毫秒）來判斷是否要切換。</span><span class="sxs-lookup"><span data-stu-id="a2bea-213">We recommend using a timeout (e.g., 500–1500 ms) to determine whether to switch or not.</span></span> <span data-ttu-id="a2bea-214">這是為了避免每次系統因快速監看或動畫快遞而短暫遺失追蹤時，都要清除游標。</span><span class="sxs-lookup"><span data-stu-id="a2bea-214">This is to prevent popping up a cursor every time the system may briefly lose tracking due to fast eye motions or winks and blinks.</span></span> <span data-ttu-id="a2bea-215">如果您是 Unity 開發人員，則已在混合現實工具組中處理自動回復為頭部。</span><span class="sxs-lookup"><span data-stu-id="a2bea-215">If you are a Unity developer, the automatic fallback to head-gaze is already handled in the Mixed Reality Toolkit.</span></span> <span data-ttu-id="a2bea-216">如果您是 DirectX 開發人員，您必須自行處理此交換器。</span><span class="sxs-lookup"><span data-stu-id="a2bea-216">If you are a DirectX developer, you need to handle this switch yourself.</span></span>

### <a name="3-fallback-for-other-eye-tracking-specific-applications"></a><span data-ttu-id="a2bea-217">3. 針對其他眼睛追蹤特定應用程式的回退</span><span class="sxs-lookup"><span data-stu-id="a2bea-217">3. Fallback for other eye-tracking-specific applications</span></span>
<span data-ttu-id="a2bea-218">您的應用程式可能會以專為眼睛量身打造的獨特方式來使用眼睛，例如，用來製作圖片的外觀，或是以眼睛為基礎的注意熱度圖依賴視覺效果的精確資訊。</span><span class="sxs-lookup"><span data-stu-id="a2bea-218">Your app may use eye-gaze in a unique way that is tailored specifically to the eyes - for example, for animating an avatar’s eyes or for eye-based attention heatmaps relying on precise information about visual attention.</span></span> <span data-ttu-id="a2bea-219">在此情況下，沒有任何明確的回溯。</span><span class="sxs-lookup"><span data-stu-id="a2bea-219">In this case, there is no clear fallback.</span></span> <span data-ttu-id="a2bea-220">如果無法使用眼睛追蹤，可能只需要停用這些功能。</span><span class="sxs-lookup"><span data-stu-id="a2bea-220">If eye tracking is not available, these capabilities may simply need to be disabled.</span></span>
<span data-ttu-id="a2bea-221">同樣地，我們建議您與不知道功能無法運作的使用者清楚溝通。</span><span class="sxs-lookup"><span data-stu-id="a2bea-221">Again, we recommend to clearly communicate this to the user who may be unaware that the capability is not working.</span></span>

<br>

<span data-ttu-id="a2bea-222">這個頁面希望能讓您開始瞭解 HoloLens 2 的眼睛追蹤和眼睛輸入的角色。</span><span class="sxs-lookup"><span data-stu-id="a2bea-222">This page has hopefully provided you with a good overview to get you started understanding the role of eye tracking and eye-gaze input for HoloLens 2.</span></span> <span data-ttu-id="a2bea-223">若要開始進行開發，請查看我們的資訊，[瞭解如何與全息影像互動](eye-gaze-interaction.md)、 [Unity 中的眼睛](https://aka.ms/mrtk-eyes)，以及[DirectX 中的眼睛](gaze-in-directx.md)。</span><span class="sxs-lookup"><span data-stu-id="a2bea-223">To get started developing, check out our information on the role of [eye-gaze for interacting with holograms](eye-gaze-interaction.md), [eye-gaze in Unity](https://aka.ms/mrtk-eyes) and [eye-gaze in DirectX](gaze-in-directx.md).</span></span>


## <a name="see-also"></a><span data-ttu-id="a2bea-224">請參閱</span><span class="sxs-lookup"><span data-stu-id="a2bea-224">See also</span></span>
* [<span data-ttu-id="a2bea-225">校正</span><span class="sxs-lookup"><span data-stu-id="a2bea-225">Calibration</span></span>](calibration.md)
* [<span data-ttu-id="a2bea-226">舒適度</span><span class="sxs-lookup"><span data-stu-id="a2bea-226">Comfort</span></span>](comfort.md)
* [<span data-ttu-id="a2bea-227">眼睛眼的互動</span><span class="sxs-lookup"><span data-stu-id="a2bea-227">Eye-gaze-based interaction</span></span>](eye-gaze-interaction.md)
* [<span data-ttu-id="a2bea-228">在 DirectX 中的眼睛</span><span class="sxs-lookup"><span data-stu-id="a2bea-228">Eye-gaze in DirectX</span></span>](gaze-in-directx.md)
* [<span data-ttu-id="a2bea-229">Unity 中的眼睛（混合現實工具組）</span><span class="sxs-lookup"><span data-stu-id="a2bea-229">Eye-gaze in Unity (Mixed Reality Toolkit)</span></span>](https://aka.ms/mrtk-eyes)
* [<span data-ttu-id="a2bea-230">注視和認可</span><span class="sxs-lookup"><span data-stu-id="a2bea-230">Gaze and commit</span></span>](gaze-and-commit.md)
* [<span data-ttu-id="a2bea-231">語音輸入</span><span class="sxs-lookup"><span data-stu-id="a2bea-231">Voice input</span></span>](voice-design.md)


