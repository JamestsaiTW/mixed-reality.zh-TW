---
title: 追蹤
description: 追蹤
author: sostel
ms.author: sostel
ms.date: 04/05/2019
ms.topic: article
ms.localizationpriority: high
keywords: 混合實境、 輸入、 眼睛視線的眼睛追蹤
ms.openlocfilehash: d41b9973ede323e842d7187becb1220ba9980a5d
ms.sourcegitcommit: 5b4292ef786447549c0199003e041ca48bb454cd
ms.translationtype: MT
ms.contentlocale: zh-TW
ms.lasthandoff: 05/30/2019
ms.locfileid: "66402354"
---
# <a name="eye-tracking-on-hololens-2"></a><span data-ttu-id="2beec-104">HoloLens 2 上追蹤</span><span class="sxs-lookup"><span data-stu-id="2beec-104">Eye tracking on HoloLens 2</span></span>
<span data-ttu-id="2beec-105">HoloLens 2 允許的內容和 Holographic 內的人了解帶入新境界藉由提供驚人的能力，利用使用者正在查看的相關資訊的開發人員的體驗。</span><span class="sxs-lookup"><span data-stu-id="2beec-105">HoloLens 2 allows for a whole new level of context and human understanding within the Holographic experience by providing developers with the incredible ability of using information about what users are looking at.</span></span> <span data-ttu-id="2beec-106">此頁面可讓開發人員如何受惠眼睛追蹤不同使用案例，以及設計眼睛視線基礎的使用者介面時需要留意的概觀。</span><span class="sxs-lookup"><span data-stu-id="2beec-106">This page gives an overview of how developers can benefit from eye tracking for various use cases and what to look out for when designing eye-gaze-based user interfaces.</span></span> 

## <a name="use-cases"></a><span data-ttu-id="2beec-107">使用案例</span><span class="sxs-lookup"><span data-stu-id="2beec-107">Use cases</span></span>
<span data-ttu-id="2beec-108">追蹤可讓您追蹤使用者注視的即時應用程式。</span><span class="sxs-lookup"><span data-stu-id="2beec-108">Eye tracking enables applications to track where the user is looking in real time.</span></span> <span data-ttu-id="2beec-109">本節說明一些可能的使用案例和 novel 門兒追蹤在混合實境中使用的互動。</span><span class="sxs-lookup"><span data-stu-id="2beec-109">This section describes some of the potential use cases and novel interactions that become possible with eye tracking in mixed reality.</span></span>
<span data-ttu-id="2beec-110">開始之前，在下列中我們會提及[混合實境 Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html)數次，因為它提供數個有趣且功能強大的範例使用眼睛追蹤，例如快速且輕鬆的眼睛支援目標選取項目，並自動捲動文字為基礎的使用者會探討。</span><span class="sxs-lookup"><span data-stu-id="2beec-110">Before getting started, in the following we will mention the [Mixed Reality Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) several times as it provides several interesting and powerful examples for using eye tracking such as quick and effortless eye-supported target selections and automatically scrolling through text based on where the user looks at.</span></span> 

### <a name="user-intent"></a><span data-ttu-id="2beec-111">使用者意圖</span><span class="sxs-lookup"><span data-stu-id="2beec-111">User intent</span></span>    
<span data-ttu-id="2beec-112">使用者會查看的資訊提供一個功能強大**其他輸入的內容**，例如語音、 實際操作及控制站。</span><span class="sxs-lookup"><span data-stu-id="2beec-112">Information about where a user looks at provides a powerful **context for other inputs**, such as voice, hands and controllers.</span></span>
<span data-ttu-id="2beec-113">這可以用於各種工作。</span><span class="sxs-lookup"><span data-stu-id="2beec-113">This can be used for various tasks.</span></span>
<span data-ttu-id="2beec-114">比方說，這可以是介於快速又輕鬆地**目標**跨只要查看全像圖，然後說 「 選取 」 場景 (另請參閱[Head 視線和認可](gaze-and-commit.md))，或者說出"put 這..."，然後尋找您要將全像圖，並輸入 「...there"。</span><span class="sxs-lookup"><span data-stu-id="2beec-114">For example, this may range from quickly and effortlessly **targeting** across the scene by simply looking at a hologram and saying "select" (also see [Head-gaze and commit](gaze-and-commit.md)) or by saying "put this...", then looking over to where you want to place the hologram and say "...there".</span></span> <span data-ttu-id="2beec-115">這個範例可在[混合實境工具組-眼睛支援目標選取項目](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_TargetSelection.html)並[混合實境工具組-眼睛支援目標定位](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Positioning.html)。</span><span class="sxs-lookup"><span data-stu-id="2beec-115">Examples for this can be found in [Mixed Reality Toolkit - Eye-supported Target Selection](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_TargetSelection.html) and [Mixed Reality Toolkit - Eye-supported Target Positioning](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Positioning.html).</span></span>

<span data-ttu-id="2beec-116">使用者意圖的其他範例可能包括以增強與 embodied 虛擬的代理程式和互動式全像投影中使用使用者查看的資訊。</span><span class="sxs-lookup"><span data-stu-id="2beec-116">An additional example for user intent may include using information about what users look at to enhance the engagement with embodied virtual agents and interactive holograms.</span></span> <span data-ttu-id="2beec-117">比方說，虛擬的代理程式可能會調整可用的選項，並根據目前其行為檢視內容。</span><span class="sxs-lookup"><span data-stu-id="2beec-117">For example, virtual agents may adapt available options and their behavior based on currently viewed content.</span></span> 

### <a name="implicit-actions"></a><span data-ttu-id="2beec-118">隱含的動作</span><span class="sxs-lookup"><span data-stu-id="2beec-118">Implicit actions</span></span>
<span data-ttu-id="2beec-119">使用者意圖密切相關的隱含動作類別。</span><span class="sxs-lookup"><span data-stu-id="2beec-119">The category of implicit actions closely relates to user intent.</span></span>
<span data-ttu-id="2beec-120">其概念是全像投影或使用者介面項目回應有點 instinctual 的方式，可能不甚至覺得您系統互動，而系統和使用者都保持同步。比方說，是一個非常成功的例子**眼睛視線基礎的自動捲動**。</span><span class="sxs-lookup"><span data-stu-id="2beec-120">The idea is that holograms or user interface elements react in a somewhat instinctual way that may not even feel like you are interacting with the system at all, but rather that the system and the user are in sync. For example, one immensely successful example is **eye-gaze-based auto scroll**.</span></span> <span data-ttu-id="2beec-121">這個概念很簡單：使用者讀取文字，並可以只要繼續閱讀本文。</span><span class="sxs-lookup"><span data-stu-id="2beec-121">The idea is as simple: The user reads a text and can just keep on reading.</span></span> <span data-ttu-id="2beec-122">文字會逐漸移動，讓使用者在其讀取流程中。</span><span class="sxs-lookup"><span data-stu-id="2beec-122">The text gradually moves up to keep users in their reading flow.</span></span> <span data-ttu-id="2beec-123">重要的層面是捲動的速度會配合使用者的讀取速度。</span><span class="sxs-lookup"><span data-stu-id="2beec-123">A key aspect is that the scrolling speed adapts to the reading speed of the user.</span></span>
<span data-ttu-id="2beec-124">另一個範例是**眼睛支援縮放和取景位置調整**的使用者可以感覺上就像是完全朝什麼他或她會將焦點放在深入說明。</span><span class="sxs-lookup"><span data-stu-id="2beec-124">Another example is **eye-supported zoom and pan** for which the user can feel like diving exactly toward what he or she is focusing at.</span></span> <span data-ttu-id="2beec-125">觸發縮放控制縮放速度可以透過語音控制或手動輸入這一點很重要的相關提供控制項的感覺和避免讓的使用者 （我們將討論這些設計指導方針，詳細說明如下）。</span><span class="sxs-lookup"><span data-stu-id="2beec-125">Triggering the zoom and controlling the zoom speed can be controlled via voice or hand input which is important about providing the feeling of control and avoid overwhelming the user (we will talk about these design guidelines in more detail below).</span></span> <span data-ttu-id="2beec-126">一旦放大，使用者可以順暢地遵循，比方說，只是透過其眼睛視線探索他或她的鄰區街道的課程。</span><span class="sxs-lookup"><span data-stu-id="2beec-126">Once zoomed in, the user can then smoothly follow, for example, the course of a street to explore his or her neighborhood just simply by using their eye gaze.</span></span>
<span data-ttu-id="2beec-127">這種互動的示範範例可在[混合實境工具組-眼睛支援的瀏覽](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Navigation.html)範例。</span><span class="sxs-lookup"><span data-stu-id="2beec-127">Demo examples for these types of interactions can be found in the [Mixed Reality Toolkit - Eye-supported Navigation](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Navigation.html) sample.</span></span>

<span data-ttu-id="2beec-128">其他使用案例_隱含動作_可能包括：</span><span class="sxs-lookup"><span data-stu-id="2beec-128">Additional use cases for _implicit actions_ may include:</span></span>
- <span data-ttu-id="2beec-129">**智慧型通知：** 以往取得困擾蹦現在您已在此對話方塊專注的右邊的通知嗎？</span><span class="sxs-lookup"><span data-stu-id="2beec-129">**Smart notifications:** Ever get annoyed by notifications popping up right where you were focusing?</span></span> <span data-ttu-id="2beec-130">請考慮使用者目前並注意其中，您可以讓它更加完善 ！</span><span class="sxs-lookup"><span data-stu-id="2beec-130">Taking into account where a user is currently paying attention to, you can make it better!</span></span> <span data-ttu-id="2beec-131">顯示時差目前若要限制分散注意力，並自動一次關閉尋找使用者的通知完成讀取。</span><span class="sxs-lookup"><span data-stu-id="2beec-131">Show notifications offset from where the user is currently looking to limit distractions and automatically dismiss them once finished reading.</span></span> 
- <span data-ttu-id="2beec-132">**用心全像投影：** 全像投影稍微回應時正在進行調查。</span><span class="sxs-lookup"><span data-stu-id="2beec-132">**Attentive holograms:** Holograms that subtly react when being looked at.</span></span> <span data-ttu-id="2beec-133">這可以是介於稍微發光的 UI 項目，緩時變 blooming 花卉虛擬寵物開始回頭看看您，或想要避免您的眼睛視線延長眨之後。</span><span class="sxs-lookup"><span data-stu-id="2beec-133">This may range from slightly glowing UI elements, a slowly blooming flower to a virtual pet starting to look back at you or trying to avoid your eye gaze after a prolonged stare.</span></span> <span data-ttu-id="2beec-134">這可能會提供有趣的有意義的連線和應用程式中的滿意度。</span><span class="sxs-lookup"><span data-stu-id="2beec-134">This may provide an interesting sense of connectivity and satisfaction in your app.</span></span>

### <a name="attention-tracking"></a><span data-ttu-id="2beec-135">追蹤的注意事項</span><span class="sxs-lookup"><span data-stu-id="2beec-135">Attention tracking</span></span>   
<span data-ttu-id="2beec-136">使用者會查看的資訊是非常強大的工具，評估可用性的設計，並且識別有效的工作資料流中的問題。</span><span class="sxs-lookup"><span data-stu-id="2beec-136">Information about where users look at is an immensely powerful tool to assess usability of designs and to identify problems in efficient work streams.</span></span> <span data-ttu-id="2beec-137">到目前為止，視覺效果和分析追蹤已在不同的應用程式區域中常見的作法。</span><span class="sxs-lookup"><span data-stu-id="2beec-137">By now,  eye tracking visualization and analytics are already a common practice in various application areas.</span></span> <span data-ttu-id="2beec-138">HoloLens 2 中，我們會提供新的維度，此了解 3D 全像投影可以是放在真實世界的內容，並一起評估。</span><span class="sxs-lookup"><span data-stu-id="2beec-138">With HoloLens 2, we provide a new dimension to this understanding as 3D holograms can be placed in real-world contexts and assessed alongside.</span></span> <span data-ttu-id="2beec-139">[混合實境 Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html)提供基本範例，用於記錄和載入追蹤資料以及如何將其視覺化。</span><span class="sxs-lookup"><span data-stu-id="2beec-139">The [Mixed Reality Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) provides basic examples for logging and loading eye tracking data and for how to visualize them.</span></span>

<span data-ttu-id="2beec-140">此區域中的其他應用程式可能包括：</span><span class="sxs-lookup"><span data-stu-id="2beec-140">Other applications in this area may include:</span></span> 
-   <span data-ttu-id="2beec-141">**遠端的眼睛視線視覺效果：** 以視覺化方式檢視哪些遠端的共同作業者查看，比方說，並確認是否正確了解並遵循指示。</span><span class="sxs-lookup"><span data-stu-id="2beec-141">**Remote eye gaze visualization:** Visualize what remote collaborators are looking at to, for example, ensure whether instructions are correctly understood and followed.</span></span>
-   <span data-ttu-id="2beec-142">**使用者參考資料的相關研究：** 追蹤的注意可用來瀏覽新手或專家使用者以視覺方式分析內容或其手眼睛協調複雜的工作 （例如，針對分析的醫學資料，或同時操作機制） 的方式。</span><span class="sxs-lookup"><span data-stu-id="2beec-142">**User research studies:** Attention tracking can be used to explore the way novice vs. experts users visually analyze content or their hand-eye-coordination for complex tasks (e.g., for analysis of medical data or while operating machinery).</span></span>
-   <span data-ttu-id="2beec-143">**模擬訓練和效能監視：** 練習，並找出更有效地執行流程中的瓶頸，以最佳化的工作執行。</span><span class="sxs-lookup"><span data-stu-id="2beec-143">**Training simulations and Performance monitoring:** Practice and optimize the execution of tasks by identifying bottlenecks more effectively in the execution flow.</span></span>
-   <span data-ttu-id="2beec-144">**設計的評估、 廣告和行銷研究：** 追蹤是評估網站和產品設計的市場調查的常用工具。</span><span class="sxs-lookup"><span data-stu-id="2beec-144">**Design evaluations, advertisement and marketing research:** Eye tracking is a common tool for market research to evaluate website and product designs.</span></span>

### <a name="additional-use-cases"></a><span data-ttu-id="2beec-145">其他使用案例</span><span class="sxs-lookup"><span data-stu-id="2beec-145">Additional use cases</span></span>
- <span data-ttu-id="2beec-146">**遊戲：** 想要有的超強功能嗎？</span><span class="sxs-lookup"><span data-stu-id="2beec-146">**Gaming:** Ever wanted to have superpowers?</span></span> <span data-ttu-id="2beec-147">以下是您將有機會 ！</span><span class="sxs-lookup"><span data-stu-id="2beec-147">Here's your chance!</span></span> <span data-ttu-id="2beec-148">Levitate 全像投影盯著它們。</span><span class="sxs-lookup"><span data-stu-id="2beec-148">Levitate holograms by staring at them.</span></span> <span data-ttu-id="2beec-149">疑難排解從眼睛的雷射字形狀。</span><span class="sxs-lookup"><span data-stu-id="2beec-149">Shoot laser beams from your eyes.</span></span> <span data-ttu-id="2beec-150">變成石的敵人 」 或 「 凍結它們 ！</span><span class="sxs-lookup"><span data-stu-id="2beec-150">Turn enemies into stone or freeze them!</span></span> <span data-ttu-id="2beec-151">使用您超人瀏覽建築物。</span><span class="sxs-lookup"><span data-stu-id="2beec-151">Use your x-ray vision to explore buildings.</span></span> <span data-ttu-id="2beec-152">限制是您的想像 ！</span><span class="sxs-lookup"><span data-stu-id="2beec-152">Your imagination is the limit!</span></span>  

- <span data-ttu-id="2beec-153">**表達能力的虛擬人偶：** 使用即時眼睛追蹤日期，以動畫顯示，表示哪些使用者目前正在查看的顯示圖片的眼睛追蹤協助更具表達力的 3D 虛擬人偶的眼睛。</span><span class="sxs-lookup"><span data-stu-id="2beec-153">**Expressive avatars:** Eye tracking aids in more expressive 3D avatars by using live eye tracking date to animate the avatar's eyes to indicate what the user is currently looking at.</span></span> <span data-ttu-id="2beec-154">它也會加入更多的表達加上動畫快遞和閃爍。</span><span class="sxs-lookup"><span data-stu-id="2beec-154">It also adds more expressiveness by adding winks and blinks.</span></span> 

- <span data-ttu-id="2beec-155">**文字項目：** 追蹤可用來當做有趣的替代低投入時間的文字項目的尤其語音或指針不方便使用。</span><span class="sxs-lookup"><span data-stu-id="2beec-155">**Text entry:** Eye tracking can be used as an interesting alternative for low-effort text entry especially when speech or hands are inconvenient to use.</span></span> 


## <a name="eye-tracking-api"></a><span data-ttu-id="2beec-156">眼睛追蹤 API</span><span class="sxs-lookup"><span data-stu-id="2beec-156">Eye tracking API</span></span>
<span data-ttu-id="2beec-157">之前，先將詳述的特定設計指導方針的眼睛視線互動，我們要簡短地指向 HoloLens 2 眼睛追蹤器提供的功能。</span><span class="sxs-lookup"><span data-stu-id="2beec-157">Before going into detail about the specific design guidelines for eye-gaze interaction, we want to briefly point to the capabilities that the HoloLens 2 Eye Tracker is providing.</span></span> <span data-ttu-id="2beec-158">[眼睛追蹤 API](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.eyespose)可透過存取： `Windows.Perception.People.EyesPose`。</span><span class="sxs-lookup"><span data-stu-id="2beec-158">The [Eye Tracking API](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.eyespose) is accessible through: `Windows.Perception.People.EyesPose`.</span></span> <span data-ttu-id="2beec-159">它為開發人員提供單一的眼睛視線光線 （視線原點和方向）。</span><span class="sxs-lookup"><span data-stu-id="2beec-159">It provides a single eye gaze ray (gaze origin and direction) to developers.</span></span>
<span data-ttu-id="2beec-160">眼睛追蹤器提供相關的資料，而_30FPS_。</span><span class="sxs-lookup"><span data-stu-id="2beec-160">The eye tracker provides data at about _30 FPS_.</span></span>
<span data-ttu-id="2beec-161">預測的眼睛視線蘊含 ca。</span><span class="sxs-lookup"><span data-stu-id="2beec-161">The predicted eye gaze lies within ca.</span></span> <span data-ttu-id="2beec-162">1.0-1.5 度在周圍的實際 visual 的角度探討目標。</span><span class="sxs-lookup"><span data-stu-id="2beec-162">1.0 - 1.5 degrees in visual angle around the actual looked at target.</span></span> <span data-ttu-id="2beec-163">如預期略微不精確，您應該規劃一些此下限值周圍的邊界。</span><span class="sxs-lookup"><span data-stu-id="2beec-163">As slight imprecisions are expected, you should plan for some margin around this lower bound value.</span></span> <span data-ttu-id="2beec-164">我們將討論這更下面。</span><span class="sxs-lookup"><span data-stu-id="2beec-164">We will discuss this more below.</span></span> <span data-ttu-id="2beec-165">針對能夠準確地追蹤的眼睛，每位使用者才能瀏覽密切追蹤使用者校正。</span><span class="sxs-lookup"><span data-stu-id="2beec-165">For eye tracking to work accurately, each user is required to go through an eye tracking user calibration.</span></span> 

<span data-ttu-id="2beec-166">![2 個計量表距離的最佳目標大小](images/gazetargeting-size-1000px.jpg)</span><span class="sxs-lookup"><span data-stu-id="2beec-166">![Optimal target size at 2 meter distance](images/gazetargeting-size-1000px.jpg)</span></span><br>
<span data-ttu-id="2beec-167">*2 個計量表距離的最佳目標大小*</span><span class="sxs-lookup"><span data-stu-id="2beec-167">*Optimal target size at 2 meter distance*</span></span>


## <a name="eye-gaze-design-guidelines"></a><span data-ttu-id="2beec-168">眼睛視線設計指導方針</span><span class="sxs-lookup"><span data-stu-id="2beec-168">Eye gaze design guidelines</span></span>
<span data-ttu-id="2beec-169">建置互動利用快速移動眼睛目標很有挑戰性。</span><span class="sxs-lookup"><span data-stu-id="2beec-169">Building an interaction that takes advantage of fast moving eye targeting can be challenging.</span></span> <span data-ttu-id="2beec-170">在本節中，我們摘要說明的主要優點和挑戰，以設計您的應用程式時納入考量。</span><span class="sxs-lookup"><span data-stu-id="2beec-170">In this section, we summarize the key advantages and challenges to take into account when designing your app.</span></span> 

### <a name="benefits-of-eye-gaze-input"></a><span data-ttu-id="2beec-171">眼睛視線輸入的優點</span><span class="sxs-lookup"><span data-stu-id="2beec-171">Benefits of eye gaze input</span></span>
- <span data-ttu-id="2beec-172">**指向適當的高速。**</span><span class="sxs-lookup"><span data-stu-id="2beec-172">**High speed pointing.**</span></span> <span data-ttu-id="2beec-173">眼睛跑車是最快速 reacting 的構成部分，我們的主體中。</span><span class="sxs-lookup"><span data-stu-id="2beec-173">The eye muscle is the fastest reacting muscle in our body.</span></span> 

- <span data-ttu-id="2beec-174">**低投入量。**</span><span class="sxs-lookup"><span data-stu-id="2beec-174">**Low effort.**</span></span> <span data-ttu-id="2beec-175">幾乎沒有任何實體的移動都是必要項目。</span><span class="sxs-lookup"><span data-stu-id="2beec-175">Barely any physical movements are necessary.</span></span> 

- <span data-ttu-id="2beec-176">**Implicitness。**</span><span class="sxs-lookup"><span data-stu-id="2beec-176">**Implicitness.**</span></span> <span data-ttu-id="2beec-177">通常稱為使用者 「 注意閱讀 」，則使用者的眼睛移動的相關資訊可讓系統知道的目標使用者方案，洽詢。</span><span class="sxs-lookup"><span data-stu-id="2beec-177">Often described by users as "mind reading", information about a user's eye movements lets the system know which target the user plans to engage with.</span></span> 

- <span data-ttu-id="2beec-178">**替代的輸入的通道。**</span><span class="sxs-lookup"><span data-stu-id="2beec-178">**Alternative input channel.**</span></span> <span data-ttu-id="2beec-179">眼睛視線可以提供功能強大的支援輸入的手動和語音輸入建置年經驗的使用者根據其手眼睛協調。</span><span class="sxs-lookup"><span data-stu-id="2beec-179">Eye gaze can provide a powerful supporting input for hand and voice input building on years of experience from users based on their hand-eye coordination.</span></span>

- <span data-ttu-id="2beec-180">**視覺化的注意。**</span><span class="sxs-lookup"><span data-stu-id="2beec-180">**Visual attention.**</span></span> <span data-ttu-id="2beec-181">另一個重要優點是可以推斷哪些使用者注意。</span><span class="sxs-lookup"><span data-stu-id="2beec-181">Another important benefit is the possibility to infer what a user's is paying attention to.</span></span> <span data-ttu-id="2beec-182">這可協助您從多個有效地評估不同的設計，以便協助更聰明的使用者介面中的各種應用程式區域，並增強社交提示進行遠端通訊。</span><span class="sxs-lookup"><span data-stu-id="2beec-182">This can help in various application areas ranging from more effectively evaluating different designs to aiding in smarter User Interfaces and enhanced social cues for remote communication.</span></span>

<span data-ttu-id="2beec-183">簡單的說，使用眼睛視線輸入可能會提供快速且輕鬆的內容訊號-這是特別強大，搭配其他輸入這類*語音*並*手動*輸入確認使用者的意圖。</span><span class="sxs-lookup"><span data-stu-id="2beec-183">In a nutshell, using eye gaze as an input potentially offers a fast and effortless contextual signal - This is particularly powerful in combination with other inputs such as *voice* and *manual* input to confirm the user's intent.</span></span>


### <a name="challenges-of-eye-gaze-as-an-input"></a><span data-ttu-id="2beec-184">挑戰的眼睛視線做為輸入</span><span class="sxs-lookup"><span data-stu-id="2beec-184">Challenges of eye gaze as an input</span></span>
<span data-ttu-id="2beec-185">使用大量電源，愈強責任：雖然您可以使用眼睛視線，以建立覺得像是 「 達神奇的使用者經驗，也很重要知道它不適合在帳戶這適當。</span><span class="sxs-lookup"><span data-stu-id="2beec-185">With lots of power, comes lots of responsibility: While eye gaze can be used to create magical user experiences feeling like a superhero, it is also important to know what it is not good at to account for this appropriately.</span></span> <span data-ttu-id="2beec-186">在下列程式碼，我們會討論一些*挑戰*考慮到帳戶，以及如何使用眼睛視線輸入時加以解決：</span><span class="sxs-lookup"><span data-stu-id="2beec-186">In the following, we discuss some *challenges* to take into account and how to address them when working with eye gaze input:</span></span> 

- <span data-ttu-id="2beec-187">**您的眼睛視線是 「 永遠開啟 」** 開啟您的眼睛 lids，目前您眼睛啟動 fixating 的項目，在您的環境。</span><span class="sxs-lookup"><span data-stu-id="2beec-187">**Your eye gaze is "always on"** The moment you open your eye lids, your eyes start fixating things in your environment.</span></span> <span data-ttu-id="2beec-188">回應至每個您看起來，廠牌和可能不小心發出動作，因為您探討了一些文字太長導致可怕的體驗 ！</span><span class="sxs-lookup"><span data-stu-id="2beec-188">Reacting to every look you make and potentially accidentally issuing actions because you looked at something for too long would result in a terrible experience!</span></span>
<span data-ttu-id="2beec-189">這就是為什麼我們建議您結合使用的眼睛視線*語音命令*，*交給筆勢*，  *按鈕按一下*或擴充到選取的目標觸發程序詳述。</span><span class="sxs-lookup"><span data-stu-id="2beec-189">This is why we recommend combining eye gaze with a *voice command*, *hand gesture*, *button click* or extended dwell to trigger the selection of a target.</span></span>
<span data-ttu-id="2beec-190">此解決方案也可讓模式，在其中使用者可以自由地看一下沒有 involuntarily 觸發的項目非常龐大的感覺。</span><span class="sxs-lookup"><span data-stu-id="2beec-190">This solution also allows for a mode in which the user can freely look around without the overwhelming feeling of involuntarily triggering something.</span></span> <span data-ttu-id="2beec-191">此問題應該也列入考量時設計視覺和聽覺意見反應，只查看目標時。</span><span class="sxs-lookup"><span data-stu-id="2beec-191">This issue should also be taken into account when designing visual and auditory feedback when merely looking at a target.</span></span>
<span data-ttu-id="2beec-192">不會拖垮立即顯效果的使用者或將滑鼠移至 音效。</span><span class="sxs-lookup"><span data-stu-id="2beec-192">Do not overwhelm the user with immediate pop-out effects or hover sounds.</span></span> <span data-ttu-id="2beec-193">一些微妙的差異是機碼 ！</span><span class="sxs-lookup"><span data-stu-id="2beec-193">Subtlety is key!</span></span> <span data-ttu-id="2beec-194">設計建議所說，我們將討論這個進一步以下的一些最佳作法。</span><span class="sxs-lookup"><span data-stu-id="2beec-194">We will discuss some best practices for this further below when talking about design recommendations.</span></span>

- <span data-ttu-id="2beec-195">**觀察與控制**想像一下您想要精確地對齊在您的塗鴉牆一張相片。</span><span class="sxs-lookup"><span data-stu-id="2beec-195">**Observation vs. control** Imagine you want to precisely align a photograph at your wall.</span></span> <span data-ttu-id="2beec-196">您看看其框線和其周圍環境，以查看是否妥善對齊。</span><span class="sxs-lookup"><span data-stu-id="2beec-196">You look at its borders and its surroundings to see if it aligns well.</span></span> <span data-ttu-id="2beec-197">現在想像一下您該怎麼做，當您想要使用您的眼睛視線做為輸入，將圖片移在相同的時間。</span><span class="sxs-lookup"><span data-stu-id="2beec-197">Now imagine how you would do that when at the same time you want to use your eye gaze as an input to move the picture.</span></span> <span data-ttu-id="2beec-198">困難，對吧？</span><span class="sxs-lookup"><span data-stu-id="2beec-198">Difficult, isn't it?</span></span> <span data-ttu-id="2beec-199">需要同時用於輸入和控制項時，這會描述眼睛視線雙重角色。</span><span class="sxs-lookup"><span data-stu-id="2beec-199">This describes the double role of eye gaze when it is required both for input and control.</span></span> 

- <span data-ttu-id="2beec-200">**將保留之前按一下：** 快速的目標選取項目，如研究顯示使用者的眼睛視線可能會繼續在做出結論手動按一下之前 (例如 airtap)。</span><span class="sxs-lookup"><span data-stu-id="2beec-200">**Leave before click:** For quick target selections, research has shown that a user's eye gaze may move on before concluding a manual click (e.g., an airtap).</span></span> <span data-ttu-id="2beec-201">因此，特別注意若干事項，快速的眼睛視線訊號的同步處理的速度較慢的控制項輸入 （例如語音、 實際操作、 控制站）。</span><span class="sxs-lookup"><span data-stu-id="2beec-201">Hence, special attention must be paid to synchronizing the fast eye gaze signal with slower control input (e.g., voice, hands, controller).</span></span>

- <span data-ttu-id="2beec-202">**小型的目標：** 當您嘗試讀取只是有點太小，無法輕鬆地閱讀的文字時，您知道感覺嗎？</span><span class="sxs-lookup"><span data-stu-id="2beec-202">**Small targets:** Do you know the feeling when you try to read text that is just a bit too small to comfortably read?</span></span> <span data-ttu-id="2beec-203">在您讓您感到疲勞和舊出損，因為您嘗試重新調整到更好的焦點眼睛的眼睛此 straining 感覺嗎？</span><span class="sxs-lookup"><span data-stu-id="2beec-203">This straining feeling on your eyes that cause you to feel tired and worn out because you try to readjust your eyes to focus better?</span></span>
<span data-ttu-id="2beec-204">這是的觸，您可以叫用您的使用者時強制使用眼睛目標的應用程式中選取目標太小。</span><span class="sxs-lookup"><span data-stu-id="2beec-204">This is a feeling you may invoke in your users when forcing them to select too small targets in your app using eye targeting.</span></span>
<span data-ttu-id="2beec-205">針對您的設計，愉快且熟悉的體驗，為您的使用者，我們建議目標應該至少 2 個 ° 中視覺化的角度，最好是更大。</span><span class="sxs-lookup"><span data-stu-id="2beec-205">For your design, to create a pleasant and comfortable experience for your users, we recommend that targets should be at least 2° in visual angle, preferably larger.</span></span>

- <span data-ttu-id="2beec-206">**不完全的眼睛視線移動**我們的眼睛執行快速移動 fixation fixation。</span><span class="sxs-lookup"><span data-stu-id="2beec-206">**Ragged eye gaze movements** Our eyes perform rapid movements from fixation to fixation.</span></span> <span data-ttu-id="2beec-207">如果您查看掃描路徑的已錄製的眼睛移動時，您可以看到它們看起來不完全。</span><span class="sxs-lookup"><span data-stu-id="2beec-207">If you look at scan paths of recorded eye movements, you can see that they look ragged.</span></span> <span data-ttu-id="2beec-208">快速和自發地跳躍點相較，移動眼睛*前端的視線*或*交給動作*。</span><span class="sxs-lookup"><span data-stu-id="2beec-208">Your eyes move quickly and in spontaneous jumps in comparison to *head gaze* or *hand motions*.</span></span>  

- <span data-ttu-id="2beec-209">**追蹤可靠性：** 追蹤精確度可能會降低稍有變更光線，當您調整至新的條件。</span><span class="sxs-lookup"><span data-stu-id="2beec-209">**Tracking reliability:** Eye tracking accuracy may degrade a little in changing light as your eye adjust to the new conditions.</span></span>
<span data-ttu-id="2beec-210">雖然這不一定會影響您的應用程式設計，精確度為應內 2 ° 上述限制。</span><span class="sxs-lookup"><span data-stu-id="2beec-210">While this should not necessarily affect your app design, as the accuracy should be within the above mentioned limitation of 2°.</span></span> <span data-ttu-id="2beec-211">這可能表示使用者必須執行另一個校正。</span><span class="sxs-lookup"><span data-stu-id="2beec-211">It may mean that the user has to run another calibration.</span></span> 


### <a name="design-recommendations"></a><span data-ttu-id="2beec-212">設計建議</span><span class="sxs-lookup"><span data-stu-id="2beec-212">Design recommendations</span></span>
<span data-ttu-id="2beec-213">在下列程式碼，我們列出了特定的設計建議根據所述的優點和挑戰的眼睛視線輸入：</span><span class="sxs-lookup"><span data-stu-id="2beec-213">In the following, we list specific design recommendations based on the described advantages and challenges for eye gaze input:</span></span>

1. <span data-ttu-id="2beec-214">**眼睛視線 ！ = Head 視線：**</span><span class="sxs-lookup"><span data-stu-id="2beec-214">**Eye gaze != Head gaze:**</span></span>
    - <span data-ttu-id="2beec-215">**請考慮是否快速但不完全的眼睛移動適合您輸入的工作：** 雖然我們的快速且不完全的眼睛移動非常快速地在我們的檢視中選取目標，但卻需要 smooth 輸入滴下 （例如，用於繪製或 encircling 註解） 的工作較不適用。</span><span class="sxs-lookup"><span data-stu-id="2beec-215">**Consider whether fast yet ragged eye movements fit your input task:** While our fast and ragged eye movements are great to quickly select targets across our Field of View, it is less applicable for tasks that require smooth input trajectories (e.g., for drawing or encircling annotations).</span></span> <span data-ttu-id="2beec-216">在此情況下，手動或指的標頭應該是慣用。</span><span class="sxs-lookup"><span data-stu-id="2beec-216">In this case, hand or head pointing should be preferred.</span></span>
  
    - <span data-ttu-id="2beec-217">**避免發生直接附加至使用者的眼睛視線 （例如，滑桿或游標）。**</span><span class="sxs-lookup"><span data-stu-id="2beec-217">**Avoid attaching something directly to the user’s eye gaze (e.g., a slider or cursor).**</span></span>
<span data-ttu-id="2beec-218">若是資料指標，這可能會導致 「 帶逃跑游標 」 效果，因為有些微的位移，預計的眼睛視線訊號中。</span><span class="sxs-lookup"><span data-stu-id="2beec-218">In case of a cursor, this may result in the “fleeing cursor” effect due to slight offsets in the projected eye gaze signal.</span></span> <span data-ttu-id="2beec-219">如果滑桿，它與衝突雙重角色控制您眼睛滑桿，同時也想要檢查物件是否在正確的位置。</span><span class="sxs-lookup"><span data-stu-id="2beec-219">In case of a slider, it conflicts with the double role of controlling the slider with your eyes while also wanting to check whether the object is at the correct location.</span></span> <span data-ttu-id="2beec-220">簡單的說，使用者可能會很快覺得可以爆滿和困擾，尤其是是否訊號是該使用者不精確。</span><span class="sxs-lookup"><span data-stu-id="2beec-220">In a nutshell, users may quickly feel overwhelmed and distracted, especially if the signal is imprecise for that user.</span></span> 
  
2. <span data-ttu-id="2beec-221">**眼睛視線結合其他輸入：** 與其他輸入，例如手勢、 語音命令或按下按鈕，整合的眼睛追蹤會提供數個優點：</span><span class="sxs-lookup"><span data-stu-id="2beec-221">**Combine eye gaze with other inputs:** The integration of Eye Tracking with other inputs, such as hand gestures, voice commands or button presses, serves several advantages:</span></span>
    - <span data-ttu-id="2beec-222">**允許免費觀察：** 假設我們的眼睛的主要角色是觀察到我們的環境中，務必要允許使用者而不觸發任何看一下 (視覺、 聽覺，...) 的意見反應或動作。</span><span class="sxs-lookup"><span data-stu-id="2beec-222">**Allow for free observation:** Given that the main role of our eyes is to observe our environment, it is important to allow users to look around without triggering any (visual, auditory, ...) feedback or actions.</span></span> 
    <span data-ttu-id="2beec-223">ET 結合另一個輸入控制項可讓您順暢 ET 觀察及輸入的控制項模式之間轉換。</span><span class="sxs-lookup"><span data-stu-id="2beec-223">Combining ET with another input control allows for smoothly transitioning between ET observation and input control modes.</span></span>
  
    - <span data-ttu-id="2beec-224">**功能強大的內容提供者：** 使用的相關資訊，其中使用者查看同時 uttering 語音命令，或執行手動動作是用來輕鬆地跨檢視欄位內輸入。</span><span class="sxs-lookup"><span data-stu-id="2beec-224">**Powerful context provider:** Using information about where the user is looking at while uttering a voice command or performing a hand gesture allows for effortlessly channeling the input across the field-of-view.</span></span> <span data-ttu-id="2beec-225">範例包含：「 將它放那里 「 若要快速流暢選取，然後放置在場景的雷射藉由只查看目標與目的地。</span><span class="sxs-lookup"><span data-stu-id="2beec-225">Examples include: “Put that there” to quickly and fluently select and position a hologram across the scene by simply looking at a target and destination.</span></span> 

    - <span data-ttu-id="2beec-226">**需要同步處理多樣式的輸入 （「 保留之前按一下 」 問題）：** 快速眼睛移動結合更複雜的其他輸入 （例如，長的語音命令或手勢） 具有與您的眼睛視線移再完成額外的輸入的命令的風險。</span><span class="sxs-lookup"><span data-stu-id="2beec-226">**Need for synchronizing multimodal inputs (“leave before click” issue):** Combining rapid eye movements with more complex additional inputs (e.g., long voice commands or hand gestures) bears the risk of moving on with your eye gaze before finishing the additional input command.</span></span> <span data-ttu-id="2beec-227">因此，如果您建立您自己的輸入的控制項 （例如，自訂手勢），請務必記錄此使它與哪些使用者有 fixated 上過去相互關聯的輸入或近似持續時間的開始。</span><span class="sxs-lookup"><span data-stu-id="2beec-227">Hence, if you create your own input controls (e.g., custom hand gestures), make sure to log the onset of this input or approximate duration to correlate it with what a user had fixated on in the past.</span></span>
    
3. <span data-ttu-id="2beec-228">**追蹤輸入微妙的意見反應：** 最好提供意見反應，如果目標探討了 （以表示系統如預期般運作），但應該保留細微。</span><span class="sxs-lookup"><span data-stu-id="2beec-228">**Subtle feedback for eye tracking input:** It is useful to provide feedback if a target is looked at (to indicate that the system is working as intended) but should be kept subtle.</span></span> <span data-ttu-id="2beec-229">這可以包括 緩時變透明混色縮小/放大視覺反白顯示或執行其他難以察覺的目標行為，例如，緩慢動作 （例如，稍微增加目標），表示系統正確偵測到的使用者查看為目標，不過，如果沒有不必要地中斷使用者的目前工作流程。</span><span class="sxs-lookup"><span data-stu-id="2beec-229">This may include slowly blending in/out visual highlights or perform other subtle target behaviors, such as slow motions (e.g., slightly increasing the target) to indicate that the system correctly detected that the user is looking at a target, however, without unnecessarily interrupting the user’s current workflow.</span></span> 

4. <span data-ttu-id="2beec-230">**避免強制非自然的眼睛移動做為輸入：** 不強制使用者在您的應用程式中的觸發程序動作執行特定的眼睛移動 （視線筆勢）。</span><span class="sxs-lookup"><span data-stu-id="2beec-230">**Avoid enforcing unnatural eye movements as input:** Do not force users to perform specific eye movements (gaze gestures) to trigger actions in your app.</span></span>

5. <span data-ttu-id="2beec-231">**不是精確的帳戶：** 我們會區分兩種類型的不精確也就是通知使用者：位移和抖動。</span><span class="sxs-lookup"><span data-stu-id="2beec-231">**Account for imprecisions:** We distinguish two types of imprecisions which are noticeable to users: Offset and Jitter.</span></span> <span data-ttu-id="2beec-232">位址位移的最簡單方式是提供夠大的目標，才能與互動 (> 2 ° 中視覺化的角度 – 做為參考： 您的縮圖是大約 2 ° 中視覺化的角度，當您延伸您的 arm (1))。</span><span class="sxs-lookup"><span data-stu-id="2beec-232">The easiest way to address offsets is to provide sufficiently large targets to interact with (> 2° in visual angle – as reference: your thumbnail is about 2° in visual angle when you stretch out your arm (1)).</span></span> <span data-ttu-id="2beec-233">這會導致下列指導方針：</span><span class="sxs-lookup"><span data-stu-id="2beec-233">This leads to the following guidance:</span></span>
    - <span data-ttu-id="2beec-234">不會強制使用者選取目標太小：研究顯示，是否目標是足夠大 （和系統設計也），使用者會描述為輕鬆就能和神奇的互動。</span><span class="sxs-lookup"><span data-stu-id="2beec-234">Do not force users to select tiny targets: Research has shown that if targets are sufficiently large (and the system is designed well), users describe the interaction as effortless and magical.</span></span> <span data-ttu-id="2beec-235">如果目標變得太小，則使用者會說明經驗 fatiguing 和令人洩氣。</span><span class="sxs-lookup"><span data-stu-id="2beec-235">If targets become too small, users describe the experience as fatiguing and frustrating.</span></span>
    
## <a name="eye-gaze-design-guidelines"></a><span data-ttu-id="2beec-236">眼睛視線設計指導方針</span><span class="sxs-lookup"><span data-stu-id="2beec-236">Eye gaze design guidelines</span></span>

<span data-ttu-id="2beec-237">HoloLens 2 中，我們有絕佳的機會，以進行而不是前端的視線使用眼睛視線的視線 & 更快且更方便的認可。</span><span class="sxs-lookup"><span data-stu-id="2beec-237">With HoloLens 2, we have the great opportunity to make gaze & commit faster and more comfortable by using eye gaze instead of head gaze.</span></span> <span data-ttu-id="2beec-238">不過，眼睛視線至前端的視線，在某些方面非常不同的行為，因此隨附一些獨特的挑戰。</span><span class="sxs-lookup"><span data-stu-id="2beec-238">However, eye gaze behaves very differently to head gaze in certain ways and hence comes with a number of unique challenges.</span></span> <span data-ttu-id="2beec-239">眼睛視線設計指導方針，在我們摘要說明一般的優點和挑戰，以做為輸入的媒體，在全像攝影版的應用程式中使用的眼睛追蹤時納入考量。</span><span class="sxs-lookup"><span data-stu-id="2beec-239">In Eye Gaze Design Guidelines, we summarize general advantages and challenges to take into account when using eye tracking as an input medium in your holographic app.</span></span> <span data-ttu-id="2beec-240">在本節中，我們會著重在特定的設計考量的眼睛視線 & 認可。</span><span class="sxs-lookup"><span data-stu-id="2beec-240">In this section, we focus on the specific design considerations for eye gaze & commit.</span></span> <span data-ttu-id="2beec-241">首先，我們的眼睛非常快速移動，因此很適合用來快速檢視跨目標。</span><span class="sxs-lookup"><span data-stu-id="2beec-241">First, our eyes move incredibly fast and thus are great at quickly targeting across the view.</span></span> <span data-ttu-id="2beec-242">眼睛視線適用於快速視線 & 認可動作，結合快速認可，例如空中點選或按鈕按下時，尤其如此。</span><span class="sxs-lookup"><span data-stu-id="2beec-242">This makes eye gaze ideal for quick gaze & commit actions especially when combined with fast commits such as an air-tap or button press.</span></span>

<span data-ttu-id="2beec-243">不會顯示資料指標：雖然很難互動而不需要資料指標時使用 head 視線，使得又惱人的使用眼睛視線時，游標會變成。</span><span class="sxs-lookup"><span data-stu-id="2beec-243">Do not show a cursor: While it is nearly impossible to interact without a cursor when using head gaze, the cursor becomes quickly distracting and annoying when using eye gaze.</span></span> <span data-ttu-id="2beec-244">而不是依賴資料指標來通知使用者追蹤是否運作，且已正確地偵測到目前查閱的目標，在使用微妙的視覺效果反白顯示 （下面的詳細資料）。</span><span class="sxs-lookup"><span data-stu-id="2beec-244">Instead of relying on a cursor to inform the user whether eye tracking is working and has correctly detected the currently looked at target, use subtle visual highlights (more details below).</span></span>

<span data-ttu-id="2beec-245">尋求微妙的混合暫留時的意見反應：項目看起來很棒的視覺化回饋的前端的視線，可能會導致使用眼睛視線的可怕重擔體驗。</span><span class="sxs-lookup"><span data-stu-id="2beec-245">Strive for subtle blended hover feedback: What seems great visual feedback for head gaze can result in terrible, overwhelming experiences using eye gaze.</span></span> <span data-ttu-id="2beec-246">請記住，您眼睛是優勢快速，快速 darting 跨中的檢視您欄位的點。</span><span class="sxs-lookup"><span data-stu-id="2beec-246">Remember that your eyes are enormously fast, quickly darting across points in your field-of-view.</span></span> <span data-ttu-id="2beec-247">當四處尋找快速突然反白顯示變更 （開/關） 可能會導致 flickery 的意見反應。</span><span class="sxs-lookup"><span data-stu-id="2beec-247">Quick sudden highlight changes (on/off) may result in flickery feedback when looking around.</span></span> <span data-ttu-id="2beec-248">因此，當提供暫留時的意見反應，我們建議使用順暢地混合中反白顯示 （及混合外尋找消失時）。</span><span class="sxs-lookup"><span data-stu-id="2beec-248">So, when providing hover feedback, we recommend using a smoothly blended-in highlight (and blended-out when looking away).</span></span> <span data-ttu-id="2beec-249">這表示，在第一個您會幾乎沒有注意到的意見反應查看目標時。</span><span class="sxs-lookup"><span data-stu-id="2beec-249">This means that at first you would barely notice the feedback when looking at a target.</span></span> <span data-ttu-id="2beec-250">500 到 1000年毫秒的期間，反白顯示的會增加強度。</span><span class="sxs-lookup"><span data-stu-id="2beec-250">Over the course of 500-1000 ms the highlight would increase in intensity.</span></span> <span data-ttu-id="2beec-251">當新手使用者無法保留查看要確保系統正確地判定特定的目標的目標時，專家級使用者無法快速視線 & 認可，不需等到的意見反應在其完整的濃度。</span><span class="sxs-lookup"><span data-stu-id="2beec-251">While novice users could keep looking at the target to ensure that the system has correctly determined the focused target, expert users could quickly gaze & commit without waiting until the feedback is at its full intensity.</span></span> <span data-ttu-id="2beec-252">此外，我們也建議使用 blend 外，當淡出暫留時的意見反應。</span><span class="sxs-lookup"><span data-stu-id="2beec-252">In addition, we also recommend using a blend-out when fading out the hover feedback.</span></span> <span data-ttu-id="2beec-253">研究顯示快速動作與對比變更是非常值得注意，在您周邊視覺 （因此，其中不想要視覺效果欄位的區域）。</span><span class="sxs-lookup"><span data-stu-id="2beec-253">Research has shown that quick motion and contrast changes are very noticeable in your peripheral vision (so, the area of your visual field where you are not looking).</span></span> <span data-ttu-id="2beec-254">淡出不一定要與 blend 中慢。</span><span class="sxs-lookup"><span data-stu-id="2beec-254">The fade-out doesn't have to be as slow as the blend-in.</span></span> <span data-ttu-id="2beec-255">當您反白顯示具有高對比或變更的色彩時，這是只有重要。</span><span class="sxs-lookup"><span data-stu-id="2beec-255">This is only critical when you have high contrast or color changes for your highlight.</span></span> <span data-ttu-id="2beec-256">如果暫留時的意見反應十分細微一開始，您可能不會發現的差異。</span><span class="sxs-lookup"><span data-stu-id="2beec-256">If the hover feedback was pretty subtle to begin with, you probably won't notice a difference.</span></span>

<span data-ttu-id="2beec-257">需要留意的視線和認可訊號的同步處理：輸入訊號的同步處理可能會更少的一項挑戰，簡單的視線 & 認可，因此，別擔心 ！</span><span class="sxs-lookup"><span data-stu-id="2beec-257">Look out for synchronizing gaze and commit signals: The synchronization of input signals may be less of a challenge for simple gaze & commit, so, don't worry!</span></span> <span data-ttu-id="2beec-258">是應該注意如果您想要使用更複雜的認可動作，不過，可能會很長的語音命令或複雜的手勢。</span><span class="sxs-lookup"><span data-stu-id="2beec-258">It is something to look out for in case you want to use more complicated commit actions though that may involve long voice commands or complicated hand gestures.</span></span> <span data-ttu-id="2beec-259">想像一下您查看目標，並發出長語音命令。</span><span class="sxs-lookup"><span data-stu-id="2beec-259">Imagine you look at target and utter a long voice command.</span></span> <span data-ttu-id="2beec-260">您說出所需的時間和系統偵測到您所說的內容所需的時間，請納入考量，您眼睛的視線已通常是長時間移動到場景中一些新的目標。</span><span class="sxs-lookup"><span data-stu-id="2beec-260">Taken into account the time that you needed to speak and the time that the system needed to detect what you said, your eye gaze has usually long moved on to some new target in the scene.</span></span> <span data-ttu-id="2beec-261">因此，讓您知道它們可能會需要之前已辨識的命令，請查看目標或處理方式來判斷命令和哪些使用者有探討了當時之輸入的使用者。</span><span class="sxs-lookup"><span data-stu-id="2beec-261">Hence, either make your users aware that they may need to keep looking at a target until the command has been recognized or handle the input in a way to determine the onset of the command and what the user had been looking at back then.</span></span>

## <a name="see-also"></a><span data-ttu-id="2beec-262">另請參閱</span><span class="sxs-lookup"><span data-stu-id="2beec-262">See also</span></span>
* [<span data-ttu-id="2beec-263">頭部目光和行動</span><span class="sxs-lookup"><span data-stu-id="2beec-263">Head-gaze and commit</span></span>](gaze-and-commit.md)
* [<span data-ttu-id="2beec-264">筆勢</span><span class="sxs-lookup"><span data-stu-id="2beec-264">Gestures</span></span>](gestures.md)
* [<span data-ttu-id="2beec-265">語音命令</span><span class="sxs-lookup"><span data-stu-id="2beec-265">Voice commanding</span></span>](voice-design.md)
* [<span data-ttu-id="2beec-266">運動控制器</span><span class="sxs-lookup"><span data-stu-id="2beec-266">Motion controllers</span></span>](motion-controllers.md)
* [<span data-ttu-id="2beec-267">舒適度</span><span class="sxs-lookup"><span data-stu-id="2beec-267">Comfort</span></span>](comfort.md)
