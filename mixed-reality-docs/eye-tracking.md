---
title: 眼睛
description: HoloLens 2 讓開發人員能夠使用使用者所查看的資訊, 在全像攝影的體驗中提供新的內容層級和人類認知。
author: sostel
ms.author: sostel
ms.date: 04/05/2019
ms.topic: article
keywords: 眼睛追蹤, 混合現實, 輸入, 眼睛
ms.openlocfilehash: 51779b7b210522aa4d19b5a32d7df6ccb2cb3a35
ms.sourcegitcommit: ff330a7e36e5ff7ae0e9a08c0e99eb7f3f81361f
ms.translationtype: MT
ms.contentlocale: zh-TW
ms.lasthandoff: 08/28/2019
ms.locfileid: "70122068"
---
# <a name="eye-gaze-on-hololens-2"></a><span data-ttu-id="55ad4-104">HoloLens 2 上的眼睛</span><span class="sxs-lookup"><span data-stu-id="55ad4-104">Eye-gaze on HoloLens 2</span></span>
<span data-ttu-id="55ad4-105">HoloLens 2 讓開發人員能夠使用使用者所查看的資訊, 在全像攝影的體驗中提供新的內容層級和人類認知。</span><span class="sxs-lookup"><span data-stu-id="55ad4-105">HoloLens 2 allows for a new level of context and human understanding within the holographic experience by providing developers with the ability of using information about what users are looking at.</span></span> <span data-ttu-id="55ad4-106">本頁面會告訴開發人員如何從各種使用案例的眼睛追蹤中獲益, 以及設計眼睛眼的使用者介面時的外觀。</span><span class="sxs-lookup"><span data-stu-id="55ad4-106">This page tells developers how they can benefit from eye tracking for various use cases as well as what to look for when designing eye-gaze-based user interfaces.</span></span> 


## <a name="device-support"></a><span data-ttu-id="55ad4-107">裝置支援</span><span class="sxs-lookup"><span data-stu-id="55ad4-107">Device support</span></span>

<table>
<colgroup>
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
</colgroup>
<tr>
     <td><span data-ttu-id="55ad4-108"><strong>功能</strong></span><span class="sxs-lookup"><span data-stu-id="55ad4-108"><strong>Feature</strong></span></span></td>
     <td><span data-ttu-id="55ad4-109"><a href="hololens-hardware-details.md"><strong>HoloLens (第 1 代)</strong></a></span><span class="sxs-lookup"><span data-stu-id="55ad4-109"><a href="hololens-hardware-details.md"><strong>HoloLens (1st gen)</strong></a></span></span></td>
     <td><span data-ttu-id="55ad4-110"><strong>HoloLens 2</strong></span><span class="sxs-lookup"><span data-stu-id="55ad4-110"><strong>HoloLens 2</strong></span></span></td>
     <td><span data-ttu-id="55ad4-111"><a href="immersive-headset-hardware-details.md"><strong>沉浸式頭戴裝置</strong></a></span><span class="sxs-lookup"><span data-stu-id="55ad4-111"><a href="immersive-headset-hardware-details.md"><strong>Immersive headsets</strong></a></span></span></td>
</tr>
<tr>
     <td><span data-ttu-id="55ad4-112">眼睛</span><span class="sxs-lookup"><span data-stu-id="55ad4-112">Eye-gaze</span></span></td>
     <td><span data-ttu-id="55ad4-113">❌</span><span class="sxs-lookup"><span data-stu-id="55ad4-113">❌</span></span></td>
     <td><span data-ttu-id="55ad4-114">✔️</span><span class="sxs-lookup"><span data-stu-id="55ad4-114">✔️</span></span></td>
     <td><span data-ttu-id="55ad4-115">❌</span><span class="sxs-lookup"><span data-stu-id="55ad4-115">❌</span></span></td>
</tr>
</table>

## <a name="use-cases"></a><span data-ttu-id="55ad4-116">使用案例</span><span class="sxs-lookup"><span data-stu-id="55ad4-116">Use cases</span></span>
<span data-ttu-id="55ad4-117">眼球追蹤可讓應用程式即時追蹤使用者的視線方向。</span><span class="sxs-lookup"><span data-stu-id="55ad4-117">Eye tracking enables applications to track where the user is looking in real time.</span></span> <span data-ttu-id="55ad4-118">下列使用案例說明在混合現實中可能會有眼睛追蹤的部分互動。</span><span class="sxs-lookup"><span data-stu-id="55ad4-118">The following use cases describe some interactions that are possible with eye tracking in mixed reality.</span></span>
<span data-ttu-id="55ad4-119">請記住,[混合現實工具](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html)組非常適合用來提供幾個有趣且強大的範例來使用眼睛追蹤, 例如快速且輕鬆地支援的目標選取, 以及根據下列專案自動滾動文字使用者的外觀。</span><span class="sxs-lookup"><span data-stu-id="55ad4-119">Keep in mind that the [Mixed Reality Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) is useful for providing several interesting and powerful examples for using eye tracking, such as quick and effortless eye-supported target selections as well as automatically scrolling through text based on what the user looks at.</span></span> 

### <a name="user-intent"></a><span data-ttu-id="55ad4-120">使用者意圖</span><span class="sxs-lookup"><span data-stu-id="55ad4-120">User intent</span></span>    
<span data-ttu-id="55ad4-121">使用者查看位置和內容的相關資訊, 可**為其他輸入**(例如語音、手和控制器) 提供強大的內容。</span><span class="sxs-lookup"><span data-stu-id="55ad4-121">Information about where and what a user looks at provides a powerful **context for other inputs**, such as voice, hands and controllers.</span></span>
<span data-ttu-id="55ad4-122">這可以運用在各種不同的工作上。</span><span class="sxs-lookup"><span data-stu-id="55ad4-122">This can be used for various tasks.</span></span>
<span data-ttu-id="55ad4-123">例如, 只要查看全像投影, 並說「選取」 (也請參閱[列印頭和認可](gaze-and-commit.md)), 或說出「 *put this ...* 」, 然後查看使用者的位置, 就可以在整個場景中快速且輕鬆地**設定其目標**。想要放置全息的影像, 並說「 *。其中有*「。</span><span class="sxs-lookup"><span data-stu-id="55ad4-123">For example, this can range from quickly and effortlessly **targeting** across the scene by simply looking at a hologram and saying "select" (also see [Head-gaze and commit](gaze-and-commit.md)) or by saying *"put this..."*, then looking over to where the user wants to place the hologram and say *"...there"*.</span></span> <span data-ttu-id="55ad4-124">您可以在[混合實境工具組 - 視線導向目標選取](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_TargetSelection.html)和[混合實境工具組 - 視線導向目標定位](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Positioning.html)中找到相關範例。</span><span class="sxs-lookup"><span data-stu-id="55ad4-124">Examples for this can be found in [Mixed Reality Toolkit - Eye-supported Target Selection](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_TargetSelection.html) and [Mixed Reality Toolkit - Eye-supported Target Positioning](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Positioning.html).</span></span>

<span data-ttu-id="55ad4-125">此外, 使用者意圖的範例可能包括使用使用者查看的相關資訊, 以強化與虛擬代理程式和互動式全息式的資料的互動。</span><span class="sxs-lookup"><span data-stu-id="55ad4-125">Additionally, an example for user intent might include using information about what users look at to enhance engagement with embodied virtual agents and interactive holograms.</span></span> <span data-ttu-id="55ad4-126">比方說, 虛擬代理程式可能會根據目前所看到的內容, 調整可用的選項及其行為。</span><span class="sxs-lookup"><span data-stu-id="55ad4-126">For instance, virtual agents might adapt available options and their behavior based on currently viewed content.</span></span> 

### <a name="implicit-actions"></a><span data-ttu-id="55ad4-127">隱含動作</span><span class="sxs-lookup"><span data-stu-id="55ad4-127">Implicit actions</span></span>
<span data-ttu-id="55ad4-128">隱含動作的類別與使用者意圖有密切的關係。</span><span class="sxs-lookup"><span data-stu-id="55ad4-128">The category of implicit actions closely relates to user intent.</span></span>
<span data-ttu-id="55ad4-129">其概念是, 「全息影像」或「使用者介面」元素以有點本能的方式回應, 甚至可能不會覺得使用者與系統互動, 而是讓系統和使用者保持同步。其中一個範例是以**眼睛為基礎的自動滾動**, 其中使用者可以讀取長文字, 當使用者到達文字方塊底部時, 會自動開始滾動, 讓使用者不需要進入手指就能繼續閱讀。</span><span class="sxs-lookup"><span data-stu-id="55ad4-129">The idea is that holograms or user interface elements react in a somewhat instinctual way that may not even feel like the user is interacting with the system at all, but rather that the system and the user are in sync. One example is **eye-gaze-based auto scroll** where the user can read a long text which automatically starts scrolling once the user gets to the bottom of the textbox to keep the user in the flow of reading without lifting a finger.</span></span>  
<span data-ttu-id="55ad4-130">重點是, 捲動速度會適應使用者的閱讀速度。</span><span class="sxs-lookup"><span data-stu-id="55ad4-130">A key aspect of this is that the scrolling speed adapts to the reading speed of the user.</span></span>
<span data-ttu-id="55ad4-131">另一個例子是,**眼睛支援的縮放和平移**, 讓使用者可以感受到他或她專注于的樣子。</span><span class="sxs-lookup"><span data-stu-id="55ad4-131">Another example is **eye-supported zoom and pan** where the user can feel like diving exactly toward what he or she is focused on.</span></span> <span data-ttu-id="55ad4-132">觸發縮放和控制縮放速度可以透過語音或手寫輸入來控制, 這對於提供使用者感覺控制, 同時避免被淹沒的情況很重要。</span><span class="sxs-lookup"><span data-stu-id="55ad4-132">Triggering zoom and controlling zoom speed can be controlled by voice or hand input, which is important for providing the user with the feeling of control while avoiding being overwhelmed.</span></span> <span data-ttu-id="55ad4-133">我們將在下面詳細說明這些設計方針。</span><span class="sxs-lookup"><span data-stu-id="55ad4-133">We will talk about these design guidelines in more detail below.</span></span> <span data-ttu-id="55ad4-134">一旦放大之後, 使用者就可以順暢地遵循, 例如, 使用眼睛眼來探索他的鄰近地區。</span><span class="sxs-lookup"><span data-stu-id="55ad4-134">Once zoomed in, the user can  smoothly follow, for example, the course of a street to explore his or her neighborhood by simply using their eye-gaze.</span></span>
<span data-ttu-id="55ad4-135">您可以在[混合實境工具組 - 視線導向瀏覽](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Navigation.html)範例中找到這類互動的示範。</span><span class="sxs-lookup"><span data-stu-id="55ad4-135">Demo examples for these types of interactions can be found in the [Mixed Reality Toolkit - Eye-supported Navigation](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Navigation.html) sample.</span></span>

<span data-ttu-id="55ad4-136">_隱含動作_的其他使用案例可能包括:</span><span class="sxs-lookup"><span data-stu-id="55ad4-136">Additional use cases for _implicit actions_ can include:</span></span>
- <span data-ttu-id="55ad4-137">**智慧型通知：** 蹦現的通知遮住您正在注視的內容，很煩人吧？</span><span class="sxs-lookup"><span data-stu-id="55ad4-137">**Smart notifications:** Ever get annoyed by notifications popping up right where you were focusing?</span></span> <span data-ttu-id="55ad4-138">考慮到使用者所需注意的事項, 您可以藉由抵銷使用者目前撥雲見日的通知, 讓這項體驗更好。</span><span class="sxs-lookup"><span data-stu-id="55ad4-138">Taking into account what a user is paying attention to, you can make this experience better by offsetting notifications from where the user is currently gazing.</span></span> <span data-ttu-id="55ad4-139">這會限制分散注意力, 並在使用者完成讀取之後自動予以關閉。</span><span class="sxs-lookup"><span data-stu-id="55ad4-139">This limits distractions and automatically dismisses them once the user is finished reading.</span></span> 
- <span data-ttu-id="55ad4-140">**善解人意的全像投影：** 在 gazed 時, 會稍微反應的全息影像。</span><span class="sxs-lookup"><span data-stu-id="55ad4-140">**Attentive holograms:** Holograms that subtly react when being gazed upon.</span></span> <span data-ttu-id="55ad4-141">其範圍從稍微照亮的 UI 元素到緩慢的綻放花, 到一開始回頭查看使用者, 或試著在長時間 stare 之後避免使用者眼的虛擬寵物。</span><span class="sxs-lookup"><span data-stu-id="55ad4-141">This can range from slightly glowing UI elements to a slowly blooming flower to a virtual pet starting to look back at the user or trying to avoid the user's eye-gaze after a prolonged stare.</span></span> <span data-ttu-id="55ad4-142">這項互動可能會在您的應用程式中提供有意義的連線和滿意度。</span><span class="sxs-lookup"><span data-stu-id="55ad4-142">This interaction might provide an interesting sense of connectivity and satisfaction in your application.</span></span>

### <a name="attention-tracking"></a><span data-ttu-id="55ad4-143">注意力追蹤</span><span class="sxs-lookup"><span data-stu-id="55ad4-143">Attention tracking</span></span>   
<span data-ttu-id="55ad4-144">使用者查看位置或內容的相關資訊是一種功能強大的工具, 可評估設計的可用性, 並找出有效率的工作流程中的問題。</span><span class="sxs-lookup"><span data-stu-id="55ad4-144">Information about where or what users look at is an immensely powerful tool to assess usability of designs, and to identify problems in efficient workflows.</span></span> <span data-ttu-id="55ad4-145">目視追蹤視覺效果和分析是各種應用程式領域中的常見做法。</span><span class="sxs-lookup"><span data-stu-id="55ad4-145">Eye tracking visualization and analytics are a common practice in various application areas.</span></span> <span data-ttu-id="55ad4-146">在 HoloLens 2 中, 我們會提供新的維度給這項瞭解, 因為3D 的全息影像可以放在真實世界的內容中, 並據此進行評估。</span><span class="sxs-lookup"><span data-stu-id="55ad4-146">With HoloLens 2, we provide a new dimension to this understanding as 3D holograms can be placed in real-world contexts and assessed accordingly.</span></span> <span data-ttu-id="55ad4-147">[Mixed Reality 工具](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html)組提供記錄和載入眼睛追蹤資料的基本範例, 以及如何將其視覺化。</span><span class="sxs-lookup"><span data-stu-id="55ad4-147">The [Mixed Reality Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) provides basic examples for logging and loading eye tracking data and  how to visualize them.</span></span>

<span data-ttu-id="55ad4-148">此區域中的其他應用程式可能包括:</span><span class="sxs-lookup"><span data-stu-id="55ad4-148">Other applications in this area can include:</span></span> 
-   <span data-ttu-id="55ad4-149">**遠端眼式視覺效果:** 視覺化遠端共同作業者正在查看的內容, 以確保是否已正確瞭解並遵循指示。</span><span class="sxs-lookup"><span data-stu-id="55ad4-149">**Remote eye-gaze visualization:** Visualize what remote collaborators are looking at to ensure whether instructions are correctly understood and followed.</span></span>
-   <span data-ttu-id="55ad4-150">**使用者行為研究：** 注意: 追蹤可用於探索新手與專家的使用者如何以視覺化方式分析內容, 或他們對複雜工作的操作方式 (例如, 分析醫療資料或作業機械)。</span><span class="sxs-lookup"><span data-stu-id="55ad4-150">**User research studies:** Attention tracking can be used to explore the way novice vs. expert users visually analyze content or how their hand-eye-coordination for complex tasks, such as for analysis of medical data or while operating machinery.</span></span>
-   <span data-ttu-id="55ad4-151">**模擬訓練和效能監視：** 實地操作，並更有效地找出工作執行流程中的瓶頸，藉以產生最佳執行流程。</span><span class="sxs-lookup"><span data-stu-id="55ad4-151">**Training simulations and Performance monitoring:** Practice and optimize the execution of tasks by identifying bottlenecks more effectively in the execution flow.</span></span>
-   <span data-ttu-id="55ad4-152">**設計評估、廣告和行銷研究：** 目視追蹤是在評估網站和產品設計時, 用於市場研究的常用工具。</span><span class="sxs-lookup"><span data-stu-id="55ad4-152">**Design evaluations, advertisement and marketing research:** Eye tracking is a common tool for market research when evaluating website and product designs.</span></span>

### <a name="additional-use-cases"></a><span data-ttu-id="55ad4-153">其他使用案例</span><span class="sxs-lookup"><span data-stu-id="55ad4-153">Additional use cases</span></span>
- <span data-ttu-id="55ad4-154">**遊戲：** 想要擁有超能力嗎？</span><span class="sxs-lookup"><span data-stu-id="55ad4-154">**Gaming:** Ever wanted to have superpowers?</span></span> <span data-ttu-id="55ad4-155">機會來了！</span><span class="sxs-lookup"><span data-stu-id="55ad4-155">Here's your chance!</span></span> <span data-ttu-id="55ad4-156">您可以透過開始來 levitate 全像投影。</span><span class="sxs-lookup"><span data-stu-id="55ad4-156">You can levitate holograms by staring at them.</span></span> <span data-ttu-id="55ad4-157">您的眼睛可以發出雷射光。</span><span class="sxs-lookup"><span data-stu-id="55ad4-157">Shoot laser beams from your eyes.</span></span> <span data-ttu-id="55ad4-158">將敵人變成石頭, 或將其凍結。</span><span class="sxs-lookup"><span data-stu-id="55ad4-158">Turn enemies into stone or freeze them.</span></span> <span data-ttu-id="55ad4-159">您可以用 X 光視線掃描建築物。</span><span class="sxs-lookup"><span data-stu-id="55ad4-159">Use your x-ray vision to explore buildings.</span></span> <span data-ttu-id="55ad4-160">您想得到的都行！</span><span class="sxs-lookup"><span data-stu-id="55ad4-160">Your imagination is the limit!</span></span>  

- <span data-ttu-id="55ad4-161">**生動的虛擬人偶：** 眼睛追蹤有助於更具表達性的3D 虛擬人偶, 方法是使用即時監看追蹤資料, 以動畫顯示使用者正在查看的內容。</span><span class="sxs-lookup"><span data-stu-id="55ad4-161">**Expressive avatars:** Eye tracking aids in more expressive 3D avatars by using live eye tracking data to animate the avatar's eyes that indicate what the user is looking at.</span></span> 

- <span data-ttu-id="55ad4-162">**文字輸入：** 眼睛追蹤可用來做為低度文字輸入的替代專案, 特別是當語音或手不方便使用時。</span><span class="sxs-lookup"><span data-stu-id="55ad4-162">**Text entry:** Eye tracking can be used as an alternative for low-effort text entry, especially when speech or hands are inconvenient to use.</span></span> 


## <a name="available-eye-tracking-data"></a><span data-ttu-id="55ad4-163">可用的眼睛追蹤資料</span><span class="sxs-lookup"><span data-stu-id="55ad4-163">Available eye tracking data</span></span>
<span data-ttu-id="55ad4-164">在深入瞭解肉眼互動的特定設計指導方針之前, 我們想要簡要指出 HoloLens 2[眼追蹤 API](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.eyespose)所提供的功能。</span><span class="sxs-lookup"><span data-stu-id="55ad4-164">Before going into detail about the specific design guidelines for eye-gaze interaction, we want to briefly point out the capabilities that the HoloLens 2 [Eye Tracking API](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.eyespose) provides.</span></span> <span data-ttu-id="55ad4-165">開發人員可以在大約_30 FPS (60 Hz)_ 上存取單一眼睛光線 (注視原點和方向)。</span><span class="sxs-lookup"><span data-stu-id="55ad4-165">Developers get access to a single eye-gaze ray (gaze origin and direction) at approximately _30 FPS (60 Hz)_.</span></span>
<span data-ttu-id="55ad4-166">如需有關如何存取眼睛追蹤資料的詳細資訊, 請參閱我們的開發人員指南, 以瞭解如何使用[DirectX 中的眼睛](gaze-in-directx.md)和[Unity 中的眼睛](https://aka.ms/mrtk-eyes)。</span><span class="sxs-lookup"><span data-stu-id="55ad4-166">For more detailed information about how to access eye tracking data, please refer to our developer guides on using [eye-gaze in DirectX](gaze-in-directx.md) and [eye-gaze in Unity](https://aka.ms/mrtk-eyes).</span></span>

<span data-ttu-id="55ad4-167">預測的眼睛大約是在實際目標周圍以視覺角度的1.5 度為單位 (請參閱下圖)。</span><span class="sxs-lookup"><span data-stu-id="55ad4-167">The predicted eye-gaze is approximately within 1.5 degrees in visual angle around the actual target (see the illustration below).</span></span> <span data-ttu-id="55ad4-168">由於預期會有些許 imprecisions, 因此開發人員應該規劃此下限值的某些邊界 (例如, 2.0-3.0 度可能會導致更舒適的體驗)。</span><span class="sxs-lookup"><span data-stu-id="55ad4-168">As slight imprecisions are expected, developers should plan for some margin around this lower bound value (e.g., 2.0-3.0 degrees may result in a much more comfortable experience).</span></span> <span data-ttu-id="55ad4-169">我們將在下面詳細說明如何解決選取的小型目標。</span><span class="sxs-lookup"><span data-stu-id="55ad4-169">We will discuss how to address the selection of small targets in more detail below.</span></span> <span data-ttu-id="55ad4-170">為了讓眼球追蹤精準運作，每個使用者都必須接受眼球追蹤使用者校正。</span><span class="sxs-lookup"><span data-stu-id="55ad4-170">For eye tracking to work accurately, each user is required to go through an eye tracking user calibration.</span></span> 

<span data-ttu-id="55ad4-171">![距離 2 公尺的最佳目標大小](images/gazetargeting-size-1000px.jpg)</span><span class="sxs-lookup"><span data-stu-id="55ad4-171">![Optimal target size at 2 meter distance](images/gazetargeting-size-1000px.jpg)</span></span><br>
<span data-ttu-id="55ad4-172">*雙計量距離的最佳目標大小*</span><span class="sxs-lookup"><span data-stu-id="55ad4-172">*Optimal target size at a 2-meter distance*</span></span>

## <a name="calibration"></a><span data-ttu-id="55ad4-173">效果</span><span class="sxs-lookup"><span data-stu-id="55ad4-173">Calibration</span></span> 
<span data-ttu-id="55ad4-174">為了讓眼追蹤能夠準確地工作, 每位使用者都必須經歷[眼睛追蹤使用者校正](calibration.md), 使用者必須查看一組全像攝影目標。</span><span class="sxs-lookup"><span data-stu-id="55ad4-174">For eye tracking to work accurately, each user is required to go through an [eye tracking user calibration](calibration.md) for which the user has to look at a set of holographic targets.</span></span> <span data-ttu-id="55ad4-175">這可讓裝置調整系統, 讓使用者能夠更舒適且更高品質的觀賞體驗, 並確保同時精確地追蹤。</span><span class="sxs-lookup"><span data-stu-id="55ad4-175">This allows the device to adjust the system for a more comfortable and higher quality viewing experience for the user and to ensure accurate eye tracking at the same time.</span></span> <span data-ttu-id="55ad4-176">眼睛追蹤應該適用于大部分的使用者, 但在某些情況下, 使用者可能無法成功校準。</span><span class="sxs-lookup"><span data-stu-id="55ad4-176">Eye tracking should work for most users, but there are cases in which a user might be unable to calibrate successfully.</span></span>
<span data-ttu-id="55ad4-177">若要深入瞭解校正, 請檢查[校正](calibration.md)。</span><span class="sxs-lookup"><span data-stu-id="55ad4-177">To learn more about the calibration, please check [Calibration](calibration.md).</span></span>

## <a name="eye-gaze-input-design-guidelines"></a><span data-ttu-id="55ad4-178">眼睛輸入設計指導方針</span><span class="sxs-lookup"><span data-stu-id="55ad4-178">Eye-gaze input design guidelines</span></span>
<span data-ttu-id="55ad4-179">建立利用快速移動眼目標的互動可能是一項挑戰。</span><span class="sxs-lookup"><span data-stu-id="55ad4-179">Building an interaction that takes advantage of fast-moving eye targeting can be challenging.</span></span> <span data-ttu-id="55ad4-180">在本節中, 我們將摘要說明設計應用程式時所要考慮的主要優點和挑戰。</span><span class="sxs-lookup"><span data-stu-id="55ad4-180">In this section, we summarize the key advantages and challenges to consider when designing your application.</span></span> 

### <a name="benefits-of-eye-gaze-input"></a><span data-ttu-id="55ad4-181">眼睛眼輸入的優點</span><span class="sxs-lookup"><span data-stu-id="55ad4-181">Benefits of eye-gaze input</span></span>
- <span data-ttu-id="55ad4-182">**高速指向。**</span><span class="sxs-lookup"><span data-stu-id="55ad4-182">**High speed pointing.**</span></span> <span data-ttu-id="55ad4-183">眼睛肌肉是人類主體中最快速的回應肌肉。</span><span class="sxs-lookup"><span data-stu-id="55ad4-183">The eye muscle is the fastest reacting muscle in the human body.</span></span> 

- <span data-ttu-id="55ad4-184">**輕鬆省力。**</span><span class="sxs-lookup"><span data-stu-id="55ad4-184">**Low effort.**</span></span> <span data-ttu-id="55ad4-185">幾乎不需要任何人為動作。</span><span class="sxs-lookup"><span data-stu-id="55ad4-185">Barely any physical movements are necessary.</span></span> 

- <span data-ttu-id="55ad4-186">**隱含性。**</span><span class="sxs-lookup"><span data-stu-id="55ad4-186">**Implicitness.**</span></span> <span data-ttu-id="55ad4-187">使用者通常會將其描述為「記住閱讀」, 使用者眼移動的相關資訊可讓系統知道使用者打算參與的目標。</span><span class="sxs-lookup"><span data-stu-id="55ad4-187">Often described by users as "mind reading", information about a user's eye movements lets the system know which target the user plans to engage.</span></span> 

- <span data-ttu-id="55ad4-188">**替代輸入管道。**</span><span class="sxs-lookup"><span data-stu-id="55ad4-188">**Alternative input channel.**</span></span> <span data-ttu-id="55ad4-189">眼睛可以根據使用者的操作性協調, 提供更強大的支援輸入, 讓您能以多年來的經驗, 來建立手寫輸入。</span><span class="sxs-lookup"><span data-stu-id="55ad4-189">Eye-gaze can provide a powerful supporting input for hand and voice input building on years of experience from users based on their hand-eye coordination.</span></span>

- <span data-ttu-id="55ad4-190">**視覺注意力。**</span><span class="sxs-lookup"><span data-stu-id="55ad4-190">**Visual attention.**</span></span> <span data-ttu-id="55ad4-191">另一個重要的優點是, 推斷使用者所需注意的內容。</span><span class="sxs-lookup"><span data-stu-id="55ad4-191">Another important benefit is the possibility to infer what a user is paying attention to.</span></span> <span data-ttu-id="55ad4-192">這可協助各種應用程式領域, 範圍從更有效率地評估不同的設計, 到以更聰明的使用者介面協助, 以及強化遠端通訊的社交提示。</span><span class="sxs-lookup"><span data-stu-id="55ad4-192">This can help in various application areas ranging from more effectively evaluating different designs to aiding in smarter user interfaces and enhanced social cues for remote communication.</span></span>

<span data-ttu-id="55ad4-193">簡單地說, 使用眼睛做為輸入, 可提供快速且輕鬆的內容相關信號。</span><span class="sxs-lookup"><span data-stu-id="55ad4-193">In a nutshell, using eye-gaze as an input offers a fast and effortless contextual signal.</span></span> <span data-ttu-id="55ad4-194">這在結合其他輸入 (例如*語音*和*手動*輸入) 以確認使用者意圖時特別強大。</span><span class="sxs-lookup"><span data-stu-id="55ad4-194">This is particularly powerful when combined with other inputs such as *voice* and *manual* input to confirm the user's intent.</span></span>


### <a name="challenges-of-eye-gaze-as-an-input"></a><span data-ttu-id="55ad4-195">目視眼做為輸入的挑戰</span><span class="sxs-lookup"><span data-stu-id="55ad4-195">Challenges of eye-gaze as an input</span></span>
<span data-ttu-id="55ad4-196">有了許多功能, 有許多責任。</span><span class="sxs-lookup"><span data-stu-id="55ad4-196">With lots of power, comes lots of responsibility.</span></span>
<span data-ttu-id="55ad4-197">雖然您可以使用眼睛來建立滿足的使用者體驗, 讓您覺得像是 superhero, 但也請務必知道它不適合適當的考慮。</span><span class="sxs-lookup"><span data-stu-id="55ad4-197">While eye-gaze can be used to create satisfying user experiences that makes you feel like a superhero, it is also important to know what it is not good at to appropriately account for this.</span></span> <span data-ttu-id="55ad4-198">以下討論一些要考慮的挑戰, 以及在使用眼睛輸入時如何解決這些*問題*:</span><span class="sxs-lookup"><span data-stu-id="55ad4-198">The following discusses some *challenges* to consider as well as how to address them when working with eye-gaze input:</span></span> 

- <span data-ttu-id="55ad4-199">**您的眼睛是「永遠開啟**」當您開啟眼睛蓋時, 您的眼會開始 fixating 環境中的事物。</span><span class="sxs-lookup"><span data-stu-id="55ad4-199">**Your eye-gaze is "always on"** The moment you open your eye lids, your eyes start fixating on things in the environment.</span></span> <span data-ttu-id="55ad4-200">回應您所做的每一種情況, 並不小心發出動作, 因為您查看太久的時間會導致回答體驗。</span><span class="sxs-lookup"><span data-stu-id="55ad4-200">Reacting to every look you make and accidentally issuing actions because you looked at something for too long would result in an unsatisfying experience.</span></span>
<span data-ttu-id="55ad4-201">因此, 我們建議您結合眼睛與*語音命令*、手勢、*按鈕按一下*或擴充停留, 以觸發目標的選取。</span><span class="sxs-lookup"><span data-stu-id="55ad4-201">Therefore we recommend combining eye-gaze with a *voice command*, *hand gesture*, *button click* or extended dwell to trigger the selection of a target.</span></span>
<span data-ttu-id="55ad4-202">此解決方案也可以讓使用者在因觸發某個專案時, 自由地在不被淹沒的情況下, 輕鬆地進行流覽。</span><span class="sxs-lookup"><span data-stu-id="55ad4-202">This solution also allows for a mode in which the user can freely look around without being overwhelmed by involuntarily triggering something.</span></span> <span data-ttu-id="55ad4-203">當您只查看目標時, 設計視覺效果和聽覺意見時, 也應該考慮此問題。</span><span class="sxs-lookup"><span data-stu-id="55ad4-203">This issue should also be considered when designing visual and auditory feedback when merely looking at a target.</span></span>
<span data-ttu-id="55ad4-204">不要讓即時蹦現的效果或暫留的音效干擾到使用者。</span><span class="sxs-lookup"><span data-stu-id="55ad4-204">Do not overwhelm the user with immediate pop-out effects or hover sounds.</span></span> <span data-ttu-id="55ad4-205">奧妙是索引鍵。</span><span class="sxs-lookup"><span data-stu-id="55ad4-205">Subtlety is key.</span></span> <span data-ttu-id="55ad4-206">後續我們在談到設計建議時，將進一步討論一些相關的最佳作法。</span><span class="sxs-lookup"><span data-stu-id="55ad4-206">We will discuss some best practices for this further below when talking about design recommendations.</span></span>

- <span data-ttu-id="55ad4-207">**觀察與控制項的**比較假設您想要在牆上精確地拉出相片。</span><span class="sxs-lookup"><span data-stu-id="55ad4-207">**Observation vs. control** Imagine that you want to precisely straighten a photograph on your wall.</span></span> <span data-ttu-id="55ad4-208">您檢視了相框及其周圍環境，看看是否妥善對齊。</span><span class="sxs-lookup"><span data-stu-id="55ad4-208">You look at its borders and its surroundings to see if it aligns well.</span></span> <span data-ttu-id="55ad4-209">現在想像一下當您想要使用眼睛做為移動圖片的輸入時, 該怎麼做。</span><span class="sxs-lookup"><span data-stu-id="55ad4-209">Now imagine how you would do that when you want to use your eye-gaze as an input to move the picture.</span></span> <span data-ttu-id="55ad4-210">很難對吧？</span><span class="sxs-lookup"><span data-stu-id="55ad4-210">Difficult, isn't it?</span></span> <span data-ttu-id="55ad4-211">這會說明在輸入和控制兩者都需要時, 眼睛的雙重角色。</span><span class="sxs-lookup"><span data-stu-id="55ad4-211">This describes the double role of eye-gaze when it is required both for input and control.</span></span> 

- <span data-ttu-id="55ad4-212">**在點按前即移開目光：** 針對快速目標的選擇, 研究顯示使用者的眼睛可以在結束手動按一下之前繼續進行 (例如, airtap)。</span><span class="sxs-lookup"><span data-stu-id="55ad4-212">**Leave before click:** For quick target selections, research has shown that a user's eye-gaze can move on before concluding a manual click (e.g., an airtap).</span></span> <span data-ttu-id="55ad4-213">因此, 必須特別注意, 才能同步處理使用速度較慢之控制項輸入 (例如語音、手、控制器) 的快速監看式信號。</span><span class="sxs-lookup"><span data-stu-id="55ad4-213">Hence, special attention must be paid to synchronizing the fast eye-gaze signal with slower control input (e.g., voice, hands, controller).</span></span>

- <span data-ttu-id="55ad4-214">**小型目標：** 當您嘗試閱讀的文字太小而無法輕鬆閱讀時, 您是否知道感覺？</span><span class="sxs-lookup"><span data-stu-id="55ad4-214">**Small targets:** Do you know the feeling when you try to read text that is just a bit too small to read comfortably?</span></span> <span data-ttu-id="55ad4-215">這對您的看法感到滿意, 會導致您感到厭倦並磨損, 因為您嘗試重新調整眼睛, 使其更專注于焦點。</span><span class="sxs-lookup"><span data-stu-id="55ad4-215">This straining feeling on your eyes can cause you to feel tired and worn out because you try to readjust your eyes to focus better.</span></span>
<span data-ttu-id="55ad4-216">當您想要在您的應用程式中使用目視目標來選取太小的目標時, 您可能會在使用者中叫用這項功能。</span><span class="sxs-lookup"><span data-stu-id="55ad4-216">This is a feeling you might invoke in your users when forcing them to select targets that are too small in your application using eye targeting.</span></span>
<span data-ttu-id="55ad4-217">您的設計若要為使用者營造出愉快而舒適的體驗，我們建議目標的視角至少應為 2°，最好是更大。</span><span class="sxs-lookup"><span data-stu-id="55ad4-217">For your design, to create a pleasant and comfortable experience for your users, we recommend that targets should be at least 2° in visual angle, preferably larger.</span></span>

- <span data-ttu-id="55ad4-218">不**齊整眼的移動**我們的眼睛會快速從 fixation 到 fixation 的移動。</span><span class="sxs-lookup"><span data-stu-id="55ad4-218">**Ragged eye-gaze movements** Our eyes perform rapid movements from fixation to fixation.</span></span> <span data-ttu-id="55ad4-219">如果您記錄眼球移動的掃描路徑，並加以檢視，您會發現它們呈現為不規則的路徑。</span><span class="sxs-lookup"><span data-stu-id="55ad4-219">If you look at scan paths of recorded eye movements, you can see that they look ragged.</span></span> <span data-ttu-id="55ad4-220">相較于*列印頭*或手中的*運動*, 您的眼睛會快速且自然地跳躍。</span><span class="sxs-lookup"><span data-stu-id="55ad4-220">Your eyes move quickly and in spontaneous jumps in comparison to *head-gaze* or *hand motions*.</span></span>  

- <span data-ttu-id="55ad4-221">**追蹤可靠性：** 眼球追蹤的精確度可能因光線的變化而略為下降，因為您的眼球必須適應新環境。</span><span class="sxs-lookup"><span data-stu-id="55ad4-221">**Tracking reliability:** Eye tracking accuracy may degrade a little in changing light as your eye adjust to the new conditions.</span></span>
<span data-ttu-id="55ad4-222">雖然這不一定會影響您的應用程式設計, 因為精確度應該在2限制內, 所以使用者可能需要重新校準。</span><span class="sxs-lookup"><span data-stu-id="55ad4-222">While this should not necessarily affect your application design, as the accuracy should be within the 2° limitation, i might be necessary for the user to calibrate again.</span></span> 


## <a name="design-recommendations"></a><span data-ttu-id="55ad4-223">設計建議</span><span class="sxs-lookup"><span data-stu-id="55ad4-223">Design recommendations</span></span>
<span data-ttu-id="55ad4-224">以下是根據眼睛輸入所述的優點和挑戰, 列出特定設計建議的清單:</span><span class="sxs-lookup"><span data-stu-id="55ad4-224">The following is a list of specific design recommendations based on the described advantages and challenges for eye-gaze input:</span></span>

1. <span data-ttu-id="55ad4-225">**眼睛並不像是注視:**</span><span class="sxs-lookup"><span data-stu-id="55ad4-225">**Eye-gaze is not the same as Head-gaze:**</span></span>
    - <span data-ttu-id="55ad4-226">**請考量快速但不規則的眼球移動是否適用於您的輸入工作：** 雖然我們可以快速且不齊整的觀點來快速地在我們的視野範圍內選取目標, 但較不適用於需要平滑輸入軌跡 (例如繪製或 encircling 注釋) 的工作。</span><span class="sxs-lookup"><span data-stu-id="55ad4-226">**Consider whether fast yet ragged eye movements fit your input task:** While our fast and ragged eye movements are great at quickly selecting targets across our field of view, it is less applicable for tasks that require smooth input trajectories (e.g., drawing or encircling annotations).</span></span> <span data-ttu-id="55ad4-227">在此情況下，手部或頭部指向應該較為合用。</span><span class="sxs-lookup"><span data-stu-id="55ad4-227">In this case, hand or head pointing should be preferred.</span></span>
  
    - <span data-ttu-id="55ad4-228">**避免直接將某個專案附加至使用者的眼睛 (例如滑杆或游標)。**</span><span class="sxs-lookup"><span data-stu-id="55ad4-228">**Avoid attaching something directly to the user’s eye-gaze (e.g., a slider or cursor).**</span></span>
<span data-ttu-id="55ad4-229">如果是游標, 這可能會造成「fleeing 游標」的效果, 這是因為投射眼信號的輕微位移。</span><span class="sxs-lookup"><span data-stu-id="55ad4-229">In case of a cursor, this may result in the “fleeing cursor” effect due to slight offsets in the projected eye-gaze signal.</span></span> <span data-ttu-id="55ad4-230">在滑杆的情況下, 它可能會與使用您的眼睛控制滑杆的雙重角色發生衝突, 同時也想要檢查物件是否在正確的位置。</span><span class="sxs-lookup"><span data-stu-id="55ad4-230">In case of a slider, it can conflict with the double role of controlling the slider with your eyes while also wanting to check whether the object is at the correct location.</span></span> <span data-ttu-id="55ad4-231">簡單地說, 使用者可能會變得很龐大, 而且會被淹沒, 特別是如果該使用者的信號不精確。</span><span class="sxs-lookup"><span data-stu-id="55ad4-231">In a nutshell, users could become overwhelmed and distracted, especially if the signal is imprecise for that user.</span></span> 
  
2. <span data-ttu-id="55ad4-232">**結合眼睛與其他輸入:** 目視追蹤與其他輸入的整合, 例如手勢、語音命令或按鈕按下, 有幾個優點:</span><span class="sxs-lookup"><span data-stu-id="55ad4-232">**Combine eye-gaze with other inputs:** The integration of eye tracking with other inputs, such as hand gestures, voice commands or button presses, serves several advantages:</span></span>
    - <span data-ttu-id="55ad4-233">**允許隨意觀看：** 假設我們眼的主要角色是要觀察我們的環境, 很重要的是, 使用者不需要觸發任何 (視覺、聽覺等) 意見或動作, 就能進行查詢。</span><span class="sxs-lookup"><span data-stu-id="55ad4-233">**Allow for free observation:** Given that the main role of our eyes is to observe our environment, it is important users are allowed to look around without triggering any (visual, auditory, etc.) feedback or actions.</span></span> 
    <span data-ttu-id="55ad4-234">將眼睛追蹤與另一個輸入控制項結合, 可讓您在眼睛追蹤觀察和輸入控制項模式之間順暢地轉換。</span><span class="sxs-lookup"><span data-stu-id="55ad4-234">Combining eye tracking with another input control allows smooth transitioning between eye tracking observation and input control modes.</span></span>
  
    - <span data-ttu-id="55ad4-235">**強大的內容提供者：** 使用有關使用者在 uttering 語音命令或執行手勢時所查看之位置和內容的資訊, 可讓您順暢地將此整個現場的輸入。</span><span class="sxs-lookup"><span data-stu-id="55ad4-235">**Powerful context provider:** Using information about where and what the user is looking at while uttering a voice command or performing a hand gesture allows seamlessly channeling the input across the field-of-view.</span></span> <span data-ttu-id="55ad4-236">例如: 「把它放在那裡」可讓您快速流暢地在場景內選取並放置全像投影，只需依序看著目標和目的地即可。</span><span class="sxs-lookup"><span data-stu-id="55ad4-236">For example: “Put that there” to quickly and fluently select and position a hologram across the scene by simply looking at a target and destination.</span></span> 

    - <span data-ttu-id="55ad4-237">**多種樣式的輸入間必須同步 (「在點按前即移開目光」的問題)：** 將快速監看式與更複雜的其他輸入結合, 例如長時間的語音命令或手勢, 在完成額外的輸入命令之前, 會帶來繼續留意的風險。</span><span class="sxs-lookup"><span data-stu-id="55ad4-237">**Need for synchronizing multimodal inputs (“leave before click” issue):** Combining rapid eye movements with more complex additional inputs, such as long voice commands or hand gestures, bears the risk of continuing your eye-gaze before finishing the additional input command.</span></span> <span data-ttu-id="55ad4-238">因此, 如果您建立自己的輸入控制項 (例如, 自訂手勢), 請務必記錄此輸入或大約持續時間的萌芽, 使其與使用者過去查看的內容相互關聯。</span><span class="sxs-lookup"><span data-stu-id="55ad4-238">Hence, if you create your own input controls (e.g., custom hand gestures), make sure to log the onset of this input or approximate duration to correlate it with what a user had looked at in the past.</span></span>
    
3. <span data-ttu-id="55ad4-239">**眼球追蹤輸入的微妙反饋：** 當目標查看以指出系統正如預期方式運作, 但應該保持細微時, 提供意見反應會很有説明。</span><span class="sxs-lookup"><span data-stu-id="55ad4-239">**Subtle feedback for eye tracking input:** It's useful to provide feedback when a target is looked at to indicate that the system is working as intended but should be kept subtle.</span></span> <span data-ttu-id="55ad4-240">這可能包括緩慢的混合、進出、視覺效果反白顯示或執行其他細微的目標行為, 例如緩慢的動作, 例如稍微增加目標大小, 以指出系統是否已正確偵測到使用者正在查看目標, 而沒有不必要地中斷使用者目前的工作流程。</span><span class="sxs-lookup"><span data-stu-id="55ad4-240">This can include slowly blending, in and out, visual highlights or perform other subtle target behaviors, such as slow motions, such as slightly increasing the target size, to indicate that the system correctly detected that the user is looking at a target without unnecessarily interrupting the user’s current workflow.</span></span> 

4. <span data-ttu-id="55ad4-241">**避免以不自然的眼球移動進行輸入：** 請勿強制使用者執行特定的眼睛移動 (注視手勢) 來觸發應用程式中的動作。</span><span class="sxs-lookup"><span data-stu-id="55ad4-241">**Avoid enforcing unnatural eye movements as input:** Do not force users to perform specific eye movements (gaze gestures) to trigger actions in your application.</span></span>

5. <span data-ttu-id="55ad4-242">**處理不精確的問題：** 我們會區分對使用者而言很明顯的兩種 imprecisions 類型: [位移] 和 [抖動]。</span><span class="sxs-lookup"><span data-stu-id="55ad4-242">**Account for imprecisions:** We distinguish two types of imprecisions which are noticeable to users: offset and jitter.</span></span> <span data-ttu-id="55ad4-243">解決位移最簡單的方式, 就是提供夠大的目標來與互動。</span><span class="sxs-lookup"><span data-stu-id="55ad4-243">The easiest way to address an offset is to provide sufficiently large targets to interact with.</span></span> <span data-ttu-id="55ad4-244">建議您使用大於2°的視覺角度做為參考。</span><span class="sxs-lookup"><span data-stu-id="55ad4-244">It is suggested that you use a visual angle greater than 2° as a reference.</span></span> <span data-ttu-id="55ad4-245">例如, 當您延展 arm 時, 縮圖大約是視覺角度的2°。</span><span class="sxs-lookup"><span data-stu-id="55ad4-245">For instance, your thumbnail is about 2° in visual angle when you stretch out your arm.</span></span> <span data-ttu-id="55ad4-246">據此我們提供下列指導方針：</span><span class="sxs-lookup"><span data-stu-id="55ad4-246">This leads to the following guidance:</span></span>
    - <span data-ttu-id="55ad4-247">請勿強制使用者選取 [小型目標]。</span><span class="sxs-lookup"><span data-stu-id="55ad4-247">Do not force users to select tiny targets.</span></span> <span data-ttu-id="55ad4-248">研究顯示, 如果目標夠大, 而且系統的設計良好, 使用者就可以輕鬆且神奇地描述其互動。</span><span class="sxs-lookup"><span data-stu-id="55ad4-248">Research has shown that if targets are sufficiently large, and that the system is designed well, users describe their interactions as effortless and magical.</span></span> <span data-ttu-id="55ad4-249">如果目標太小，則使用者會反映體驗令人疲累又洩氣。</span><span class="sxs-lookup"><span data-stu-id="55ad4-249">If targets become too small, users describe the experience as fatiguing and frustrating.</span></span>
  
## <a name="dev-guidance-what-if-eye-tracking-is-not-available"></a><span data-ttu-id="55ad4-250">開發指導方針:如果無法使用眼睛追蹤, 該怎麼辦？</span><span class="sxs-lookup"><span data-stu-id="55ad4-250">Dev guidance: What if eye tracking is not available?</span></span>
<span data-ttu-id="55ad4-251">在某些情況下, 您的應用程式可能不會因為各種原因而收到任何眼睛追蹤資料, 包括但不限於:</span><span class="sxs-lookup"><span data-stu-id="55ad4-251">There may be situations in which your app will not receive any eye tracking data due to various reasons including but not limited to:</span></span>
* <span data-ttu-id="55ad4-252">使用者已略過眼睛追蹤校準。</span><span class="sxs-lookup"><span data-stu-id="55ad4-252">The user skipped the eye tracking calibration.</span></span>
* <span data-ttu-id="55ad4-253">使用者已校正, 但決定不授與您的應用程式使用其眼追蹤資料的許可權。</span><span class="sxs-lookup"><span data-stu-id="55ad4-253">The user calibrated, but decided to not give permission to your app to use their eye tracking data.</span></span>
* <span data-ttu-id="55ad4-254">使用者具有獨特的眼鏡, 或系統尚不支援的一些眼睛狀況。</span><span class="sxs-lookup"><span data-stu-id="55ad4-254">The user has unique eyeglasses or some eye condition that the system does not yet support.</span></span>
* <span data-ttu-id="55ad4-255">外部因素會抑制可靠的眼睛追蹤, 例如 HoloLens 面板或眼鏡上的塗抹、強烈的直接陽光與遮蔽, 因為眼睛前方的頭髮。</span><span class="sxs-lookup"><span data-stu-id="55ad4-255">External factors inhibiting reliable eye tracking such as smudges on the HoloLens visor or eyeglasses, intense direct sunlight and occlusions due to hair in front of the eyes.</span></span>

<span data-ttu-id="55ad4-256">身為應用程式開發人員, 這表示您必須考慮如何支援可能無法使用眼追蹤資料的使用者。</span><span class="sxs-lookup"><span data-stu-id="55ad4-256">For you as an app developer, this means that you need to account for how to support users for whom eye tracking data may not be available.</span></span> <span data-ttu-id="55ad4-257">我們會先說明如何偵測眼追蹤是否可用, 以及如何解決不同應用程式無法使用的情況。</span><span class="sxs-lookup"><span data-stu-id="55ad4-257">Below we first explain how to detect whether eye tracking is available and how to address when it is not available for different applications.</span></span>

### <a name="1-how-to-detect-that-eye-tracking-is-available"></a><span data-ttu-id="55ad4-258">1.如何偵測到眼睛追蹤可供使用</span><span class="sxs-lookup"><span data-stu-id="55ad4-258">1. How to detect that eye tracking is available</span></span>
<span data-ttu-id="55ad4-259">有幾個檢查可判斷是否可以使用眼睛追蹤資料。</span><span class="sxs-lookup"><span data-stu-id="55ad4-259">There are a few checks to determine whether eye tracking data is available.</span></span> <span data-ttu-id="55ad4-260">檢查是否 。</span><span class="sxs-lookup"><span data-stu-id="55ad4-260">Check whether...</span></span>
* <span data-ttu-id="55ad4-261">...系統完全支援眼追蹤。</span><span class="sxs-lookup"><span data-stu-id="55ad4-261">... the system supports eye tracking at all.</span></span> <span data-ttu-id="55ad4-262">呼叫下列*方法*:[EyesPose. IsSupported ()](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.eyespose.issupported#Windows_Perception_People_EyesPose_IsSupported)</span><span class="sxs-lookup"><span data-stu-id="55ad4-262">Call the following *method*: [Windows.Perception.People.EyesPose.IsSupported()](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.eyespose.issupported#Windows_Perception_People_EyesPose_IsSupported)</span></span>

* <span data-ttu-id="55ad4-263">...使用者已校正。</span><span class="sxs-lookup"><span data-stu-id="55ad4-263">... the user is calibrated.</span></span> <span data-ttu-id="55ad4-264">呼叫下列*屬性*:[EyesPose. IsCalibrationValid。](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.eyespose.iscalibrationvalid#Windows_Perception_People_EyesPose_IsCalibrationValid)</span><span class="sxs-lookup"><span data-stu-id="55ad4-264">Call the following *property*: [Windows.Perception.People.EyesPose.IsCalibrationValid](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.eyespose.iscalibrationvalid#Windows_Perception_People_EyesPose_IsCalibrationValid)</span></span>

* <span data-ttu-id="55ad4-265">...使用者已提供您的應用程式許可權來使用其眼追蹤資料:取出目前的 _' GazeInputAccessStatus '_ 。</span><span class="sxs-lookup"><span data-stu-id="55ad4-265">... the user has given your app permission to use their eye tracking data: Retrieve the current _'GazeInputAccessStatus'_.</span></span> <span data-ttu-id="55ad4-266">如需如何執行此動作的範例, 請前往[要求存取注視輸入](https://docs.microsoft.com/en-us/windows/mixed-reality/gaze-in-directX#requesting-access-to-gaze-input)。</span><span class="sxs-lookup"><span data-stu-id="55ad4-266">An example on how to do this is explained at [Requesting access to gaze input](https://docs.microsoft.com/en-us/windows/mixed-reality/gaze-in-directX#requesting-access-to-gaze-input).</span></span>

<span data-ttu-id="55ad4-267">此外, 您可能會想要藉由在收到的眼睛追蹤資料更新之間加上超時時間來檢查您的眼睛追蹤資料是否過時, 如下所述。</span><span class="sxs-lookup"><span data-stu-id="55ad4-267">In addition, you may want to check that your eye tracking data is not stale by adding a timeout between received eye tracking data updates and otherwise fallback to head-gaze as discussed below.</span></span> 

<span data-ttu-id="55ad4-268">如上所述, 有幾個原因可能無法使用眼睛追蹤資料。</span><span class="sxs-lookup"><span data-stu-id="55ad4-268">As described above, there are several reasons why eye tracking data may not be available.</span></span> <span data-ttu-id="55ad4-269">雖然有些使用者可能會基本思考模式決定撤銷其眼追蹤資料的存取權, 而且可以將較差的使用者體驗取捨到不提供存取其眼追蹤資料的隱私權, 在某些情況下, 這可能是不慎的。</span><span class="sxs-lookup"><span data-stu-id="55ad4-269">While some users may have consciously decided to revoke access to their eye tracking data and are ok with the trade-off of an inferior user experience to the privacy of not providing access to their eye tracking data, in some cases this may be unintentional.</span></span> <span data-ttu-id="55ad4-270">因此, 如果您的應用程式使用眼追蹤, 而且這是經驗的重要部分, 我們建議您清楚地與使用者溝通。</span><span class="sxs-lookup"><span data-stu-id="55ad4-270">Hence, if your app uses eye tracking, and this is an important part of the experience, we recommend clearly communicating this to the user.</span></span> <span data-ttu-id="55ad4-271">請通知使用者, 追蹤對您的應用程式很重要的原因 (甚至是列出一些增強的功能), 您的應用程式可能會有充分的潛能, 協助使用者進一步瞭解所放棄的內容。</span><span class="sxs-lookup"><span data-stu-id="55ad4-271">Kindly informing the user why eye tracking is critical for your application (maybe even listing some enhanced features) to experience the full potential of your application can help the user to better understand what they are giving up.</span></span> <span data-ttu-id="55ad4-272">協助使用者識別眼睛追蹤可能無法運作的原因 (根據上述檢查), 並提供一些建議以快速疑難排解可能的問題。</span><span class="sxs-lookup"><span data-stu-id="55ad4-272">Help the user to identify why eye tracking may not be working (based on the above checks) and offer some suggestions to quickly troubleshoot potential issues.</span></span> <span data-ttu-id="55ad4-273">例如, 如果您可以偵測到系統支援監看追蹤, 則使用者會經過校正, 甚至也會獲得其許可權, 但不會收到任何其他問題, 例如一些其他問題, 像是塗抹或 pixels occluded 的眼睛。</span><span class="sxs-lookup"><span data-stu-id="55ad4-273">For example, if you can detect that the system supports eye tracking, the user is calibrated and even has given their permission, yet no eye tracking data is received, then this may point to some other issues such as smudges or the eyes being occluded.</span></span> <span data-ttu-id="55ad4-274">請注意, 在少數情況下, 使用者可能會無法正常執行眼追蹤。</span><span class="sxs-lookup"><span data-stu-id="55ad4-274">Please note though that there are rare cases of users for whom eye tracking may simply not work.</span></span> <span data-ttu-id="55ad4-275">因此, 請重視, 允許關閉或甚至停用提醒, 以在應用程式中啟用眼睛追蹤。</span><span class="sxs-lookup"><span data-stu-id="55ad4-275">Hence, please be respectful of that by allowing to dismiss or even disable reminders for enabling eye tracking in your app.</span></span>

### <a name="2-fallback-for-apps-using-eye-gaze-as-a-primary-input-pointer"></a><span data-ttu-id="55ad4-276">2.使用眼睛作為主要輸入指標的應用程式的 Fallback</span><span class="sxs-lookup"><span data-stu-id="55ad4-276">2. Fallback for apps using eye-gaze as a primary input pointer</span></span>
<span data-ttu-id="55ad4-277">如果您的應用程式使用眼睛眼做為指標輸入, 以快速選取場景中的全像投影, 但眼睛追蹤資料無法使用, 建議您回到前端, 並開始顯示列印頭游標。</span><span class="sxs-lookup"><span data-stu-id="55ad4-277">If your app uses eye-gaze as a pointer input to quickly select holograms across the scene, yet eye tracking data is unavailable, we recommend falling back to head-gaze and start showing the head-gaze cursor.</span></span> <span data-ttu-id="55ad4-278">我們建議使用 timeout (例如500–1500毫秒) 來判斷是否要切換。</span><span class="sxs-lookup"><span data-stu-id="55ad4-278">We recommend using a timeout (e.g., 500–1500 ms) to determine whether to switch or not.</span></span> <span data-ttu-id="55ad4-279">這是為了避免每次系統因快速監看或動畫快遞而短暫遺失追蹤時, 都要清除游標。</span><span class="sxs-lookup"><span data-stu-id="55ad4-279">This is to prevent popping up a cursor every time the system may briefly lose tracking due to fast eye motions or winks and blinks.</span></span> <span data-ttu-id="55ad4-280">如果您是 Unity 開發人員, 則已在混合現實工具組中處理自動回復為頭部。</span><span class="sxs-lookup"><span data-stu-id="55ad4-280">If you are a Unity developer, the automatic fallback to head-gaze is already handled in the Mixed Reality Toolkit.</span></span> <span data-ttu-id="55ad4-281">如果您是 DirectX 開發人員, 您必須自行處理此交換器。</span><span class="sxs-lookup"><span data-stu-id="55ad4-281">If you are a DirectX developer, you need to handle this switch yourself.</span></span>

### <a name="3-fallback-for-other-eye-tracking-specific-applications"></a><span data-ttu-id="55ad4-282">3.其他眼睛追蹤特定應用程式的回退</span><span class="sxs-lookup"><span data-stu-id="55ad4-282">3. Fallback for other eye-tracking-specific applications</span></span>
<span data-ttu-id="55ad4-283">您的應用程式可能會以專為眼睛量身打造的獨特方式來使用眼睛, 例如, 用來製作圖片的外觀, 或是以眼睛為基礎的注意熱度圖依賴視覺效果的精確資訊。</span><span class="sxs-lookup"><span data-stu-id="55ad4-283">Your app may use eye-gaze in a unique way that is tailored specifically to the eyes - for example, for animating an avatar’s eyes or for eye-based attention heatmaps relying on precise information about visual attention.</span></span> <span data-ttu-id="55ad4-284">在此情況下, 沒有任何明確的回溯。</span><span class="sxs-lookup"><span data-stu-id="55ad4-284">In this case, there is no clear fallback.</span></span> <span data-ttu-id="55ad4-285">如果無法使用眼睛追蹤, 可能只需要停用這些功能。</span><span class="sxs-lookup"><span data-stu-id="55ad4-285">If eye tracking is not available, these capabilities may simply need to be disabled.</span></span> 

<br>

<span data-ttu-id="55ad4-286">這個頁面希望能讓您開始瞭解 HoloLens 2 的眼睛追蹤和眼睛輸入的角色。</span><span class="sxs-lookup"><span data-stu-id="55ad4-286">This page has hopefully provided you with a good overview to get you started understanding the role of eye tracking and eye-gaze input for HoloLens 2.</span></span> <span data-ttu-id="55ad4-287">若要開始進行開發, 請查看我們在[Unity 中眼](https://aka.ms/mrtk-eyes)的資訊, 以及[DirectX 中的眼睛](gaze-in-directx.md)。</span><span class="sxs-lookup"><span data-stu-id="55ad4-287">To get started developing, check out our information on [eye-gaze in Unity](https://aka.ms/mrtk-eyes) and [eye-gaze in DirectX](gaze-in-directx.md).</span></span>


## <a name="see-also"></a><span data-ttu-id="55ad4-288">另請參閱</span><span class="sxs-lookup"><span data-stu-id="55ad4-288">See also</span></span>
* [<span data-ttu-id="55ad4-289">在 DirectX 中的眼睛</span><span class="sxs-lookup"><span data-stu-id="55ad4-289">Eye-gaze in DirectX</span></span>](gaze-in-directx.md)
* [<span data-ttu-id="55ad4-290">Unity 中的眼睛 (混合現實工具組)</span><span class="sxs-lookup"><span data-stu-id="55ad4-290">Eye-gaze in Unity (Mixed Reality Toolkit)</span></span>](https://aka.ms/mrtk-eyes)
* [<span data-ttu-id="55ad4-291">校正</span><span class="sxs-lookup"><span data-stu-id="55ad4-291">Calibration</span></span>](calibration.md)
* [<span data-ttu-id="55ad4-292">頭部目光和行動</span><span class="sxs-lookup"><span data-stu-id="55ad4-292">Head-gaze and commit</span></span>](gaze-and-commit.md)
* [<span data-ttu-id="55ad4-293">手勢</span><span class="sxs-lookup"><span data-stu-id="55ad4-293">Hand gestures</span></span>](gestures.md)
* [<span data-ttu-id="55ad4-294">語音輸入</span><span class="sxs-lookup"><span data-stu-id="55ad4-294">Voice input</span></span>](voice-design.md)
* [<span data-ttu-id="55ad4-295">運動控制器</span><span class="sxs-lookup"><span data-stu-id="55ad4-295">Motion controllers</span></span>](motion-controllers.md)
* [<span data-ttu-id="55ad4-296">舒適度</span><span class="sxs-lookup"><span data-stu-id="55ad4-296">Comfort</span></span>](comfort.md)
