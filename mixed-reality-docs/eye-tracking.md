---
title: 眼睛
description: HoloLens 2 讓開發人員能夠使用使用者所查看的資訊, 在全像攝影的體驗中提供新的內容層級和人類認知。
author: sostel
ms.author: sostel
ms.date: 04/05/2019
ms.topic: article
keywords: 眼睛追蹤, 混合現實, 輸入, 眼睛眼, 眼睛
ms.openlocfilehash: c847f7de2cf4492c89225a88aeaf189f51cfbc40
ms.sourcegitcommit: b0b1b8e1182cce93929d409706cdaa99ff24fdee
ms.translationtype: MT
ms.contentlocale: zh-TW
ms.lasthandoff: 07/23/2019
ms.locfileid: "68387602"
---
# <a name="eye-gaze-on-hololens-2"></a>HoloLens 2 上的眼睛
HoloLens 2 讓開發人員能夠使用使用者所查看的資訊, 在全像攝影的體驗中提供新的內容層級和人類認知。 本頁面會告訴開發人員如何從各種使用案例的眼睛追蹤中獲益, 以及設計眼睛眼的使用者介面時的外觀。 


## <a name="device-support"></a>裝置支援

<table>
<colgroup>
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
</colgroup>
<tr>
     <td><strong>功能</strong></td>
     <td><a href="hololens-hardware-details.md"><strong>HoloLens (第 1 代)</strong></a></td>
     <td><strong>HoloLens 2</strong></td>
     <td><a href="immersive-headset-hardware-details.md"><strong>沉浸式頭戴裝置</strong></a></td>
</tr>
<tr>
     <td>眼睛</td>
     <td>❌</td>
     <td>✔️</td>
     <td>❌</td>
</tr>
</table>

## <a name="use-cases"></a>使用案例
眼球追蹤可讓應用程式即時追蹤使用者的視線方向。 下列使用案例說明在混合現實中可能會有眼睛追蹤的部分互動。
請記住,[混合現實工具](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html)組非常適合用來提供幾個有趣且強大的範例來使用眼睛追蹤, 例如快速且輕鬆地支援的目標選取, 以及根據下列專案自動滾動文字使用者的外觀。 

### <a name="user-intent"></a>使用者意圖    
使用者查看位置和內容的相關資訊, 可**為其他輸入**(例如語音、手和控制器) 提供強大的內容。
這可以運用在各種不同的工作上。
例如, 只要查看全像投影, 並說「選取」 (也請參閱[列印頭和認可](gaze-and-commit.md)), 或說出「put this ...」, 然後查看使用者想要放置的位置, 就可以在整個場景中快速且輕鬆地**設定**範圍:全息圖, 然後說「...其中有「。 您可以在[混合實境工具組 - 視線導向目標選取](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_TargetSelection.html)和[混合實境工具組 - 視線導向目標定位](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Positioning.html)中找到相關範例。

此外, 使用者意圖的範例可能包括使用使用者查看的相關資訊, 以強化與虛擬代理程式和互動式全息式的資料的互動。 比方說, 虛擬代理程式可能會根據目前所看到的內容, 調整可用的選項及其行為。 

### <a name="implicit-actions"></a>隱含動作
隱含動作的類別與使用者意圖有密切的關係。
其概念是, 「全息影像」或「使用者介面」元素以有點本能的方式回應, 甚至可能不會覺得使用者與系統互動, 而是讓系統和使用者保持同步。其中一個範例是以**眼睛為基礎的自動滾動**, 其中使用者會在文字繼續滾動或與使用者的注視同步時, 讀取文字。 其中一個重要的層面是, 捲動速度會調整到使用者的閱讀速度。
另一個範例是**眼睛支援的 zoom 和 pan** , 讓使用者可以感受到他或她的焦點為何。 觸發縮放和控制縮放速度可以透過語音或手寫輸入來控制, 這對於提供使用者感覺控制, 同時避免被淹沒的情況很重要。 我們將在下面詳細說明這些設計方針。 一旦放大之後, 使用者就可以順暢地遵循, 例如, 使用眼睛眼來探索他的鄰近地區。
您可以在[混合實境工具組 - 視線導向瀏覽](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Navigation.html)範例中找到這類互動的示範。

_隱含動作_的其他使用案例可能包括:
- **智慧型通知：** 蹦現的通知遮住您正在注視的內容，很煩人吧？ 考慮到使用者所需注意的事項, 您可以藉由抵銷使用者目前撥雲見日的通知, 讓這項體驗更好。 這會限制分散注意力, 並在使用者完成讀取之後自動予以關閉。 
- **善解人意的全像投影：** 在 gazed 時, 會稍微反應的全息影像。 其範圍從稍微照亮的 UI 元素到緩慢的綻放花, 到一開始回頭查看使用者, 或試著在長時間 stare 之後避免使用者眼的虛擬寵物。 這項互動可能會在您的應用程式中提供有意義的連線和滿意度。

### <a name="attention-tracking"></a>注意力追蹤   
使用者查看位置或內容的相關資訊是一種功能強大的工具, 可評估設計的可用性, 並找出有效率的工作流程中的問題。 目視追蹤視覺效果和分析是各種應用程式領域中的常見做法。 在 HoloLens 2 中, 我們會提供新的維度給這項瞭解, 因為3D 的全息影像可以放在真實世界的內容中, 並據此進行評估。 [Mixed Reality 工具](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html)組提供記錄和載入眼睛追蹤資料的基本範例, 以及如何將其視覺化。

此區域中的其他應用程式可能包括: 
-   **遠端眼式視覺效果:** 視覺化遠端共同作業者正在查看的內容, 以確保是否已正確瞭解並遵循指示。
-   **使用者行為研究：** 注意: 追蹤可用於探索新手與專家的使用者如何以視覺化方式分析內容, 或他們對複雜工作的操作方式 (例如, 分析醫療資料或作業機械)。
-   **模擬訓練和效能監視：** 實地操作，並更有效地找出工作執行流程中的瓶頸，藉以產生最佳執行流程。
-   **設計評估、廣告和行銷研究：** 當您 evaluateing 網站和產品設計時, 眼追蹤是一種常用的市場研究工具。

### <a name="additional-use-cases"></a>其他使用案例
- **遊戲：** 想要擁有超能力嗎？ 機會來了！ 您可以透過開始來 levitate 全像投影。 您的眼睛可以發出雷射光。 將敵人變成石頭, 或將其凍結。 您可以用 X 光視線掃描建築物。 您想得到的都行！  

- **生動的虛擬人偶：** 眼睛追蹤利用即時追蹤日期來協助更具表達性的3D 虛擬人偶, 以動畫顯示使用者正在查看的內容。 此外也可加上眨眼和瞇眼來增添表達力。 

- **文字輸入：** 眼睛追蹤可用來做為低度文字輸入的替代專案, 特別是當語音或手不方便使用時。 


## <a name="eye-tracking-api"></a>眼球追蹤 API
在深入瞭解眼睛互動的特定設計指導方針之前, 我們想要簡要指出 HoloLens 2 眼追蹤程式 API 為開發人員提供的功能。 它提供了單一眼睛眼的鳥瞰原點和方向--提供大約_30 FPS_的資料。 

預測的眼睛位於 ca 內。 1.0-1.5 度, 以視覺角度表示實際目標。 由於預期會有些微偏差，您應為此下限預留緩衝值。 這一點將在稍後詳細討論。 為了讓眼球追蹤精準運作，每個使用者都必須接受眼球追蹤使用者校正。 

![距離 2 公尺的最佳目標大小](images/gazetargeting-size-1000px.jpg)<br>
*雙計量距離的最佳目標大小*
<br>
<br>
[眼睛追蹤 API](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.eyespose)可透過: ' EyesPose ' 存取。 

## <a name="eye-gaze-design-guidelines"></a>眼睛設計指導方針
要建置互動，使其利用快速移動的眼球鎖定目標，可能並不容易。 在本節中, 我們將摘要說明設計應用程式時要考慮的主要優點和挑戰。 

### <a name="benefits-of-eye-gaze-input"></a>眼睛眼輸入的優點
- **高速指向。** 眼部肌肉是人體中反應速度最快的肌肉。 

- **輕鬆省力。** 幾乎不需要任何人為動作。 

- **隱含性。** 使用者通常會將其描述為「記住閱讀」, 使用者眼移動的相關資訊可讓系統知道使用者打算參與的目標。 

- **替代輸入管道。** 眼睛可以根據使用者的操作性協調, 提供更強大的支援輸入, 讓您能以多年來的經驗, 來建立手寫輸入。

- **視覺注意力。** 另一個重要的優點是, 推斷使用者所需注意的內容。 這可協助各種應用程式領域, 範圍從更有效率地評估不同的設計, 到以更聰明的使用者介面協助, 以及強化遠端通訊的社交提示。

簡單地說, 使用眼睛做為輸入, 可提供快速且輕鬆的內容相關信號。 這在結合其他輸入 (例如*語音*和*手動*輸入) 以確認使用者意圖時特別強大。


### <a name="challenges-of-eye-gaze-as-an-input"></a>目視眼做為輸入的挑戰
有了許多功能, 有許多責任。
雖然您可以使用眼睛來建立滿足的使用者體驗, thata 讓您覺得像是 superhero, 但也請務必知道它不適合適當地考慮此情況。 下面討論一些要納入考慮的挑戰, 以及在使用眼睛輸入時如何解決這些*問題*: 

- **您的眼睛是「永遠開啟**」當您開啟眼睛蓋時, 您的眼會開始 fixating 環境中的事物。 回應您所做的每一種情況, 並不小心發出動作, 因為您查看太久的時間會導致回答體驗。
這就是為什麼我們建議您結合眼睛與*語音命令*、手勢、*按鈕按一下*或擴充停留, 以觸發目標的選取。
此解決方案也可以讓使用者在因觸發某個專案時, 自由地在不被淹沒的情況下, 輕鬆地進行流覽。 在設計單純觀看目標的視覺和聽覺反饋時，也應將此問題納入考量。
不要讓即時蹦現的效果或暫留的音效干擾到使用者。 奧妙是索引鍵。 後續我們在談到設計建議時，將進一步討論一些相關的最佳作法。

- **觀察與控制項的**比較假設您想要在牆上精確地拉出相片。 您檢視了相框及其周圍環境，看看是否妥善對齊。 現在想像一下當您想要使用眼睛做為移動圖片的輸入時, 該怎麼做。 很難對吧？ 這會說明在輸入和控制兩者都需要時, 眼睛的雙重角色。 

- **在點按前即移開目光：** 針對快速目標的選擇, 研究顯示使用者的眼睛可以在結束手動按一下之前繼續進行 (例如, airtap)。 因此, 必須特別注意, 才能同步處理使用速度較慢之控制項輸入 (例如語音、手、控制器) 的快速監看式信號。

- **小型目標：** 當您嘗試閱讀的文字太小而難以閱讀時, 您是否知道覺得？ 這對您的看法感到滿意, 會導致您感到厭倦並磨損, 因為您嘗試重新調整眼睛, 使其更專注于焦點。
當您想要在您的應用程式中使用目視目標來選取太小的目標時, 您可能會在使用者中叫用這項功能。
您的設計若要為使用者營造出愉快而舒適的體驗，我們建議目標的視角至少應為 2°，最好是更大。

- 不**齊整眼的移動**我們的眼睛會快速從 fixation 到 fixation 的移動。 如果您記錄眼球移動的掃描路徑，並加以檢視，您會發現它們呈現為不規則的路徑。 相較於*頭部目光*或*手部動作*，眼球移動的速度較快，且同時會跳躍。  

- **追蹤可靠性：** 眼球追蹤的精確度可能因光線的變化而略為下降，因為您的眼球必須適應新環境。
雖然這不一定會影響您的應用程式設計, 因為精確度應該在2限制內, 所以使用者可能需要執行另一個校正。 


## <a name="design-recommendations"></a>設計建議
以下是根據眼睛輸入所述的優點和挑戰, 列出特定設計建議的清單:

1. **眼睛眼! = Head 注視:**
    - **請考量快速但不規則的眼球移動是否適用於您的輸入工作：** 雖然我們快速且不齊眼的移動非常適合在我們的視野範圍 (FoV) 上快速選取目標, 但較不適用於需要平滑輸入軌跡 (例如繪製或 encircling 注釋) 的工作。 在此情況下，手部或頭部指向應該較為合用。
  
    - **避免直接將某個專案附加至使用者的眼睛 (例如滑杆或游標)。**
如果是游標, 這可能會造成「fleeing 游標」的效果, 這是因為投射眼信號的輕微位移。 在滑杆的情況下, 它可能會與使用您的眼睛控制滑杆的雙重角色發生衝突, 同時也想要檢查物件是否在正確的位置。 簡單地說, 使用者可能會變得很龐大, 而且會被淹沒, 特別是如果該使用者的信號不精確。 
  
2. **結合眼睛與其他輸入:** 目視追蹤與其他輸入的整合, 例如手勢、語音命令或按鈕按下, 有幾個優點:
    - **允許隨意觀看：** 假設我們眼的主要角色是要觀察我們的環境, 很重要的是, 使用者不需要觸發任何 (視覺、聽覺等) 意見或動作, 就能進行查詢。 
    將眼睛追蹤與另一個輸入控制項結合, 可讓您在眼睛追蹤觀察和輸入控制項模式之間順暢地轉換。
  
    - **強大的內容提供者：** 使用有關使用者在 uttering 語音命令或執行手勢時所查看之位置和內容的資訊, 可讓您順暢地將此整個現場的輸入。 例如: 「把它放在那裡」可讓您快速流暢地在場景內選取並放置全像投影，只需依序看著目標和目的地即可。 

    - **多種樣式的輸入間必須同步 (「在點按前即移開目光」的問題)：** 將快速監看式與更複雜的其他輸入結合, 例如長時間的語音命令或手勢, 在完成額外的輸入命令之前, 會帶來繼續留意的風險。 因此，如果您自行建立輸入控制項 (例如自訂手勢)，請務必記錄此輸入的開端或約略的持續時間，並將其與使用者過去的關注標的產生關聯。
    
3. **眼球追蹤輸入的微妙反饋：** 當目標查看以指出系統正如預期方式運作時, 提供意見反應很有用, 但應該保持細微。 這可能包括緩慢的混合、進出、視覺效果反白顯示或執行其他細微的目標行為, 例如緩慢的動作, 例如稍微增加目標, 表示系統已正確偵測到使用者正在查看目標, 但沒有不必要地中斷使用者目前的工作流程。 

4. **避免以不自然的眼球移動進行輸入：** 請勿強制使用者執行特定的眼睛移動 (注視手勢) 來觸發應用程式中的動作。

5. **處理不精確的問題：** 我們會區分對使用者而言很明顯的兩種 imprecisions 類型: [位移] 和 [抖動]。 解決位移最簡單的方式, 就是提供夠大的目標來與互動。 建議您使用大於2°的視覺角度做為參考。 例如, 當您延展 arm 時, 縮圖大約是視覺角度的2°。 據此我們提供下列指導方針：
    - 請勿強制使用者選取 [小型目標]。 研究顯示, 如果目標夠大, 而且系統的設計良好, 使用者就可以輕鬆且神奇地描述其互動。 如果目標太小，則使用者會反映體驗令人疲累又洩氣。
   

## <a name="see-also"></a>另請參閱
* [頭部目光和行動](gaze-and-commit.md)
* [DirectX 中的 Head 和眼睛](gaze-in-directx.md)
* [Unity 中的眼睛 (混合現實工具組)](https://aka.ms/mrtk-eyes)
* [手勢](gestures.md)
* [語音輸入](voice-design.md)
* [運動控制器](motion-controllers.md)
* [舒適度](comfort.md)
