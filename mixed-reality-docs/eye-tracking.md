---
title: 眼球追蹤
description: HoloLens 2 讓開發人員能夠使用使用者所查看之內容的相關資訊，在全像攝影體驗中提供新的內容層級和人類認知。
author: sostel
ms.author: sostel
ms.date: 10/29/2019
ms.topic: article
keywords: 眼睛追蹤，混合現實，輸入，眼睛眼，校正
ms.openlocfilehash: 88c1827d3656ceb851e8f778daa2303b88dd17c8
ms.sourcegitcommit: b6b76275fad90df6d9645dd2bc074b7b2168c7c8
ms.translationtype: MT
ms.contentlocale: zh-TW
ms.lasthandoff: 11/11/2019
ms.locfileid: "73913218"
---
# <a name="eye-tracking-on-hololens-2"></a><span data-ttu-id="53f09-104">HoloLens 2 的眼球追蹤</span><span class="sxs-lookup"><span data-stu-id="53f09-104">Eye tracking on HoloLens 2</span></span>

![MRTK 中的眼睛追蹤示範](images/mrtk_et_scenemenu.jpg)

<span data-ttu-id="53f09-106">HoloLens 2 讓開發人員能夠使用使用者所查看之內容的相關資訊，在全像攝影體驗中提供新的內容層級和人類認知。</span><span class="sxs-lookup"><span data-stu-id="53f09-106">HoloLens 2 allows for a new level of context and human understanding within the holographic experience by providing developers with the ability to use information about what the user is looking at.</span></span> <span data-ttu-id="53f09-107">本頁面會告訴開發人員如何從各種使用案例的眼睛追蹤中獲益，以及設計眼睛眼的使用者互動時的外觀。</span><span class="sxs-lookup"><span data-stu-id="53f09-107">This page tells developers how they can benefit from eye tracking for various use cases as well as what to look for when designing eye-gaze-based user interactions.</span></span> 

<span data-ttu-id="53f09-108">眼睛追蹤 API 已設計成使用者的隱私權，避免傳遞任何可識別的資訊，特別是任何生物識別。</span><span class="sxs-lookup"><span data-stu-id="53f09-108">Eye tracking API has been designed with user’s privacy in mind, avoiding passing any identifiable information, particularly any biometrics.</span></span> <span data-ttu-id="53f09-109">對於具備目視追蹤功能的應用程式，使用者必須授與應用程式許可權，以使用目視追蹤資訊。</span><span class="sxs-lookup"><span data-stu-id="53f09-109">For eye-tracking capable applications, the user needs to grant app permission to use eye tracking information.</span></span> 


### <a name="device-support"></a><span data-ttu-id="53f09-110">裝置支援</span><span class="sxs-lookup"><span data-stu-id="53f09-110">Device support</span></span>
<table>
<colgroup>
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
</colgroup>
<tr>
     <td><span data-ttu-id="53f09-111"><strong>特徵</strong></span><span class="sxs-lookup"><span data-stu-id="53f09-111"><strong>Feature</strong></span></span></td>
     <td><span data-ttu-id="53f09-112"><a href="hololens-hardware-details.md"><strong>HoloLens (第 1 代)</strong></a></span><span class="sxs-lookup"><span data-stu-id="53f09-112"><a href="hololens-hardware-details.md"><strong>HoloLens (1st gen)</strong></a></span></span></td>
     <td><span data-ttu-id="53f09-113"><a href="https://docs.microsoft.com/hololens/hololens2-hardware"><strong>HoloLens 2</strong></span><span class="sxs-lookup"><span data-stu-id="53f09-113"><a href="https://docs.microsoft.com/hololens/hololens2-hardware"><strong>HoloLens 2</strong></span></span></td>
     <td><span data-ttu-id="53f09-114"><a href="immersive-headset-hardware-details.md"><strong>沉浸式頭戴裝置</strong></a></span><span class="sxs-lookup"><span data-stu-id="53f09-114"><a href="immersive-headset-hardware-details.md"><strong>Immersive headsets</strong></a></span></span></td>
</tr>
<tr>
     <td><span data-ttu-id="53f09-115">眼睛</span><span class="sxs-lookup"><span data-stu-id="53f09-115">Eye-gaze</span></span></td>
     <td>❌</td>
     <td><span data-ttu-id="53f09-116">✔️</span><span class="sxs-lookup"><span data-stu-id="53f09-116">✔️</span></span></td>
     <td>❌</td>
</tr>
</table>

<br>

## <a name="calibration"></a><span data-ttu-id="53f09-117">效果</span><span class="sxs-lookup"><span data-stu-id="53f09-117">Calibration</span></span> 
<span data-ttu-id="53f09-118">為了讓眼追蹤能夠準確地工作，每位使用者都必須經歷[眼睛追蹤使用者校正](calibration.md)，使用者必須查看一組全像攝影目標。</span><span class="sxs-lookup"><span data-stu-id="53f09-118">For eye tracking to work accurately, each user is required to go through an [eye tracking user calibration](calibration.md) for which the user has to look at a set of holographic targets.</span></span> <span data-ttu-id="53f09-119">這可讓裝置調整系統，讓使用者能夠更舒適且更高品質的觀賞體驗，並確保同時精確地追蹤。</span><span class="sxs-lookup"><span data-stu-id="53f09-119">This allows the device to adjust the system for a more comfortable and higher quality viewing experience for the user and to ensure accurate eye tracking at the same time.</span></span> 

<span data-ttu-id="53f09-120">眼睛追蹤應該適用于大部分的使用者，但在少數情況下，使用者可能無法成功校準。</span><span class="sxs-lookup"><span data-stu-id="53f09-120">Eye tracking should work for most users, but there are rare cases in which a user might not be able to calibrate successfully.</span></span> <span data-ttu-id="53f09-121">校正可能因各種原因而失敗，包括但不限於：</span><span class="sxs-lookup"><span data-stu-id="53f09-121">Calibration might fail for various reasons, including but not limited to:</span></span> 
* <span data-ttu-id="53f09-122">使用者先前退出宣告校正程式</span><span class="sxs-lookup"><span data-stu-id="53f09-122">The user previously opted out of the calibration process</span></span>
* <span data-ttu-id="53f09-123">使用者有注意力，而未遵循校正目標</span><span class="sxs-lookup"><span data-stu-id="53f09-123">The user got distracted and didn't follow the calibration targets</span></span>
* <span data-ttu-id="53f09-124">使用者有特定類型的 contact 鏡頭和眼鏡，但系統尚未支援</span><span class="sxs-lookup"><span data-stu-id="53f09-124">The user has certain types of contact lenses and glasses which the system doesn't yet support</span></span> 
* <span data-ttu-id="53f09-125">使用者有特定的眼睛生理學、眼睛狀況或系統尚未支援的眼睛外科</span><span class="sxs-lookup"><span data-stu-id="53f09-125">The user has certain eye physiology, eye conditions or had eye surgery which the system doesn't yet support</span></span>  
* <span data-ttu-id="53f09-126">外部因素抑制了可靠的眼睛追蹤，例如 HoloLens 面板或眼鏡上的塗抹、強烈的直接陽光與遮蔽，因為眼睛前方的頭髮</span><span class="sxs-lookup"><span data-stu-id="53f09-126">External factors inhibiting reliable eye tracking such as smudges on the HoloLens visor or eyeglasses, intense direct sunlight and occlusions due to hair in front of the eyes</span></span>

<span data-ttu-id="53f09-127">開發人員應務必為可能無法使用眼追蹤資料的使用者提供適當的支援（無法成功校準）。</span><span class="sxs-lookup"><span data-stu-id="53f09-127">Developers should make sure to provide adequate support for users for whom eye tracking data may not be available (who are not able to calibrate successfully).</span></span> <span data-ttu-id="53f09-128">我們已在此頁面底部的一節中，提供回溯解決方案的建議。</span><span class="sxs-lookup"><span data-stu-id="53f09-128">We have provided recommendations for fallback solutions in the section at the bottom of this page.</span></span> 

<span data-ttu-id="53f09-129">若要深入瞭解校正以及如何確保順暢的體驗，請查看我們的[眼睛追蹤使用者校準](calibration.md)頁面。</span><span class="sxs-lookup"><span data-stu-id="53f09-129">To learn more about the calibration and about how to ensure a smooth experience, please check our [eye tracking user calibration](calibration.md) page.</span></span>

<br>

## <a name="available-eye-tracking-data"></a><span data-ttu-id="53f09-130">可用的眼睛追蹤資料</span><span class="sxs-lookup"><span data-stu-id="53f09-130">Available eye tracking data</span></span>
<span data-ttu-id="53f09-131">在深入瞭解眼睛輸入的特定使用案例之前，我們想要簡要指出 HoloLens 2[眼追蹤 API](https://docs.microsoft.com/uwp/api/windows.perception.people.eyespose)所提供的功能。</span><span class="sxs-lookup"><span data-stu-id="53f09-131">Before going into detail about specific use cases for eye-gaze input, we want to briefly point out the capabilities that the HoloLens 2 [Eye Tracking API](https://docs.microsoft.com/uwp/api/windows.perception.people.eyespose) provides.</span></span> <span data-ttu-id="53f09-132">開發人員可以在大約_30 FPS （30 Hz）_ 的情況中，存取單一眼睛光線（注視原點和方向）。</span><span class="sxs-lookup"><span data-stu-id="53f09-132">Developers get access to a single eye-gaze ray (gaze origin and direction) at approximately _30 FPS (30 Hz)_.</span></span>
<span data-ttu-id="53f09-133">如需有關如何存取眼睛追蹤資料的詳細資訊，請參閱我們的開發人員指南，以瞭解如何使用[DirectX 中的眼睛](gaze-in-directx.md)和[Unity 中的眼睛](https://aka.ms/mrtk-eyes)。</span><span class="sxs-lookup"><span data-stu-id="53f09-133">For more detailed information about how to access eye tracking data, please refer to our developer guides on using [eye-gaze in DirectX](gaze-in-directx.md) and [eye-gaze in Unity](https://aka.ms/mrtk-eyes).</span></span>

<span data-ttu-id="53f09-134">預測的眼睛大約是在實際目標周圍以視覺角度的1.5 度為單位（請參閱下圖）。</span><span class="sxs-lookup"><span data-stu-id="53f09-134">The predicted eye-gaze is approximately within 1.5 degrees in visual angle around the actual target (see the illustration below).</span></span> <span data-ttu-id="53f09-135">由於預期會有些許 imprecisions，因此開發人員應該規劃此下限值的某些邊界（例如，2.0-3.0 度可能會導致更舒適的體驗）。</span><span class="sxs-lookup"><span data-stu-id="53f09-135">As slight imprecisions are expected, developers should plan for some margin around this lower bound value (e.g., 2.0-3.0 degrees may result in a much more comfortable experience).</span></span> <span data-ttu-id="53f09-136">我們將在下面詳細說明如何解決選取的小型目標。</span><span class="sxs-lookup"><span data-stu-id="53f09-136">We will discuss how to address the selection of small targets in more detail below.</span></span> <span data-ttu-id="53f09-137">為了讓眼球追蹤精準運作，每個使用者都必須接受眼球追蹤使用者校正。</span><span class="sxs-lookup"><span data-stu-id="53f09-137">For eye tracking to work accurately, each user is required to go through an eye tracking user calibration.</span></span> 

<span data-ttu-id="53f09-138">![2 個計量表距離的最佳目標大小](images/gazetargeting-size-1000px.jpg)</span><span class="sxs-lookup"><span data-stu-id="53f09-138">![Optimal target size at 2 meter distance](images/gazetargeting-size-1000px.jpg)</span></span><br>
<span data-ttu-id="53f09-139">*雙計量距離的最佳目標大小*</span><span class="sxs-lookup"><span data-stu-id="53f09-139">*Optimal target size at a 2-meter distance*</span></span>

<br>

## <a name="use-cases"></a><span data-ttu-id="53f09-140">使用案例</span><span class="sxs-lookup"><span data-stu-id="53f09-140">Use cases</span></span>
<span data-ttu-id="53f09-141">眼球追蹤可讓應用程式即時追蹤使用者的視線方向。</span><span class="sxs-lookup"><span data-stu-id="53f09-141">Eye tracking enables applications to track where the user is looking in real time.</span></span> <span data-ttu-id="53f09-142">下列使用案例說明在 HoloLens 2 上，混合現實中可能會有的一些互動。</span><span class="sxs-lookup"><span data-stu-id="53f09-142">The following use cases describe some interactions that are possible with eye tracking on HoloLens 2 in mixed reality.</span></span>
<span data-ttu-id="53f09-143">請注意，這些使用案例尚未包含在全像攝影介面的體驗中（也就是當您啟動 HoloLens 2 時所看到的介面）。</span><span class="sxs-lookup"><span data-stu-id="53f09-143">Please note that these use cases are not yet part of the Holographic Shell experience (i.e., the interface that you see when you start up your HoloLens 2).</span></span>
<span data-ttu-id="53f09-144">您可以在[Mixed Reality 工具](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html)組中試用其中一些專案，其中提供幾個有趣且強大的範例來使用眼睛追蹤，例如快速且輕鬆地支援的目標選取，以及自動以文字為基礎的滾動使用者查看的內容。</span><span class="sxs-lookup"><span data-stu-id="53f09-144">You can try some of them out in the [Mixed Reality Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) which provides several interesting and powerful examples for using eye tracking, such as quick and effortless eye-supported target selections as well as automatically scrolling through text based on what the user looks at.</span></span> 

### <a name="user-intent"></a><span data-ttu-id="53f09-145">使用者意圖</span><span class="sxs-lookup"><span data-stu-id="53f09-145">User intent</span></span>    
<span data-ttu-id="53f09-146">使用者查看位置和內容的相關資訊，可**為其他輸入**（例如語音、手和控制器）提供強大的內容。</span><span class="sxs-lookup"><span data-stu-id="53f09-146">Information about where and what a user looks at provides a powerful **context for other inputs**, such as voice, hands and controllers.</span></span>
<span data-ttu-id="53f09-147">這可以運用在各種不同的工作上。</span><span class="sxs-lookup"><span data-stu-id="53f09-147">This can be used for various tasks.</span></span>
<span data-ttu-id="53f09-148">例如，只要查看全像投影並說「*選取*」（也請參閱[注視和認可](gaze-and-commit.md)），或說出「 *put this ...* 」，然後查看使用者的位置，就可以在整個場景中快速且輕鬆地**設定其目標**。想要放置全息的影像，並說「 *.。。其中有*「。</span><span class="sxs-lookup"><span data-stu-id="53f09-148">For example, this can range from quickly and effortlessly **targeting** across the scene by simply looking at a hologram and saying *"select"* (also see [gaze and commit](gaze-and-commit.md)) or by saying *"put this..."*, then looking over to where the user wants to place the hologram and say *"...there"*.</span></span> <span data-ttu-id="53f09-149">您可以在[混合實境工具組 - 視線導向目標選取](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_TargetSelection.html)和[混合實境工具組 - 視線導向目標定位](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Positioning.html)中找到相關範例。</span><span class="sxs-lookup"><span data-stu-id="53f09-149">Examples for this can be found in [Mixed Reality Toolkit - Eye-supported Target Selection](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_TargetSelection.html) and [Mixed Reality Toolkit - Eye-supported Target Positioning](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Positioning.html).</span></span>

<span data-ttu-id="53f09-150">此外，使用者意圖的範例可能包括使用使用者查看的相關資訊，以強化與虛擬代理程式和互動式全息式的資料的互動。</span><span class="sxs-lookup"><span data-stu-id="53f09-150">Additionally, an example for user intent might include using information about what users look at to enhance engagement with embodied virtual agents and interactive holograms.</span></span> <span data-ttu-id="53f09-151">比方說，虛擬代理程式可能會根據目前所看到的內容，調整可用的選項及其行為。</span><span class="sxs-lookup"><span data-stu-id="53f09-151">For instance, virtual agents might adapt available options and their behavior based on currently viewed content.</span></span> 

### <a name="implicit-actions"></a><span data-ttu-id="53f09-152">隱含動作</span><span class="sxs-lookup"><span data-stu-id="53f09-152">Implicit actions</span></span>
<span data-ttu-id="53f09-153">隱含動作的類別與使用者意圖有密切的關係。</span><span class="sxs-lookup"><span data-stu-id="53f09-153">The category of implicit actions closely relates to user intent.</span></span>
<span data-ttu-id="53f09-154">其概念是，全息影像或使用者介面專案會以本能的方式回應，這可能不會覺得使用者與系統互動，而是讓系統和使用者保持同步。其中一個範例是以**眼睛為基礎的自動滾動**，其中使用者可以讀取長文字，當使用者到達文字方塊底部時，會自動開始滾動，讓使用者不需要進入手指就能繼續閱讀。</span><span class="sxs-lookup"><span data-stu-id="53f09-154">The idea is that holograms or user interface elements react in an instinctual way that may not even feel like the user is interacting with the system at all, but rather that the system and the user are in sync. One example is **eye-gaze-based auto scroll** where the user can read a long text which automatically starts scrolling once the user gets to the bottom of the textbox to keep the user in the flow of reading without lifting a finger.</span></span>  
<span data-ttu-id="53f09-155">重點是，捲動速度會適應使用者的閱讀速度。</span><span class="sxs-lookup"><span data-stu-id="53f09-155">A key aspect of this is that the scrolling speed adapts to the reading speed of the user.</span></span>
<span data-ttu-id="53f09-156">另一個例子是，**眼睛支援的縮放和平移**，讓使用者可以感受到他或她專注于的樣子。</span><span class="sxs-lookup"><span data-stu-id="53f09-156">Another example is **eye-supported zoom and pan** where the user can feel like diving exactly toward what he or she is focused on.</span></span> <span data-ttu-id="53f09-157">觸發縮放和控制縮放速度可以透過語音或手寫輸入來控制，這對於提供使用者感覺控制，同時避免被淹沒的情況很重要。</span><span class="sxs-lookup"><span data-stu-id="53f09-157">Triggering zoom and controlling zoom speed can be controlled by voice or hand input, which is important for providing the user with the feeling of control while avoiding being overwhelmed.</span></span> <span data-ttu-id="53f09-158">我們將在下面詳細說明這些設計考慮。</span><span class="sxs-lookup"><span data-stu-id="53f09-158">We will talk about these design considerations in more detail below.</span></span> <span data-ttu-id="53f09-159">一旦放大之後，使用者就可以順暢地遵循，例如，使用眼睛眼來探索他的鄰近地區。</span><span class="sxs-lookup"><span data-stu-id="53f09-159">Once zoomed in, the user can  smoothly follow, for example, the course of a street to explore his or her neighborhood by simply using their eye-gaze.</span></span>
<span data-ttu-id="53f09-160">您可以在[混合實境工具組 - 視線導向瀏覽](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Navigation.html)範例中找到這類互動的示範。</span><span class="sxs-lookup"><span data-stu-id="53f09-160">Demo examples for these types of interactions can be found in the [Mixed Reality Toolkit - Eye-supported Navigation](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Navigation.html) sample.</span></span>

<span data-ttu-id="53f09-161">_隱含動作_的其他使用案例可能包括：</span><span class="sxs-lookup"><span data-stu-id="53f09-161">Additional use cases for _implicit actions_ may include:</span></span>
- <span data-ttu-id="53f09-162">**智慧型通知：** 在您要尋找的位置，感到苦惱的通知會立即出現嗎？</span><span class="sxs-lookup"><span data-stu-id="53f09-162">**Smart notifications:** Ever get annoyed by notifications popping up right where you are looking?</span></span> <span data-ttu-id="53f09-163">考慮到使用者所需注意的事項，您可以藉由抵銷使用者目前撥雲見日的通知，讓這項體驗更好。</span><span class="sxs-lookup"><span data-stu-id="53f09-163">Taking into account what a user is paying attention to, you can make this experience better by offsetting notifications from where the user is currently gazing.</span></span> <span data-ttu-id="53f09-164">這會限制分散注意力，並在使用者完成讀取之後自動予以關閉。</span><span class="sxs-lookup"><span data-stu-id="53f09-164">This limits distractions and automatically dismisses them once the user is finished reading.</span></span> 
- <span data-ttu-id="53f09-165">**用心的全息影像：** 在 gazed 時，會稍微反應的全息影像。</span><span class="sxs-lookup"><span data-stu-id="53f09-165">**Attentive holograms:** Holograms that subtly react when being gazed upon.</span></span> <span data-ttu-id="53f09-166">其範圍從稍微照亮的 UI 元素，到虛擬狗的緩慢綻放花卉，一開始會回頭查看使用者並 wagging 其結尾。</span><span class="sxs-lookup"><span data-stu-id="53f09-166">This can range from slightly glowing UI elements, a slowly blooming flower to a virtual dog starting to look back at the user and wagging its tail.</span></span> <span data-ttu-id="53f09-167">這項互動可能會在您的應用程式中提供有意義的連線和滿意度。</span><span class="sxs-lookup"><span data-stu-id="53f09-167">This interaction might provide an interesting sense of connectivity and satisfaction in your application.</span></span>

### <a name="attention-tracking"></a><span data-ttu-id="53f09-168">注意力追蹤</span><span class="sxs-lookup"><span data-stu-id="53f09-168">Attention tracking</span></span>   
<span data-ttu-id="53f09-169">使用者查看位置或內容的相關資訊可以是功能強大的工具，它可以協助您評估設計的可用性，並找出工作流程中的問題，使其更有效率。</span><span class="sxs-lookup"><span data-stu-id="53f09-169">Information about where or what users look at can be an immensely powerful tool – it can help assess usability of designs and identify problems in workflows to make them more efficient.</span></span>
<span data-ttu-id="53f09-170">目視追蹤視覺效果和分析是各種應用程式領域中的常見做法。</span><span class="sxs-lookup"><span data-stu-id="53f09-170">Eye tracking visualization and analytics are a common practice in various application areas.</span></span> <span data-ttu-id="53f09-171">在 HoloLens 2 中，我們會提供新的維度給這項瞭解，因為3D 的全息影像可以放在真實世界的內容中，並據此進行評估。</span><span class="sxs-lookup"><span data-stu-id="53f09-171">With HoloLens 2, we provide a new dimension to this understanding as 3D holograms can be placed in real-world contexts and assessed accordingly.</span></span> <span data-ttu-id="53f09-172">[Mixed Reality 工具](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html)組提供記錄和載入眼睛追蹤資料的基本範例，以及如何將其視覺化。</span><span class="sxs-lookup"><span data-stu-id="53f09-172">The [Mixed Reality Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) provides basic examples for logging and loading eye tracking data and how to visualize them.</span></span>
<span data-ttu-id="53f09-173">Microsoft 致力於促進創新，同時確保使用者可以透過其眼追蹤資訊的使用方式，獲得提供通知和透明的體驗。</span><span class="sxs-lookup"><span data-stu-id="53f09-173">Microsoft is dedicated to facilitating innovation while ensuring that users are provided an informed and transparent experience with how their eye tracking information is used.</span></span>  <span data-ttu-id="53f09-174">我們會與開發人員和 UX 小組合作，為協力廠商提供指引，確保體驗是以使用者為中心。</span><span class="sxs-lookup"><span data-stu-id="53f09-174">We will work with our developers and UX teams to provide guidance for third parties that ensures experiences are centered around the user.</span></span>  


<span data-ttu-id="53f09-175">同屬此領域的其他應用程式包括：</span><span class="sxs-lookup"><span data-stu-id="53f09-175">Other applications in this area may include:</span></span> 
-   <span data-ttu-id="53f09-176">**遠端眼式視覺效果：** 遠端監看式視覺效果：將遠端共同作業者正在查看的內容視覺化，以提供立即的意見反應，並加速更精確的資訊處理。</span><span class="sxs-lookup"><span data-stu-id="53f09-176">**Remote eye-gaze visualization:** Remote eye-gaze visualizations: Visualize what remote collaborators are looking at to be able to provide immediate feedback and facilitate more accurate information processing.</span></span>
-   <span data-ttu-id="53f09-177">**使用者研究研究：** 注意追蹤可協助研究人員深入瞭解使用者如何察覺和與自然環境互動，而不會干擾，以設計更本能的人電腦互動。</span><span class="sxs-lookup"><span data-stu-id="53f09-177">**User research studies:** Attention tracking can help researchers get more insights into how users perceive and engage with natural environment,  without interfering, to design more instinctual human-computer-interactions.</span></span> <span data-ttu-id="53f09-178">眼睛追蹤可以提供研究中的參與者不直接表達的資訊，但研究員可能會很容易錯過。</span><span class="sxs-lookup"><span data-stu-id="53f09-178">Eye tracking can provide information that is not directly articulated by participants in the study, that otherwise might be easily missed by the researcher.</span></span> 
-   <span data-ttu-id="53f09-179">**定型和效能監視：** 藉由在執行流程中更有效率地識別瓶頸，來練習並優化工作的執行作業。</span><span class="sxs-lookup"><span data-stu-id="53f09-179">**Training and performance monitoring:** Practice and optimize the execution of tasks by identifying bottlenecks more effectively in the execution flow.</span></span> <span data-ttu-id="53f09-180">眼睛追蹤可以提供自然的即時和目標資訊，協助改善工作場所的訓練、生產力和安全性。</span><span class="sxs-lookup"><span data-stu-id="53f09-180">Eye tracking can provide natural, real-time and objective information to help improve training, productivity, and safety in the workplace.</span></span> 
-   <span data-ttu-id="53f09-181">**設計評估、行銷和消費者研究：** 眼睛追蹤讓商業公司能夠在實際環境中執行行銷和取用者研究，或分析哪些內容會吸引使用者注意，以改善產品或空間設計。</span><span class="sxs-lookup"><span data-stu-id="53f09-181">**Design evaluations, marketing and consumer research:** Eye tracking enables commercial companies to perform marketing and consumer studies in real-world environments or analyze what captures user’s attention to improve product or space design.</span></span> 

### <a name="additional-use-cases"></a><span data-ttu-id="53f09-182">其他使用案例</span><span class="sxs-lookup"><span data-stu-id="53f09-182">Additional use cases</span></span>
- <span data-ttu-id="53f09-183">**遊戲：** 您是否想要超能力？</span><span class="sxs-lookup"><span data-stu-id="53f09-183">**Gaming:** Ever wanted to have superpowers?</span></span> <span data-ttu-id="53f09-184">機會來了！</span><span class="sxs-lookup"><span data-stu-id="53f09-184">Here's your chance!</span></span> <span data-ttu-id="53f09-185">您可以透過開始來 levitate 全像投影。</span><span class="sxs-lookup"><span data-stu-id="53f09-185">You can levitate holograms by staring at them.</span></span> <span data-ttu-id="53f09-186">從眼睛中取得鐳射字形狀-試試[RoboRaid 中的 HoloLens 2](https://www.microsoft.com/p/roboraid/9nblggh5fv3j)。</span><span class="sxs-lookup"><span data-stu-id="53f09-186">Shoot laser beams from your eyes - try it out in [RoboRaid for HoloLens 2](https://www.microsoft.com/p/roboraid/9nblggh5fv3j).</span></span>
<span data-ttu-id="53f09-187">將敵人變成石頭，或將其凍結。</span><span class="sxs-lookup"><span data-stu-id="53f09-187">Turn enemies into stone or freeze them.</span></span> <span data-ttu-id="53f09-188">您可以用 X 光視線掃描建築物。</span><span class="sxs-lookup"><span data-stu-id="53f09-188">Use your x-ray vision to explore buildings.</span></span> <span data-ttu-id="53f09-189">您想得到的都行！</span><span class="sxs-lookup"><span data-stu-id="53f09-189">Your imagination is the limit!</span></span>
<span data-ttu-id="53f09-190">請注意，使用者不會太多-若要深入瞭解，請參閱我們的[眼睛型輸入設計指導方針](eye-gaze-interaction.md)。</span><span class="sxs-lookup"><span data-stu-id="53f09-190">Beware of not overwhelming the user though - to find out more, check out our [eye-gaze-based input design guidelines](eye-gaze-interaction.md).</span></span>

- <span data-ttu-id="53f09-191">**表達虛擬人偶：** 眼睛追蹤有助於更具表達性的3D 虛擬人偶，方法是使用即時監看追蹤資料，以動畫顯示使用者正在查看的內容。</span><span class="sxs-lookup"><span data-stu-id="53f09-191">**Expressive avatars:** Eye tracking aids in more expressive 3D avatars by using live eye tracking data to animate the avatar's eyes that indicate what the user is looking at.</span></span> 

- <span data-ttu-id="53f09-192">**文字輸入：** 眼睛追蹤可用來做為低度文字輸入的替代專案，特別是當語音或手不方便使用時。</span><span class="sxs-lookup"><span data-stu-id="53f09-192">**Text entry:** Eye tracking can be used as an alternative for low-effort text entry, especially when speech or hands are inconvenient to use.</span></span> 

<br>

## <a name="using-eye-gaze-for-interaction"></a><span data-ttu-id="53f09-193">使用眼睛來互動</span><span class="sxs-lookup"><span data-stu-id="53f09-193">Using eye-gaze for interaction</span></span>
<span data-ttu-id="53f09-194">建立利用快速移動眼目標的互動可能是一項挑戰。</span><span class="sxs-lookup"><span data-stu-id="53f09-194">Building an interaction that takes advantage of fast-moving eye targeting can be challenging.</span></span>
<span data-ttu-id="53f09-195">一方面，眼睛的移動速度很快，因此您必須小心瞭解如何使用眼睛眼輸入，因為其他使用者可能會發現這種體驗很龐大或混亂。</span><span class="sxs-lookup"><span data-stu-id="53f09-195">On the one hand, the eyes move so fast that you need to be careful on how to use eye-gaze input, because otherwise users may find the experience overwhelming or distracting.</span></span> <span data-ttu-id="53f09-196">另一方面，您也可以建立真正的神奇體驗，以激發您的使用者！</span><span class="sxs-lookup"><span data-stu-id="53f09-196">On the other hand, you can also create truly magical experiences that will excite your users!</span></span> <span data-ttu-id="53f09-197">為協助您，請查看我們的重要優點、挑戰和設計建議，以瞭解[互動](eye-gaze-interaction.md)。</span><span class="sxs-lookup"><span data-stu-id="53f09-197">To help you, check out our overview of key advantages, challenges and design recommendations for [eye-gaze for interaction](eye-gaze-interaction.md).</span></span> 
 
## <a name="fallback-solutions-when-eye-tracking-is-not-available"></a><span data-ttu-id="53f09-198">無法使用眼睛追蹤時的回溯解決方案</span><span class="sxs-lookup"><span data-stu-id="53f09-198">Fallback solutions when eye tracking is not available</span></span>

<span data-ttu-id="53f09-199">在罕見的情況下，可能無法使用目視追蹤資料。</span><span class="sxs-lookup"><span data-stu-id="53f09-199">In rare cases eye tracking data might not be available.</span></span>
<span data-ttu-id="53f09-200">這可能是因為以下列出最常見的不同原因：</span><span class="sxs-lookup"><span data-stu-id="53f09-200">This can be due to different reasons from which the most common are listed below:</span></span>
* <span data-ttu-id="53f09-201">系統無法[校正使用者](calibration.md)。</span><span class="sxs-lookup"><span data-stu-id="53f09-201">The system failed to [calibrate the user](calibration.md).</span></span>
* <span data-ttu-id="53f09-202">使用者已略過[校正](calibration.md)。</span><span class="sxs-lookup"><span data-stu-id="53f09-202">The user skipped the [calibration](calibration.md).</span></span>   
* <span data-ttu-id="53f09-203">使用者已校正，但決定不授與您的應用程式使用其眼追蹤資料的許可權。</span><span class="sxs-lookup"><span data-stu-id="53f09-203">The user is calibrated, but decided to not give permission to your app to use their eye tracking data.</span></span>    
* <span data-ttu-id="53f09-204">使用者具有獨特的眼鏡，或系統尚不支援的一些眼睛狀況。</span><span class="sxs-lookup"><span data-stu-id="53f09-204">The user has unique eyeglasses or some eye condition that the system does not yet support.</span></span>    
* <span data-ttu-id="53f09-205">外部因素會抑制可靠的眼睛追蹤，例如 HoloLens 面板或眼鏡上的塗抹、強烈的直接陽光與遮蔽，因為眼睛前方的頭髮。</span><span class="sxs-lookup"><span data-stu-id="53f09-205">External factors inhibiting reliable eye tracking such as smudges on the HoloLens visor or eyeglasses, intense direct sunlight and occlusions due to hair in front of the eyes.</span></span>   

<span data-ttu-id="53f09-206">因此，開發人員應該確保這些使用者有適當的回溯支援。</span><span class="sxs-lookup"><span data-stu-id="53f09-206">Hence, developers should ensure that there is appropriate fallback support for these users.</span></span> <span data-ttu-id="53f09-207">在 [ [DirectX 中](gaze-in-directx.md#fallback-when-eye-tracking-is-not-available)的監看追蹤] 頁面上，我們會說明偵測是否有可用的監看追蹤資料所需的 api。</span><span class="sxs-lookup"><span data-stu-id="53f09-207">On the [Eye Tracking in DirectX](gaze-in-directx.md#fallback-when-eye-tracking-is-not-available) page, we explain the APIs required to detect whether eye tracking data is available.</span></span> 

<span data-ttu-id="53f09-208">雖然有些使用者可能會基本思考模式決定撤銷其眼追蹤資料的存取權，而且可以將較差的使用者體驗取捨到不提供存取其眼追蹤資料的隱私權，在某些情況下，這可能是不慎的。</span><span class="sxs-lookup"><span data-stu-id="53f09-208">While some users may have consciously decided to revoke access to their eye tracking data and are ok with the trade-off of an inferior user experience to the privacy of not providing access to their eye tracking data, in some cases this may be unintentional.</span></span>  
<span data-ttu-id="53f09-209">因此，如果您的應用程式使用眼追蹤，而且這是經驗的重要部分，我們建議您清楚地與使用者溝通。</span><span class="sxs-lookup"><span data-stu-id="53f09-209">Hence, if your app uses eye tracking, and this is an important part of the experience, we recommend clearly communicating this to the user.</span></span>     
<span data-ttu-id="53f09-210">請通知使用者，追蹤對您的應用程式很重要的原因（甚至是列出一些增強的功能），您的應用程式可能會有充分的潛能，協助使用者進一步瞭解所放棄的內容。</span><span class="sxs-lookup"><span data-stu-id="53f09-210">Kindly informing the user why eye tracking is critical for your application (maybe even listing some enhanced features) to experience the full potential of your application can help the user to better understand what they are giving up.</span></span>    
<span data-ttu-id="53f09-211">協助使用者識別眼睛追蹤可能無法運作的原因（根據上述檢查），並提供一些建議以快速疑難排解可能的問題。</span><span class="sxs-lookup"><span data-stu-id="53f09-211">Help the user to identify why eye tracking may not be working (based on the above checks) and offer some suggestions to quickly troubleshoot potential issues.</span></span>  
<span data-ttu-id="53f09-212">例如，如果您可以偵測到系統支援監看追蹤，則使用者會經過校正，甚至也會獲得其許可權，但不會收到任何其他問題，例如一些其他問題，像是塗抹或 pixels occluded 的眼睛。</span><span class="sxs-lookup"><span data-stu-id="53f09-212">For example, if you can detect that the system supports eye tracking, the user is calibrated and even has given their permission, yet no eye tracking data is received, then this may point to some other issues such as smudges or the eyes being occluded.</span></span>    
<span data-ttu-id="53f09-213">請注意，在少數情況下，使用者可能會無法正常執行眼追蹤。</span><span class="sxs-lookup"><span data-stu-id="53f09-213">Please note though that there are rare cases of users for whom eye tracking may simply not work.</span></span>    
<span data-ttu-id="53f09-214">因此，請重視，允許關閉或甚至停用提醒，以在應用程式中啟用眼睛追蹤。</span><span class="sxs-lookup"><span data-stu-id="53f09-214">Hence, please be respectful of that by allowing to dismiss or even disable reminders for enabling eye tracking in your app.</span></span>

### <a name="fallback-for-apps-using-eye-gaze-as-a-primary-input-pointer"></a><span data-ttu-id="53f09-215">使用眼睛作為主要輸入指標的應用程式的 Fallback</span><span class="sxs-lookup"><span data-stu-id="53f09-215">Fallback for apps using eye-gaze as a primary input pointer</span></span>
<span data-ttu-id="53f09-216">如果您的應用程式使用眼睛眼做為指標輸入，以快速選取場景中的全像投影，但眼睛追蹤資料無法使用，建議您回到前端，並開始顯示列印頭游標。</span><span class="sxs-lookup"><span data-stu-id="53f09-216">If your app uses eye-gaze as a pointer input to quickly select holograms across the scene, yet eye tracking data is unavailable, we recommend falling back to head-gaze and start showing the head-gaze cursor.</span></span> <span data-ttu-id="53f09-217">我們建議使用 timeout （例如500–1500毫秒）來判斷是否要切換。</span><span class="sxs-lookup"><span data-stu-id="53f09-217">We recommend using a timeout (e.g., 500–1500 ms) to determine whether to switch or not.</span></span> <span data-ttu-id="53f09-218">這是為了避免每次系統因快速監看或動畫快遞而短暫遺失追蹤時，都要清除游標。</span><span class="sxs-lookup"><span data-stu-id="53f09-218">This is to prevent popping up a cursor every time the system may briefly lose tracking due to fast eye motions or winks and blinks.</span></span> <span data-ttu-id="53f09-219">如果您是 Unity 開發人員，則已在混合現實工具組中處理自動回復為頭部。</span><span class="sxs-lookup"><span data-stu-id="53f09-219">If you are a Unity developer, the automatic fallback to head-gaze is already handled in the Mixed Reality Toolkit.</span></span> <span data-ttu-id="53f09-220">如果您是 DirectX 開發人員，您必須自行處理此交換器。</span><span class="sxs-lookup"><span data-stu-id="53f09-220">If you are a DirectX developer, you need to handle this switch yourself.</span></span>

### <a name="fallback-for-other-eye-tracking-specific-applications"></a><span data-ttu-id="53f09-221">其他眼睛追蹤特定應用程式的回退</span><span class="sxs-lookup"><span data-stu-id="53f09-221">Fallback for other eye-tracking-specific applications</span></span>
<span data-ttu-id="53f09-222">您的應用程式可能會以專為眼睛量身打造的獨特方式來使用眼睛，例如，用來製作圖片的外觀，或是以眼睛為基礎的注意熱度圖依賴視覺效果的精確資訊。</span><span class="sxs-lookup"><span data-stu-id="53f09-222">Your app may use eye-gaze in a unique way that is tailored specifically to the eyes - for example, for animating an avatar’s eyes or for eye-based attention heatmaps relying on precise information about visual attention.</span></span> <span data-ttu-id="53f09-223">在此情況下，沒有任何明確的回溯。</span><span class="sxs-lookup"><span data-stu-id="53f09-223">In this case, there is no clear fallback.</span></span> <span data-ttu-id="53f09-224">如果無法使用眼睛追蹤，可能只需要停用這些功能。</span><span class="sxs-lookup"><span data-stu-id="53f09-224">If eye tracking is not available, these capabilities may simply need to be disabled.</span></span>
<span data-ttu-id="53f09-225">同樣地，我們建議您與不知道功能無法運作的使用者清楚溝通。</span><span class="sxs-lookup"><span data-stu-id="53f09-225">Again, we recommend to clearly communicate this to the user who may be unaware that the capability is not working.</span></span>

<br>

<span data-ttu-id="53f09-226">這個頁面希望能讓您開始瞭解 HoloLens 2 的眼睛追蹤和眼睛輸入的角色。</span><span class="sxs-lookup"><span data-stu-id="53f09-226">This page has hopefully provided you with a good overview to get you started understanding the role of eye tracking and eye-gaze input for HoloLens 2.</span></span> <span data-ttu-id="53f09-227">若要開始進行開發，請查看我們的資訊，[瞭解如何與全息影像互動](eye-gaze-interaction.md)、 [Unity 中的眼睛](https://aka.ms/mrtk-eyes)，以及[DirectX 中的眼睛](gaze-in-directx.md)。</span><span class="sxs-lookup"><span data-stu-id="53f09-227">To get started developing, check out our information on the role of [eye-gaze for interacting with holograms](eye-gaze-interaction.md), [eye-gaze in Unity](https://aka.ms/mrtk-eyes) and [eye-gaze in DirectX](gaze-in-directx.md).</span></span>


## <a name="see-also"></a><span data-ttu-id="53f09-228">請參閱</span><span class="sxs-lookup"><span data-stu-id="53f09-228">See also</span></span>
* [<span data-ttu-id="53f09-229">校正</span><span class="sxs-lookup"><span data-stu-id="53f09-229">Calibration</span></span>](calibration.md)
* [<span data-ttu-id="53f09-230">舒適度</span><span class="sxs-lookup"><span data-stu-id="53f09-230">Comfort</span></span>](comfort.md)
* [<span data-ttu-id="53f09-231">眼部目光導向的互動</span><span class="sxs-lookup"><span data-stu-id="53f09-231">Eye-gaze-based interaction</span></span>](eye-gaze-interaction.md)
* [<span data-ttu-id="53f09-232">在 DirectX 中的眼睛</span><span class="sxs-lookup"><span data-stu-id="53f09-232">Eye-gaze in DirectX</span></span>](gaze-in-directx.md)
* [<span data-ttu-id="53f09-233">Unity 中的眼睛（混合現實工具組）</span><span class="sxs-lookup"><span data-stu-id="53f09-233">Eye-gaze in Unity (Mixed Reality Toolkit)</span></span>](https://aka.ms/mrtk-eyes)
* [<span data-ttu-id="53f09-234">目光和行動</span><span class="sxs-lookup"><span data-stu-id="53f09-234">Gaze and commit</span></span>](gaze-and-commit.md)
* [<span data-ttu-id="53f09-235">語音輸入</span><span class="sxs-lookup"><span data-stu-id="53f09-235">Voice input</span></span>](voice-design.md)


