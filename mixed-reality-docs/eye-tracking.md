---
title: 眼睛
description: HoloLens 2 讓開發人員能夠使用使用者所查看的資訊, 在全像攝影的體驗中提供新的內容層級和人類認知。
author: sostel
ms.author: sostel
ms.date: 04/05/2019
ms.topic: article
keywords: 眼睛追蹤, 混合現實, 輸入, 眼睛眼, 眼睛
ms.openlocfilehash: c847f7de2cf4492c89225a88aeaf189f51cfbc40
ms.sourcegitcommit: b0b1b8e1182cce93929d409706cdaa99ff24fdee
ms.translationtype: MT
ms.contentlocale: zh-TW
ms.lasthandoff: 07/23/2019
ms.locfileid: "68387602"
---
# <a name="eye-gaze-on-hololens-2"></a><span data-ttu-id="7b73a-104">HoloLens 2 上的眼睛</span><span class="sxs-lookup"><span data-stu-id="7b73a-104">Eye-gaze on HoloLens 2</span></span>
<span data-ttu-id="7b73a-105">HoloLens 2 讓開發人員能夠使用使用者所查看的資訊, 在全像攝影的體驗中提供新的內容層級和人類認知。</span><span class="sxs-lookup"><span data-stu-id="7b73a-105">HoloLens 2 allows for a new level of context and human understanding within the holographic experience by providing developers with the ability of using information about what users are looking at.</span></span> <span data-ttu-id="7b73a-106">本頁面會告訴開發人員如何從各種使用案例的眼睛追蹤中獲益, 以及設計眼睛眼的使用者介面時的外觀。</span><span class="sxs-lookup"><span data-stu-id="7b73a-106">This page tells developers how they can benefit from eye tracking for various use cases as well as what to look for when designing eye-gaze-based user interfaces.</span></span> 


## <a name="device-support"></a><span data-ttu-id="7b73a-107">裝置支援</span><span class="sxs-lookup"><span data-stu-id="7b73a-107">Device support</span></span>

<table>
<colgroup>
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
</colgroup>
<tr>
     <td><span data-ttu-id="7b73a-108"><strong>功能</strong></span><span class="sxs-lookup"><span data-stu-id="7b73a-108"><strong>Feature</strong></span></span></td>
     <td><span data-ttu-id="7b73a-109"><a href="hololens-hardware-details.md"><strong>HoloLens (第 1 代)</strong></a></span><span class="sxs-lookup"><span data-stu-id="7b73a-109"><a href="hololens-hardware-details.md"><strong>HoloLens (1st gen)</strong></a></span></span></td>
     <td><span data-ttu-id="7b73a-110"><strong>HoloLens 2</strong></span><span class="sxs-lookup"><span data-stu-id="7b73a-110"><strong>HoloLens 2</strong></span></span></td>
     <td><span data-ttu-id="7b73a-111"><a href="immersive-headset-hardware-details.md"><strong>沉浸式頭戴裝置</strong></a></span><span class="sxs-lookup"><span data-stu-id="7b73a-111"><a href="immersive-headset-hardware-details.md"><strong>Immersive headsets</strong></a></span></span></td>
</tr>
<tr>
     <td><span data-ttu-id="7b73a-112">眼睛</span><span class="sxs-lookup"><span data-stu-id="7b73a-112">Eye-gaze</span></span></td>
     <td><span data-ttu-id="7b73a-113">❌</span><span class="sxs-lookup"><span data-stu-id="7b73a-113">❌</span></span></td>
     <td><span data-ttu-id="7b73a-114">✔️</span><span class="sxs-lookup"><span data-stu-id="7b73a-114">✔️</span></span></td>
     <td><span data-ttu-id="7b73a-115">❌</span><span class="sxs-lookup"><span data-stu-id="7b73a-115">❌</span></span></td>
</tr>
</table>

## <a name="use-cases"></a><span data-ttu-id="7b73a-116">使用案例</span><span class="sxs-lookup"><span data-stu-id="7b73a-116">Use cases</span></span>
<span data-ttu-id="7b73a-117">眼球追蹤可讓應用程式即時追蹤使用者的視線方向。</span><span class="sxs-lookup"><span data-stu-id="7b73a-117">Eye tracking enables applications to track where the user is looking in real time.</span></span> <span data-ttu-id="7b73a-118">下列使用案例說明在混合現實中可能會有眼睛追蹤的部分互動。</span><span class="sxs-lookup"><span data-stu-id="7b73a-118">The following use cases describe some interactions that are possible with eye tracking in mixed reality.</span></span>
<span data-ttu-id="7b73a-119">請記住,[混合現實工具](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html)組非常適合用來提供幾個有趣且強大的範例來使用眼睛追蹤, 例如快速且輕鬆地支援的目標選取, 以及根據下列專案自動滾動文字使用者的外觀。</span><span class="sxs-lookup"><span data-stu-id="7b73a-119">Keep in mind that the [Mixed Reality Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) is useful for providing several interesting and powerful examples for using eye tracking, such as quick and effortless eye-supported target selections as well as automatically scrolling through text based on what the user looks at.</span></span> 

### <a name="user-intent"></a><span data-ttu-id="7b73a-120">使用者意圖</span><span class="sxs-lookup"><span data-stu-id="7b73a-120">User intent</span></span>    
<span data-ttu-id="7b73a-121">使用者查看位置和內容的相關資訊, 可**為其他輸入**(例如語音、手和控制器) 提供強大的內容。</span><span class="sxs-lookup"><span data-stu-id="7b73a-121">Information about where and what a user looks at provides a powerful **context for other inputs**, such as voice, hands and controllers.</span></span>
<span data-ttu-id="7b73a-122">這可以運用在各種不同的工作上。</span><span class="sxs-lookup"><span data-stu-id="7b73a-122">This can be used for various tasks.</span></span>
<span data-ttu-id="7b73a-123">例如, 只要查看全像投影, 並說「選取」 (也請參閱[列印頭和認可](gaze-and-commit.md)), 或說出「put this ...」, 然後查看使用者想要放置的位置, 就可以在整個場景中快速且輕鬆地**設定**範圍:全息圖, 然後說「.。。其中有「。</span><span class="sxs-lookup"><span data-stu-id="7b73a-123">For example, this can range from quickly and effortlessly **targeting** across the scene by simply looking at a hologram and saying "select" (also see [Head-gaze and commit](gaze-and-commit.md)) or by saying "put this...", then looking over to where the user wants to place the hologram and say "...there".</span></span> <span data-ttu-id="7b73a-124">您可以在[混合實境工具組 - 視線導向目標選取](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_TargetSelection.html)和[混合實境工具組 - 視線導向目標定位](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Positioning.html)中找到相關範例。</span><span class="sxs-lookup"><span data-stu-id="7b73a-124">Examples for this can be found in [Mixed Reality Toolkit - Eye-supported Target Selection](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_TargetSelection.html) and [Mixed Reality Toolkit - Eye-supported Target Positioning](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Positioning.html).</span></span>

<span data-ttu-id="7b73a-125">此外, 使用者意圖的範例可能包括使用使用者查看的相關資訊, 以強化與虛擬代理程式和互動式全息式的資料的互動。</span><span class="sxs-lookup"><span data-stu-id="7b73a-125">Additionally, an example for user intent might include using information about what users look at to enhance engagement with embodied virtual agents and interactive holograms.</span></span> <span data-ttu-id="7b73a-126">比方說, 虛擬代理程式可能會根據目前所看到的內容, 調整可用的選項及其行為。</span><span class="sxs-lookup"><span data-stu-id="7b73a-126">For instance, virtual agents might adapt available options and their behavior based on currently viewed content.</span></span> 

### <a name="implicit-actions"></a><span data-ttu-id="7b73a-127">隱含動作</span><span class="sxs-lookup"><span data-stu-id="7b73a-127">Implicit actions</span></span>
<span data-ttu-id="7b73a-128">隱含動作的類別與使用者意圖有密切的關係。</span><span class="sxs-lookup"><span data-stu-id="7b73a-128">The category of implicit actions closely relates to user intent.</span></span>
<span data-ttu-id="7b73a-129">其概念是, 「全息影像」或「使用者介面」元素以有點本能的方式回應, 甚至可能不會覺得使用者與系統互動, 而是讓系統和使用者保持同步。其中一個範例是以**眼睛為基礎的自動滾動**, 其中使用者會在文字繼續滾動或與使用者的注視同步時, 讀取文字。</span><span class="sxs-lookup"><span data-stu-id="7b73a-129">The idea is that holograms or user interface elements react in a somewhat instinctual way that may not even feel like the user is interacting with the system at all, but rather that the system and the user are in sync. One example is **eye-gaze-based auto scroll** where the user reads text as the text continues to scroll or flow in sync with with the user's gaze.</span></span> <span data-ttu-id="7b73a-130">其中一個重要的層面是, 捲動速度會調整到使用者的閱讀速度。</span><span class="sxs-lookup"><span data-stu-id="7b73a-130">A key aspect of this is that scrolling speed adapts to the reading speed of the user.</span></span>
<span data-ttu-id="7b73a-131">另一個範例是**眼睛支援的 zoom 和 pan** , 讓使用者可以感受到他或她的焦點為何。</span><span class="sxs-lookup"><span data-stu-id="7b73a-131">Another example is **eye-supported zoom and pan** where the user can feel like diving exactly toward what he or she is focused o.</span></span> <span data-ttu-id="7b73a-132">觸發縮放和控制縮放速度可以透過語音或手寫輸入來控制, 這對於提供使用者感覺控制, 同時避免被淹沒的情況很重要。</span><span class="sxs-lookup"><span data-stu-id="7b73a-132">Triggering zoom and controlling zoom speed can be controlled by voice or hand input, which is important for providing the user with the feeling of control while avoiding being overwhelmed.</span></span> <span data-ttu-id="7b73a-133">我們將在下面詳細說明這些設計方針。</span><span class="sxs-lookup"><span data-stu-id="7b73a-133">We will talk about these design guidelines in more detail below.</span></span> <span data-ttu-id="7b73a-134">一旦放大之後, 使用者就可以順暢地遵循, 例如, 使用眼睛眼來探索他的鄰近地區。</span><span class="sxs-lookup"><span data-stu-id="7b73a-134">Once zoomed in, the user can  smoothly follow, for example, the course of a street to explore his or her neighborhood by simply using their eye-gaze.</span></span>
<span data-ttu-id="7b73a-135">您可以在[混合實境工具組 - 視線導向瀏覽](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Navigation.html)範例中找到這類互動的示範。</span><span class="sxs-lookup"><span data-stu-id="7b73a-135">Demo examples for these types of interactions can be found in the [Mixed Reality Toolkit - Eye-supported Navigation](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Navigation.html) sample.</span></span>

<span data-ttu-id="7b73a-136">_隱含動作_的其他使用案例可能包括:</span><span class="sxs-lookup"><span data-stu-id="7b73a-136">Additional use cases for _implicit actions_ can include:</span></span>
- <span data-ttu-id="7b73a-137">**智慧型通知：** 蹦現的通知遮住您正在注視的內容，很煩人吧？</span><span class="sxs-lookup"><span data-stu-id="7b73a-137">**Smart notifications:** Ever get annoyed by notifications popping up right where you were focusing?</span></span> <span data-ttu-id="7b73a-138">考慮到使用者所需注意的事項, 您可以藉由抵銷使用者目前撥雲見日的通知, 讓這項體驗更好。</span><span class="sxs-lookup"><span data-stu-id="7b73a-138">Taking into account what a user is paying attention to, you can make this experience better by offsetting notifications from where the user is currently gazing.</span></span> <span data-ttu-id="7b73a-139">這會限制分散注意力, 並在使用者完成讀取之後自動予以關閉。</span><span class="sxs-lookup"><span data-stu-id="7b73a-139">This limits distractions and automatically dismisses them once the user is finished reading.</span></span> 
- <span data-ttu-id="7b73a-140">**善解人意的全像投影：** 在 gazed 時, 會稍微反應的全息影像。</span><span class="sxs-lookup"><span data-stu-id="7b73a-140">**Attentive holograms:** Holograms that subtly react when being gazed upon.</span></span> <span data-ttu-id="7b73a-141">其範圍從稍微照亮的 UI 元素到緩慢的綻放花, 到一開始回頭查看使用者, 或試著在長時間 stare 之後避免使用者眼的虛擬寵物。</span><span class="sxs-lookup"><span data-stu-id="7b73a-141">This can range from slightly glowing UI elements to a slowly blooming flower to a virtual pet starting to look back at the user or trying to avoid the user's eye-gaze after a prolonged stare.</span></span> <span data-ttu-id="7b73a-142">這項互動可能會在您的應用程式中提供有意義的連線和滿意度。</span><span class="sxs-lookup"><span data-stu-id="7b73a-142">This interaction might provide an interesting sense of connectivity and satisfaction in your application.</span></span>

### <a name="attention-tracking"></a><span data-ttu-id="7b73a-143">注意力追蹤</span><span class="sxs-lookup"><span data-stu-id="7b73a-143">Attention tracking</span></span>   
<span data-ttu-id="7b73a-144">使用者查看位置或內容的相關資訊是一種功能強大的工具, 可評估設計的可用性, 並找出有效率的工作流程中的問題。</span><span class="sxs-lookup"><span data-stu-id="7b73a-144">Information about where or what users look at is an immensely powerful tool to assess usability of designs, and to identify problems in efficient workflows.</span></span> <span data-ttu-id="7b73a-145">目視追蹤視覺效果和分析是各種應用程式領域中的常見做法。</span><span class="sxs-lookup"><span data-stu-id="7b73a-145">Eye tracking visualization and analytics are a common practice in various application areas.</span></span> <span data-ttu-id="7b73a-146">在 HoloLens 2 中, 我們會提供新的維度給這項瞭解, 因為3D 的全息影像可以放在真實世界的內容中, 並據此進行評估。</span><span class="sxs-lookup"><span data-stu-id="7b73a-146">With HoloLens 2, we provide a new dimension to this understanding as 3D holograms can be placed in real-world contexts and assessed accordingly.</span></span> <span data-ttu-id="7b73a-147">[Mixed Reality 工具](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html)組提供記錄和載入眼睛追蹤資料的基本範例, 以及如何將其視覺化。</span><span class="sxs-lookup"><span data-stu-id="7b73a-147">The [Mixed Reality Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) provides basic examples for logging and loading eye tracking data and  how to visualize them.</span></span>

<span data-ttu-id="7b73a-148">此區域中的其他應用程式可能包括:</span><span class="sxs-lookup"><span data-stu-id="7b73a-148">Other applications in this area can include:</span></span> 
-   <span data-ttu-id="7b73a-149">**遠端眼式視覺效果:** 視覺化遠端共同作業者正在查看的內容, 以確保是否已正確瞭解並遵循指示。</span><span class="sxs-lookup"><span data-stu-id="7b73a-149">**Remote eye-gaze visualization:** Visualize what remote collaborators are looking at to ensure whether instructions are correctly understood and followed.</span></span>
-   <span data-ttu-id="7b73a-150">**使用者行為研究：** 注意: 追蹤可用於探索新手與專家的使用者如何以視覺化方式分析內容, 或他們對複雜工作的操作方式 (例如, 分析醫療資料或作業機械)。</span><span class="sxs-lookup"><span data-stu-id="7b73a-150">**User research studies:** Attention tracking can be used to explore the way novice vs. expert users visually analyze content or how their hand-eye-coordination for complex tasks, such as for analysis of medical data or while operating machinery.</span></span>
-   <span data-ttu-id="7b73a-151">**模擬訓練和效能監視：** 實地操作，並更有效地找出工作執行流程中的瓶頸，藉以產生最佳執行流程。</span><span class="sxs-lookup"><span data-stu-id="7b73a-151">**Training simulations and Performance monitoring:** Practice and optimize the execution of tasks by identifying bottlenecks more effectively in the execution flow.</span></span>
-   <span data-ttu-id="7b73a-152">**設計評估、廣告和行銷研究：** 當您 evaluateing 網站和產品設計時, 眼追蹤是一種常用的市場研究工具。</span><span class="sxs-lookup"><span data-stu-id="7b73a-152">**Design evaluations, advertisement and marketing research:** Eye tracking is a common tool for market research when evaluateing website and product designs.</span></span>

### <a name="additional-use-cases"></a><span data-ttu-id="7b73a-153">其他使用案例</span><span class="sxs-lookup"><span data-stu-id="7b73a-153">Additional use cases</span></span>
- <span data-ttu-id="7b73a-154">**遊戲：** 想要擁有超能力嗎？</span><span class="sxs-lookup"><span data-stu-id="7b73a-154">**Gaming:** Ever wanted to have superpowers?</span></span> <span data-ttu-id="7b73a-155">機會來了！</span><span class="sxs-lookup"><span data-stu-id="7b73a-155">Here's your chance!</span></span> <span data-ttu-id="7b73a-156">您可以透過開始來 levitate 全像投影。</span><span class="sxs-lookup"><span data-stu-id="7b73a-156">You can levitate holograms by staring at them.</span></span> <span data-ttu-id="7b73a-157">您的眼睛可以發出雷射光。</span><span class="sxs-lookup"><span data-stu-id="7b73a-157">Shoot laser beams from your eyes.</span></span> <span data-ttu-id="7b73a-158">將敵人變成石頭, 或將其凍結。</span><span class="sxs-lookup"><span data-stu-id="7b73a-158">Turn enemies into stone or freeze them.</span></span> <span data-ttu-id="7b73a-159">您可以用 X 光視線掃描建築物。</span><span class="sxs-lookup"><span data-stu-id="7b73a-159">Use your x-ray vision to explore buildings.</span></span> <span data-ttu-id="7b73a-160">您想得到的都行！</span><span class="sxs-lookup"><span data-stu-id="7b73a-160">Your imagination is the limit!</span></span>  

- <span data-ttu-id="7b73a-161">**生動的虛擬人偶：** 眼睛追蹤利用即時追蹤日期來協助更具表達性的3D 虛擬人偶, 以動畫顯示使用者正在查看的內容。</span><span class="sxs-lookup"><span data-stu-id="7b73a-161">**Expressive avatars:** Eye tracking aids in more expressive 3D avatars by using live-eye tracking date to animate the avatar's eyes that indicate what the user is looking at.</span></span> <span data-ttu-id="7b73a-162">此外也可加上眨眼和瞇眼來增添表達力。</span><span class="sxs-lookup"><span data-stu-id="7b73a-162">It also adds more expressiveness by adding winks and blinks.</span></span> 

- <span data-ttu-id="7b73a-163">**文字輸入：** 眼睛追蹤可用來做為低度文字輸入的替代專案, 特別是當語音或手不方便使用時。</span><span class="sxs-lookup"><span data-stu-id="7b73a-163">**Text entry:** Eye tracking can be used as an alternative for low-effort text entry, especially when speech or hands are inconvenient to use.</span></span> 


## <a name="eye-tracking-api"></a><span data-ttu-id="7b73a-164">眼球追蹤 API</span><span class="sxs-lookup"><span data-stu-id="7b73a-164">Eye tracking API</span></span>
<span data-ttu-id="7b73a-165">在深入瞭解眼睛互動的特定設計指導方針之前, 我們想要簡要指出 HoloLens 2 眼追蹤程式 API 為開發人員提供的功能。</span><span class="sxs-lookup"><span data-stu-id="7b73a-165">Before going into detail about the specific design guidelines for eye-gaze interaction, we want to briefly point out the capabilities that the HoloLens 2 Eye Tracker API provides to developers.</span></span> <span data-ttu-id="7b73a-166">它提供了單一眼睛眼的鳥瞰原點和方向--提供大約_30 FPS_的資料。</span><span class="sxs-lookup"><span data-stu-id="7b73a-166">It provides a single eye-gaze--gaze origin and direction--providing data at approximately _30 FPS_.</span></span> 

<span data-ttu-id="7b73a-167">預測的眼睛位於 ca 內。</span><span class="sxs-lookup"><span data-stu-id="7b73a-167">The predicted eye-gaze lies within ca.</span></span> <span data-ttu-id="7b73a-168">1.0-1.5 度, 以視覺角度表示實際目標。</span><span class="sxs-lookup"><span data-stu-id="7b73a-168">1.0 - 1.5 degrees in visual angle around the actual target.</span></span> <span data-ttu-id="7b73a-169">由於預期會有些微偏差，您應為此下限預留緩衝值。</span><span class="sxs-lookup"><span data-stu-id="7b73a-169">As slight imprecisions are expected, you should plan for some margin around this lower bound value.</span></span> <span data-ttu-id="7b73a-170">這一點將在稍後詳細討論。</span><span class="sxs-lookup"><span data-stu-id="7b73a-170">We will discuss this more below.</span></span> <span data-ttu-id="7b73a-171">為了讓眼球追蹤精準運作，每個使用者都必須接受眼球追蹤使用者校正。</span><span class="sxs-lookup"><span data-stu-id="7b73a-171">For eye tracking to work accurately, each user is required to go through an eye tracking user calibration.</span></span> 

<span data-ttu-id="7b73a-172">![距離 2 公尺的最佳目標大小](images/gazetargeting-size-1000px.jpg)</span><span class="sxs-lookup"><span data-stu-id="7b73a-172">![Optimal target size at 2 meter distance](images/gazetargeting-size-1000px.jpg)</span></span><br>
<span data-ttu-id="7b73a-173">*雙計量距離的最佳目標大小*</span><span class="sxs-lookup"><span data-stu-id="7b73a-173">*Optimal target size at a 2-meter distance*</span></span>
<br>
<br>
<span data-ttu-id="7b73a-174">[眼睛追蹤 API](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.eyespose)可透過: ' EyesPose ' 存取。</span><span class="sxs-lookup"><span data-stu-id="7b73a-174">The [Eye Tracking API](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.eyespose) is accessible through: \`Windows.Perception.People.EyesPose'.</span></span> 

## <a name="eye-gaze-design-guidelines"></a><span data-ttu-id="7b73a-175">眼睛設計指導方針</span><span class="sxs-lookup"><span data-stu-id="7b73a-175">Eye-gaze design guidelines</span></span>
<span data-ttu-id="7b73a-176">要建置互動，使其利用快速移動的眼球鎖定目標，可能並不容易。</span><span class="sxs-lookup"><span data-stu-id="7b73a-176">Building an interaction that takes advantage of fast moving eye targeting can be challenging.</span></span> <span data-ttu-id="7b73a-177">在本節中, 我們將摘要說明設計應用程式時要考慮的主要優點和挑戰。</span><span class="sxs-lookup"><span data-stu-id="7b73a-177">In this section, we summarize the key advantages and challenges to take into account when designing your application.</span></span> 

### <a name="benefits-of-eye-gaze-input"></a><span data-ttu-id="7b73a-178">眼睛眼輸入的優點</span><span class="sxs-lookup"><span data-stu-id="7b73a-178">Benefits of eye-gaze input</span></span>
- <span data-ttu-id="7b73a-179">**高速指向。**</span><span class="sxs-lookup"><span data-stu-id="7b73a-179">**High speed pointing.**</span></span> <span data-ttu-id="7b73a-180">眼部肌肉是人體中反應速度最快的肌肉。</span><span class="sxs-lookup"><span data-stu-id="7b73a-180">The eye muscle is the fastest reacting muscle in our body.</span></span> 

- <span data-ttu-id="7b73a-181">**輕鬆省力。**</span><span class="sxs-lookup"><span data-stu-id="7b73a-181">**Low effort.**</span></span> <span data-ttu-id="7b73a-182">幾乎不需要任何人為動作。</span><span class="sxs-lookup"><span data-stu-id="7b73a-182">Barely any physical movements are necessary.</span></span> 

- <span data-ttu-id="7b73a-183">**隱含性。**</span><span class="sxs-lookup"><span data-stu-id="7b73a-183">**Implicitness.**</span></span> <span data-ttu-id="7b73a-184">使用者通常會將其描述為「記住閱讀」, 使用者眼移動的相關資訊可讓系統知道使用者打算參與的目標。</span><span class="sxs-lookup"><span data-stu-id="7b73a-184">Often described by users as "mind reading", information about a user's eye movements lets the system know which target the user plans to engage.</span></span> 

- <span data-ttu-id="7b73a-185">**替代輸入管道。**</span><span class="sxs-lookup"><span data-stu-id="7b73a-185">**Alternative input channel.**</span></span> <span data-ttu-id="7b73a-186">眼睛可以根據使用者的操作性協調, 提供更強大的支援輸入, 讓您能以多年來的經驗, 來建立手寫輸入。</span><span class="sxs-lookup"><span data-stu-id="7b73a-186">Eye-gaze can provide a powerful supporting input for hand and voice input building on years of experience from users based on their hand-eye coordination.</span></span>

- <span data-ttu-id="7b73a-187">**視覺注意力。**</span><span class="sxs-lookup"><span data-stu-id="7b73a-187">**Visual attention.**</span></span> <span data-ttu-id="7b73a-188">另一個重要的優點是, 推斷使用者所需注意的內容。</span><span class="sxs-lookup"><span data-stu-id="7b73a-188">Another important benefit is the possibility to infer what a user is paying attention to.</span></span> <span data-ttu-id="7b73a-189">這可協助各種應用程式領域, 範圍從更有效率地評估不同的設計, 到以更聰明的使用者介面協助, 以及強化遠端通訊的社交提示。</span><span class="sxs-lookup"><span data-stu-id="7b73a-189">This can help in various application areas ranging from more effectively evaluating different designs to aiding in smarter user interfaces and enhanced social cues for remote communication.</span></span>

<span data-ttu-id="7b73a-190">簡單地說, 使用眼睛做為輸入, 可提供快速且輕鬆的內容相關信號。</span><span class="sxs-lookup"><span data-stu-id="7b73a-190">In a nutshell, using eye-gaze as an input offers a fast and effortless contextual signal.</span></span> <span data-ttu-id="7b73a-191">這在結合其他輸入 (例如*語音*和*手動*輸入) 以確認使用者意圖時特別強大。</span><span class="sxs-lookup"><span data-stu-id="7b73a-191">This is particularly powerful when combined with other inputs such as *voice* and *manual* input to confirm the user's intent.</span></span>


### <a name="challenges-of-eye-gaze-as-an-input"></a><span data-ttu-id="7b73a-192">目視眼做為輸入的挑戰</span><span class="sxs-lookup"><span data-stu-id="7b73a-192">Challenges of eye-gaze as an input</span></span>
<span data-ttu-id="7b73a-193">有了許多功能, 有許多責任。</span><span class="sxs-lookup"><span data-stu-id="7b73a-193">With lots of power, comes lots of responsibility.</span></span>
<span data-ttu-id="7b73a-194">雖然您可以使用眼睛來建立滿足的使用者體驗, thata 讓您覺得像是 superhero, 但也請務必知道它不適合適當地考慮此情況。</span><span class="sxs-lookup"><span data-stu-id="7b73a-194">While eye-gaze can be used to create satisfying user experiences thata makes you feel like a superhero, it is also important to know what it is not good at to appropriately account for this.</span></span> <span data-ttu-id="7b73a-195">下面討論一些要納入考慮的挑戰, 以及在使用眼睛輸入時如何解決這些*問題*:</span><span class="sxs-lookup"><span data-stu-id="7b73a-195">The following discusses some *challenges* to take into account as well as how to address them when working with eye-gaze input:</span></span> 

- <span data-ttu-id="7b73a-196">**您的眼睛是「永遠開啟**」當您開啟眼睛蓋時, 您的眼會開始 fixating 環境中的事物。</span><span class="sxs-lookup"><span data-stu-id="7b73a-196">**Your eye-gaze is "always on"** The moment you open your eye lids, your eyes start fixating on things in the environment.</span></span> <span data-ttu-id="7b73a-197">回應您所做的每一種情況, 並不小心發出動作, 因為您查看太久的時間會導致回答體驗。</span><span class="sxs-lookup"><span data-stu-id="7b73a-197">Reacting to every look you make and accidentally issuing actions because you looked at something for too long would result in an unsatisfying experience.</span></span>
<span data-ttu-id="7b73a-198">這就是為什麼我們建議您結合眼睛與*語音命令*、手勢、*按鈕按一下*或擴充停留, 以觸發目標的選取。</span><span class="sxs-lookup"><span data-stu-id="7b73a-198">This is why we recommend combining eye-gaze with a *voice command*, *hand gesture*, *button click* or extended dwell to trigger the selection of a target.</span></span>
<span data-ttu-id="7b73a-199">此解決方案也可以讓使用者在因觸發某個專案時, 自由地在不被淹沒的情況下, 輕鬆地進行流覽。</span><span class="sxs-lookup"><span data-stu-id="7b73a-199">This solution also allows for a mode in which the user can freely look around without being overwhelmed by involuntarily triggering something.</span></span> <span data-ttu-id="7b73a-200">在設計單純觀看目標的視覺和聽覺反饋時，也應將此問題納入考量。</span><span class="sxs-lookup"><span data-stu-id="7b73a-200">This issue should also be taken into account when designing visual and auditory feedback when merely looking at a target.</span></span>
<span data-ttu-id="7b73a-201">不要讓即時蹦現的效果或暫留的音效干擾到使用者。</span><span class="sxs-lookup"><span data-stu-id="7b73a-201">Do not overwhelm the user with immediate pop-out effects or hover sounds.</span></span> <span data-ttu-id="7b73a-202">奧妙是索引鍵。</span><span class="sxs-lookup"><span data-stu-id="7b73a-202">Subtlety is key.</span></span> <span data-ttu-id="7b73a-203">後續我們在談到設計建議時，將進一步討論一些相關的最佳作法。</span><span class="sxs-lookup"><span data-stu-id="7b73a-203">We will discuss some best practices for this further below when talking about design recommendations.</span></span>

- <span data-ttu-id="7b73a-204">**觀察與控制項的**比較假設您想要在牆上精確地拉出相片。</span><span class="sxs-lookup"><span data-stu-id="7b73a-204">**Observation vs. control** Imagine that you want to precisely straighten a photograph on your wall.</span></span> <span data-ttu-id="7b73a-205">您檢視了相框及其周圍環境，看看是否妥善對齊。</span><span class="sxs-lookup"><span data-stu-id="7b73a-205">You look at its borders and its surroundings to see if it aligns well.</span></span> <span data-ttu-id="7b73a-206">現在想像一下當您想要使用眼睛做為移動圖片的輸入時, 該怎麼做。</span><span class="sxs-lookup"><span data-stu-id="7b73a-206">Now imagine how you would do that when you want to use your eye-gaze as an input to move the picture.</span></span> <span data-ttu-id="7b73a-207">很難對吧？</span><span class="sxs-lookup"><span data-stu-id="7b73a-207">Difficult, isn't it?</span></span> <span data-ttu-id="7b73a-208">這會說明在輸入和控制兩者都需要時, 眼睛的雙重角色。</span><span class="sxs-lookup"><span data-stu-id="7b73a-208">This describes the double role of eye-gaze when it is required both for input and control.</span></span> 

- <span data-ttu-id="7b73a-209">**在點按前即移開目光：** 針對快速目標的選擇, 研究顯示使用者的眼睛可以在結束手動按一下之前繼續進行 (例如, airtap)。</span><span class="sxs-lookup"><span data-stu-id="7b73a-209">**Leave before click:** For quick target selections, research has shown that a user's eye-gaze can move on before concluding a manual click (e.g., an airtap).</span></span> <span data-ttu-id="7b73a-210">因此, 必須特別注意, 才能同步處理使用速度較慢之控制項輸入 (例如語音、手、控制器) 的快速監看式信號。</span><span class="sxs-lookup"><span data-stu-id="7b73a-210">Hence, special attention must be paid to synchronizing the fast eye-gaze signal with slower control input (e.g., voice, hands, controller).</span></span>

- <span data-ttu-id="7b73a-211">**小型目標：** 當您嘗試閱讀的文字太小而難以閱讀時, 您是否知道覺得？</span><span class="sxs-lookup"><span data-stu-id="7b73a-211">**Small targets:** Do you know the feeling when you try to read text that is just a bit too small to read comfortable?</span></span> <span data-ttu-id="7b73a-212">這對您的看法感到滿意, 會導致您感到厭倦並磨損, 因為您嘗試重新調整眼睛, 使其更專注于焦點。</span><span class="sxs-lookup"><span data-stu-id="7b73a-212">This straining feeling on your eyes can cause you to feel tired and worn out because you try to readjust your eyes to focus better.</span></span>
<span data-ttu-id="7b73a-213">當您想要在您的應用程式中使用目視目標來選取太小的目標時, 您可能會在使用者中叫用這項功能。</span><span class="sxs-lookup"><span data-stu-id="7b73a-213">This is a feeling you might invoke in your users when forcing them to select targets that are too small in your application using eye targeting.</span></span>
<span data-ttu-id="7b73a-214">您的設計若要為使用者營造出愉快而舒適的體驗，我們建議目標的視角至少應為 2°，最好是更大。</span><span class="sxs-lookup"><span data-stu-id="7b73a-214">For your design, to create a pleasant and comfortable experience for your users, we recommend that targets should be at least 2° in visual angle, preferably larger.</span></span>

- <span data-ttu-id="7b73a-215">不**齊整眼的移動**我們的眼睛會快速從 fixation 到 fixation 的移動。</span><span class="sxs-lookup"><span data-stu-id="7b73a-215">**Ragged eye-gaze movements** Our eyes perform rapid movements from fixation to fixation.</span></span> <span data-ttu-id="7b73a-216">如果您記錄眼球移動的掃描路徑，並加以檢視，您會發現它們呈現為不規則的路徑。</span><span class="sxs-lookup"><span data-stu-id="7b73a-216">If you look at scan paths of recorded eye movements, you can see that they look ragged.</span></span> <span data-ttu-id="7b73a-217">相較於*頭部目光*或*手部動作*，眼球移動的速度較快，且同時會跳躍。</span><span class="sxs-lookup"><span data-stu-id="7b73a-217">Your eyes move quickly and in spontaneous jumps in comparison to *head gaze* or *hand motions*.</span></span>  

- <span data-ttu-id="7b73a-218">**追蹤可靠性：** 眼球追蹤的精確度可能因光線的變化而略為下降，因為您的眼球必須適應新環境。</span><span class="sxs-lookup"><span data-stu-id="7b73a-218">**Tracking reliability:** Eye tracking accuracy may degrade a little in changing light as your eye adjust to the new conditions.</span></span>
<span data-ttu-id="7b73a-219">雖然這不一定會影響您的應用程式設計, 因為精確度應該在2限制內, 所以使用者可能需要執行另一個校正。</span><span class="sxs-lookup"><span data-stu-id="7b73a-219">While this should not necessarily affect your application design, as the accuracy should be within the 2° limitation, i might be necessary for the user to run another calibration.</span></span> 


## <a name="design-recommendations"></a><span data-ttu-id="7b73a-220">設計建議</span><span class="sxs-lookup"><span data-stu-id="7b73a-220">Design recommendations</span></span>
<span data-ttu-id="7b73a-221">以下是根據眼睛輸入所述的優點和挑戰, 列出特定設計建議的清單:</span><span class="sxs-lookup"><span data-stu-id="7b73a-221">The following is a list of specific design recommendations based on the described advantages and challenges for eye-gaze input:</span></span>

1. <span data-ttu-id="7b73a-222">**眼睛眼! = Head 注視:**</span><span class="sxs-lookup"><span data-stu-id="7b73a-222">**Eye-gaze != Head-gaze:**</span></span>
    - <span data-ttu-id="7b73a-223">**請考量快速但不規則的眼球移動是否適用於您的輸入工作：** 雖然我們快速且不齊眼的移動非常適合在我們的視野範圍 (FoV) 上快速選取目標, 但較不適用於需要平滑輸入軌跡 (例如繪製或 encircling 注釋) 的工作。</span><span class="sxs-lookup"><span data-stu-id="7b73a-223">**Consider whether fast yet ragged eye movements fit your input task:** While our fast and ragged eye movements are great at quickly selecting targets across our field of view (FoV), it is less applicable for tasks that require smooth input trajectories (e.g., drawing or encircling annotations).</span></span> <span data-ttu-id="7b73a-224">在此情況下，手部或頭部指向應該較為合用。</span><span class="sxs-lookup"><span data-stu-id="7b73a-224">In this case, hand or head pointing should be preferred.</span></span>
  
    - <span data-ttu-id="7b73a-225">**避免直接將某個專案附加至使用者的眼睛 (例如滑杆或游標)。**</span><span class="sxs-lookup"><span data-stu-id="7b73a-225">**Avoid attaching something directly to the user’s eye-gaze (e.g., a slider or cursor).**</span></span>
<span data-ttu-id="7b73a-226">如果是游標, 這可能會造成「fleeing 游標」的效果, 這是因為投射眼信號的輕微位移。</span><span class="sxs-lookup"><span data-stu-id="7b73a-226">In case of a cursor, this may result in the “fleeing cursor” effect due to slight offsets in the projected eye-gaze signal.</span></span> <span data-ttu-id="7b73a-227">在滑杆的情況下, 它可能會與使用您的眼睛控制滑杆的雙重角色發生衝突, 同時也想要檢查物件是否在正確的位置。</span><span class="sxs-lookup"><span data-stu-id="7b73a-227">In case of a slider, it can conflict with the double role of controlling the slider with your eyes while also wanting to check whether the object is at the correct location.</span></span> <span data-ttu-id="7b73a-228">簡單地說, 使用者可能會變得很龐大, 而且會被淹沒, 特別是如果該使用者的信號不精確。</span><span class="sxs-lookup"><span data-stu-id="7b73a-228">In a nutshell, users could become overwhelmed and distracted, especially if the signal is imprecise for that user.</span></span> 
  
2. <span data-ttu-id="7b73a-229">**結合眼睛與其他輸入:** 目視追蹤與其他輸入的整合, 例如手勢、語音命令或按鈕按下, 有幾個優點:</span><span class="sxs-lookup"><span data-stu-id="7b73a-229">**Combine eye-gaze with other inputs:** The integration of eye tracking with other inputs, such as hand gestures, voice commands or button presses, serves several advantages:</span></span>
    - <span data-ttu-id="7b73a-230">**允許隨意觀看：** 假設我們眼的主要角色是要觀察我們的環境, 很重要的是, 使用者不需要觸發任何 (視覺、聽覺等) 意見或動作, 就能進行查詢。</span><span class="sxs-lookup"><span data-stu-id="7b73a-230">**Allow for free observation:** Given that the main role of our eyes is to observe our environment, it is important users are allowed to look around without triggering any (visual, auditory, etc.) feedback or actions.</span></span> 
    <span data-ttu-id="7b73a-231">將眼睛追蹤與另一個輸入控制項結合, 可讓您在眼睛追蹤觀察和輸入控制項模式之間順暢地轉換。</span><span class="sxs-lookup"><span data-stu-id="7b73a-231">Combining eye tracking with another input control allows smooth transitioning between eye tracking observation and input control modes.</span></span>
  
    - <span data-ttu-id="7b73a-232">**強大的內容提供者：** 使用有關使用者在 uttering 語音命令或執行手勢時所查看之位置和內容的資訊, 可讓您順暢地將此整個現場的輸入。</span><span class="sxs-lookup"><span data-stu-id="7b73a-232">**Powerful context provider:** Using information about where and what the user is looking at while uttering a voice command or performing a hand gesture allows seamlessly channeling the input across the field-of-view.</span></span> <span data-ttu-id="7b73a-233">例如: 「把它放在那裡」可讓您快速流暢地在場景內選取並放置全像投影，只需依序看著目標和目的地即可。</span><span class="sxs-lookup"><span data-stu-id="7b73a-233">For example: “Put that there” to quickly and fluently select and position a hologram across the scene by simply looking at a target and destination.</span></span> 

    - <span data-ttu-id="7b73a-234">**多種樣式的輸入間必須同步 (「在點按前即移開目光」的問題)：** 將快速監看式與更複雜的其他輸入結合, 例如長時間的語音命令或手勢, 在完成額外的輸入命令之前, 會帶來繼續留意的風險。</span><span class="sxs-lookup"><span data-stu-id="7b73a-234">**Need for synchronizing multimodal inputs (“leave before click” issue):** Combining rapid eye movements with more complex additional inputs, such as long voice commands or hand gestures, bears the risk of continuing your eye-gaze before finishing the additional input command.</span></span> <span data-ttu-id="7b73a-235">因此，如果您自行建立輸入控制項 (例如自訂手勢)，請務必記錄此輸入的開端或約略的持續時間，並將其與使用者過去的關注標的產生關聯。</span><span class="sxs-lookup"><span data-stu-id="7b73a-235">Hence, if you create your own input controls (e.g., custom hand gestures), make sure to log the onset of this input or approximate duration to correlate it with what a user had fixated on in the past.</span></span>
    
3. <span data-ttu-id="7b73a-236">**眼球追蹤輸入的微妙反饋：** 當目標查看以指出系統正如預期方式運作時, 提供意見反應很有用, 但應該保持細微。</span><span class="sxs-lookup"><span data-stu-id="7b73a-236">**Subtle feedback for eye tracking input:** It's useful to provide feedback when a target is looked at to indicate that the system is working as intended, but should be kept subtle.</span></span> <span data-ttu-id="7b73a-237">這可能包括緩慢的混合、進出、視覺效果反白顯示或執行其他細微的目標行為, 例如緩慢的動作, 例如稍微增加目標, 表示系統已正確偵測到使用者正在查看目標, 但沒有不必要地中斷使用者目前的工作流程。</span><span class="sxs-lookup"><span data-stu-id="7b73a-237">This can include slowly blending, in and out, visual highlights or perform other subtle target behaviors, such as slow motions, such as slightly increasing the target, to indicate that the system correctly detected that the user is looking at a target without unnecessarily interrupting the user’s current workflow.</span></span> 

4. <span data-ttu-id="7b73a-238">**避免以不自然的眼球移動進行輸入：** 請勿強制使用者執行特定的眼睛移動 (注視手勢) 來觸發應用程式中的動作。</span><span class="sxs-lookup"><span data-stu-id="7b73a-238">**Avoid enforcing unnatural eye movements as input:** Do not force users to perform specific eye movements (gaze gestures) to trigger actions in your application.</span></span>

5. <span data-ttu-id="7b73a-239">**處理不精確的問題：** 我們會區分對使用者而言很明顯的兩種 imprecisions 類型: [位移] 和 [抖動]。</span><span class="sxs-lookup"><span data-stu-id="7b73a-239">**Account for imprecisions:** We distinguish two types of imprecisions which are noticeable to users: offset and jitter.</span></span> <span data-ttu-id="7b73a-240">解決位移最簡單的方式, 就是提供夠大的目標來與互動。</span><span class="sxs-lookup"><span data-stu-id="7b73a-240">The easiest way to address an offset is to provide sufficiently large targets to interact with.</span></span> <span data-ttu-id="7b73a-241">建議您使用大於2°的視覺角度做為參考。</span><span class="sxs-lookup"><span data-stu-id="7b73a-241">It is suggested that you use a visual angle greater than 2° as a reference.</span></span> <span data-ttu-id="7b73a-242">例如, 當您延展 arm 時, 縮圖大約是視覺角度的2°。</span><span class="sxs-lookup"><span data-stu-id="7b73a-242">For instance, your thumbnail is about 2° in visual angle when you stretch out your arm.</span></span> <span data-ttu-id="7b73a-243">據此我們提供下列指導方針：</span><span class="sxs-lookup"><span data-stu-id="7b73a-243">This leads to the following guidance:</span></span>
    - <span data-ttu-id="7b73a-244">請勿強制使用者選取 [小型目標]。</span><span class="sxs-lookup"><span data-stu-id="7b73a-244">Do not force users to select tiny targets.</span></span> <span data-ttu-id="7b73a-245">研究顯示, 如果目標夠大, 而且系統的設計良好, 使用者就可以輕鬆且神奇地描述其互動。</span><span class="sxs-lookup"><span data-stu-id="7b73a-245">Research has shown that if targets are sufficiently large, and that the system is designed well, users describe their interactions as effortless and magical.</span></span> <span data-ttu-id="7b73a-246">如果目標太小，則使用者會反映體驗令人疲累又洩氣。</span><span class="sxs-lookup"><span data-stu-id="7b73a-246">If targets become too small, users describe the experience as fatiguing and frustrating.</span></span>
   

## <a name="see-also"></a><span data-ttu-id="7b73a-247">另請參閱</span><span class="sxs-lookup"><span data-stu-id="7b73a-247">See also</span></span>
* [<span data-ttu-id="7b73a-248">頭部目光和行動</span><span class="sxs-lookup"><span data-stu-id="7b73a-248">Head-gaze and commit</span></span>](gaze-and-commit.md)
* [<span data-ttu-id="7b73a-249">DirectX 中的 Head 和眼睛</span><span class="sxs-lookup"><span data-stu-id="7b73a-249">Head and eye-gaze in DirectX</span></span>](gaze-in-directx.md)
* [<span data-ttu-id="7b73a-250">Unity 中的眼睛 (混合現實工具組)</span><span class="sxs-lookup"><span data-stu-id="7b73a-250">Eye-gaze in Unity (Mixed Reality Toolkit)</span></span>](https://aka.ms/mrtk-eyes)
* [<span data-ttu-id="7b73a-251">手勢</span><span class="sxs-lookup"><span data-stu-id="7b73a-251">Hand gestures</span></span>](gestures.md)
* [<span data-ttu-id="7b73a-252">語音輸入</span><span class="sxs-lookup"><span data-stu-id="7b73a-252">Voice input</span></span>](voice-design.md)
* [<span data-ttu-id="7b73a-253">運動控制器</span><span class="sxs-lookup"><span data-stu-id="7b73a-253">Motion controllers</span></span>](motion-controllers.md)
* [<span data-ttu-id="7b73a-254">舒適度</span><span class="sxs-lookup"><span data-stu-id="7b73a-254">Comfort</span></span>](comfort.md)
