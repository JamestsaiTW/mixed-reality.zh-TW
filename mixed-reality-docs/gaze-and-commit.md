---
title: 頭部注視並認可
description: 頭部注視並認可輸入模型的概觀
author: caseymeekhof
ms.author: cmeekhof
ms.date: 03/31/2019
ms.topic: article
ms.localizationpriority: high
keywords: Mixed Reality, 注視, 注視定向, 互動, 設計
ms.openlocfilehash: d9eae3c0cfceba7c2c31425941dfce865f3aa609
ms.sourcegitcommit: f20beea6a539d04e1d1fc98116f7601137eebebe
ms.translationtype: HT
ms.contentlocale: zh-TW
ms.lasthandoff: 06/05/2019
ms.locfileid: "66692309"
---
# <a name="head-gaze-and-commit"></a><span data-ttu-id="8dbf9-104">頭部注視並認可</span><span class="sxs-lookup"><span data-stu-id="8dbf9-104">Head-gaze and commit</span></span>
<span data-ttu-id="8dbf9-105">「頭部注視並認可」是一種輸入模型，其涉及以頭部向前指的方向 (頭部方向) 瞄準物件，然後以次要輸入 (例如空中點選手勢或語音命令 "Select") 產生作用。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-105">Head-gaze and commit is an input model that involves targeting an object with the direction of your head pointing forward (head-direction), and then acting on it with a secondary input such as the hand gesture Air Tap or the voice command “Select”.</span></span> <span data-ttu-id="8dbf9-106">我們將其視為間接操作的「遠距」輸入模型，這表示它最適合用於伸手可及範圍內的內容互動。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-106">It is considered a "far" input model with indirect manipulation, meaning it is best used for interacting with content that is beyond arms reach.</span></span>

## <a name="device-support"></a><span data-ttu-id="8dbf9-107">裝置支援</span><span class="sxs-lookup"><span data-stu-id="8dbf9-107">Device support</span></span>

<table>
    <colgroup>
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    </colgroup>
    <tr>
        <td><span data-ttu-id="8dbf9-108"><strong>輸入模型</strong></span><span class="sxs-lookup"><span data-stu-id="8dbf9-108"><strong>Input model</strong></span></span></td>
        <td><span data-ttu-id="8dbf9-109"><a href="hololens-hardware-details.md"><strong>HoloLens (第 1 代)</strong></a></span><span class="sxs-lookup"><span data-stu-id="8dbf9-109"><a href="hololens-hardware-details.md"><strong>HoloLens (1st gen)</strong></a></span></span></td>
        <td><span data-ttu-id="8dbf9-110"><strong>HoloLens 2</strong></span><span class="sxs-lookup"><span data-stu-id="8dbf9-110"><strong>HoloLens 2</strong></span></span></td>
        <td><span data-ttu-id="8dbf9-111"><a href="immersive-headset-hardware-details.md"><strong>沉浸式頭戴裝置</strong></a></span><span class="sxs-lookup"><span data-stu-id="8dbf9-111"><a href="immersive-headset-hardware-details.md"><strong>Immersive headsets</strong></a></span></span></td>
    </tr>
     <tr>
        <td><span data-ttu-id="8dbf9-112">頭部注視並認可</span><span class="sxs-lookup"><span data-stu-id="8dbf9-112">Head-gaze and commit</span></span></td>
        <td><span data-ttu-id="8dbf9-113">✔️ 建議使用</span><span class="sxs-lookup"><span data-stu-id="8dbf9-113">✔️ Recommended</span></span></td>
        <td><span data-ttu-id="8dbf9-114">✔️ 建議使用 (第三個選擇 - <a href="interaction-fundamentals.md">查看其他選項</a>)</span><span class="sxs-lookup"><span data-stu-id="8dbf9-114">✔️ Recommended (third choice - <a href="interaction-fundamentals.md">See the other options</a>)</span></span></td>
        <td><span data-ttu-id="8dbf9-115">➕ 替代選項</span><span class="sxs-lookup"><span data-stu-id="8dbf9-115">➕ Alternate option</span></span></td>
    </tr>
</table>

## <a name="head-gaze"></a><span data-ttu-id="8dbf9-116">頭部注視</span><span class="sxs-lookup"><span data-stu-id="8dbf9-116">Head-gaze</span></span>
<span data-ttu-id="8dbf9-117">混合實境頭戴式裝置使用使用者頭部的位置和方向來判斷其頭部方向向量。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-117">Mixed reality headsets use the position and orientation of the user's head to determine their head direction vector.</span></span> <span data-ttu-id="8dbf9-118">您可以將此視為直接從使用者的雙眼之間向前直指的雷射。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-118">You can think of this as a laser that points straight ahead from directly between the user's eyes.</span></span> <span data-ttu-id="8dbf9-119">這是相當粗略的使用者觀看位置概算。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-119">This is a fairly coarse approximation of where the user is looking.</span></span> <span data-ttu-id="8dbf9-120">您的應用程式可以讓此射線與虛擬或實際物件相交並在該位置繪製游標，讓使用者知道他們目前所定向的目標。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-120">Your application can intersect this ray with virtual or real-world objects and draw a cursor at that location to let the user know what they are currently targeting.</span></span>

<span data-ttu-id="8dbf9-121">除了頭部注視以外，有些混合實境頭戴式裝置 (例如 HoloLens 2) 包含可產生眼部注視向量的眼動追蹤系統。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-121">In addition to head gaze, some mixed reality headsets like the HoloLens 2 include eye tracking systems that produce an eye-gaze vector.</span></span> <span data-ttu-id="8dbf9-122">這會對使用者觀看的位置提供精細的測量。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-122">This provides a fine-grained measurement of where the user is looking.</span></span> <span data-ttu-id="8dbf9-123">使用眼部注視可以建立注視並認可互動，但這伴隨著一組非常不同的設計限制，其將會分別涵蓋於[眼動追蹤文章](eye-tracking.md)中。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-123">It is possible to build gaze and commit interactions using eye gaze, but this comes with a very different set of design constraints, which will be covered separately in the [eye tracking article](eye-tracking.md).</span></span>

## <a name="commit"></a><span data-ttu-id="8dbf9-124">認可</span><span class="sxs-lookup"><span data-stu-id="8dbf9-124">Commit</span></span>
<span data-ttu-id="8dbf9-125">瞄準物件或 UI 元素之後，使用者可以使用次要輸入進行互動或「按一下」。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-125">After targeting an object or UI element, the user can interact or "click" on it using a secondary input.</span></span> <span data-ttu-id="8dbf9-126">這也稱為模型的認可步驟。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-126">This is known as the commit step of the model.</span></span> <span data-ttu-id="8dbf9-127">支援的認可方法如下：</span><span class="sxs-lookup"><span data-stu-id="8dbf9-127">The following commit methods are supported:</span></span>

- <span data-ttu-id="8dbf9-128">空中點選手勢</span><span class="sxs-lookup"><span data-stu-id="8dbf9-128">Air Tap gesture</span></span>
- <span data-ttu-id="8dbf9-129">說出語音命令 "Select"，或其中一個目標式語音命令</span><span class="sxs-lookup"><span data-stu-id="8dbf9-129">Speak the voice command "Select" or one of the targeted voice commands</span></span>
- <span data-ttu-id="8dbf9-130">按下 [HoloLens Clicker](hardware-accessories.md#hololens-clicker) 上的單一按鈕</span><span class="sxs-lookup"><span data-stu-id="8dbf9-130">Press the single button on a [HoloLens Clicker](hardware-accessories.md#hololens-clicker)</span></span>
- <span data-ttu-id="8dbf9-131">按下 Xbox Gamepad 上的 'A' 按鈕</span><span class="sxs-lookup"><span data-stu-id="8dbf9-131">Press the 'A' button on an Xbox Gamepad</span></span>
- <span data-ttu-id="8dbf9-132">按下 Xbox Adaptive Controller 上的 'A' 按鈕</span><span class="sxs-lookup"><span data-stu-id="8dbf9-132">Press the 'A' button on an Xbox Adaptive Controller</span></span>

### <a name="head-gaze-and-air-tap-gesture"></a><span data-ttu-id="8dbf9-133">頭部注視和空中點選手勢</span><span class="sxs-lookup"><span data-stu-id="8dbf9-133">Head-gaze and air tap gesture</span></span>
<span data-ttu-id="8dbf9-134">空中點選是手部直立的點選手勢。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-134">Air tap is a tapping gesture with the hand held upright.</span></span> <span data-ttu-id="8dbf9-135">若要執行空中點選，舉起食指朝向就緒位置，然後搭配拇指捏合並提起食指放開。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-135">To perform an Air tap, raise your index finger to the ready position, then pinch with your thumb and raise your index finger back up to release.</span></span> <span data-ttu-id="8dbf9-136">在 HoloLens 1 上，空中點選是最常見的次要輸入。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-136">On HoloLens 1, Air tap is the most common secondary input.</span></span>

![將手指放在就緒位置，然後點選或按一下移動](images/readyandpress.jpg)<br>

<span data-ttu-id="8dbf9-138">空中點選也適用於 HoloLens 2，它已從原始版本放寬。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-138">Air tap is also available on HoloLens 2, and it has been relaxed from the original version.</span></span> <span data-ttu-id="8dbf9-139">現在支援幾乎所有類型的捏合動作，只要手部直立並保持靜止。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-139">Nearly all types of pinches are now supported, as long as the hand is upright and holding still.</span></span> <span data-ttu-id="8dbf9-140">這可讓使用者更容易了解和執行手勢。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-140">This makes it much easier for users to learn and perform the gesture.</span></span>  <span data-ttu-id="8dbf9-141">這項新的空中點選透過相同的 API 取代舊的空中點選，所以現有應用程式會在針對 HoloLens 2 重新編譯之後自動取得新行為。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-141">This new Air tap replaces the old one through the same API, so existing applications will get the new behavior automatically after recompiling for HoloLens 2.</span></span>

### <a name="head-gaze-and-select-voice-command"></a><span data-ttu-id="8dbf9-142">頭部注視和 "Select" 語音命令</span><span class="sxs-lookup"><span data-stu-id="8dbf9-142">Head-gaze and "Select" voice command</span></span>
<span data-ttu-id="8dbf9-143">語音命令是 Mixed Reality 上其中一種主要互動方法。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-143">Voice commanding is one of the primary interaction methods on Mixed Reality.</span></span> <span data-ttu-id="8dbf9-144">它提供非常強大的「免持式」機制來控制系統。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-144">It provides a very powerful "Hands Free" mechanism to control the system.</span></span> <span data-ttu-id="8dbf9-145">語音互動模型有不同的類型：</span><span class="sxs-lookup"><span data-stu-id="8dbf9-145">There are diferent types of voice interaction models:</span></span>

- <span data-ttu-id="8dbf9-146">一般命令 "Select"，可允許執行 [按一下] 行動或作為次要輸入認可。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-146">The generic command "Select" that allows to perform a "click" actuation or commit as a secondary input.</span></span>
- <span data-ttu-id="8dbf9-147">「關閉」或「放大」等物件命令，可允許執行並作為次要輸入認可至動作。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-147">Object commands like "Close" or "Make it bigger" that allow to perform and commit to an action as a secondary input.</span></span>
- <span data-ttu-id="8dbf9-148">「立即開始」等不需要目標的全域命令。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-148">Global commnads like "Go to start" that don't require a target.</span></span>
- <span data-ttu-id="8dbf9-149">具有 AI 自然語言功能的交談使用者介面或實體 (例如 Cortana)。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-149">Conversation user interfaces or entities like Cortana that have an AI Natural Language capability.</span></span>
- <span data-ttu-id="8dbf9-150">自訂命令</span><span class="sxs-lookup"><span data-stu-id="8dbf9-150">Custom commnads</span></span>

<span data-ttu-id="8dbf9-151">若要尋找更多詳細資料和可用命令完整清單以及其使用方式，請查看我們的[語音命令](voice-design.md)指引。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-151">To find more details and a comprenhesive list of available commands and how to use, check out our [voice commanding](voice-design.md) guidance.</span></span>


### <a name="head-gaze-and-hololens-clicker"></a><span data-ttu-id="8dbf9-152">頭部注視和 HoloLens Clicker</span><span class="sxs-lookup"><span data-stu-id="8dbf9-152">Head-gaze and HoloLens Clicker</span></span>
<span data-ttu-id="8dbf9-153">HoloLens Clicker 是專為 HoloLens 建置的第一個周邊裝置且隨附於 HoloLens 1 Development Edition。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-153">The HoloLens Clicker is the first peripheral device built specifically for HoloLens and is included with the HoloLens 1 Development Edition.</span></span> <span data-ttu-id="8dbf9-154">HoloLens Clicker 可讓使用者以最少手動動作按一下，並認可為次要輸入。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-154">The HoloLens Clicker allows a user to click with minimal hand motion and commit as a secondary input.</span></span> <span data-ttu-id="8dbf9-155">HoloLens Clicker 會使用藍牙低能源 (BTLE) 連線到 HoloLens 1 或 2。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-155">The HoloLens clicker connects to the HoloLens 1 or 2 using Bluetooth Low Energy (BTLE).</span></span>

<span data-ttu-id="8dbf9-156">![HoloLens Clicker](images/hololens-clicker-500px.jpg)</span><span class="sxs-lookup"><span data-stu-id="8dbf9-156">![HoloLens Clicker](images/hololens-clicker-500px.jpg)</span></span><br>
<span data-ttu-id="8dbf9-157">*HoloLens Clicker*</span><span class="sxs-lookup"><span data-stu-id="8dbf9-157">*HoloLens Clicker*</span></span>

<span data-ttu-id="8dbf9-158">您可以在[這裡](hardware-accessories.md#pairing-bluetooth-accessories)找到裝置配對的詳細資訊和指示。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-158">More information and instructions to pair the device can be found [here](hardware-accessories.md#pairing-bluetooth-accessories)</span></span>




### <a name="head-gaze-and-xbox-wireless-controller"></a><span data-ttu-id="8dbf9-159">頭部注視和 Xbox 無線控制器</span><span class="sxs-lookup"><span data-stu-id="8dbf9-159">Head-gaze and Xbox Wireless Controller</span></span>
<span data-ttu-id="8dbf9-160">Xbox 無線控制器允許使用 A 按鈕來執行 [按一下] 行動作為次要輸入。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-160">The Xbox Wireless Controller allows to perform a "click" actuation as a secondary input by using the A button.</span></span> <span data-ttu-id="8dbf9-161">裝置會對應至一組預設動作，協助您導覽和控制系統。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-161">The device is mapped to a default set of actions that help navigate and controll the system.</span></span> <span data-ttu-id="8dbf9-162">如果您想要自訂控制器，請使用 Xbox Accesories 應用程式來設定 Xbox 無線控制器。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-162">If you want to customize the controller, use the Xbox Accesories App to configure your Xbox Wireless Controller.</span></span>

<span data-ttu-id="8dbf9-163">![Xbox 無線控制器](images/xboxcontroller.jpg)</span><span class="sxs-lookup"><span data-stu-id="8dbf9-163">![Xbox Wireless Controller](images/xboxcontroller.jpg)</span></span><br>
<span data-ttu-id="8dbf9-164">*Xbox 無線控制器*</span><span class="sxs-lookup"><span data-stu-id="8dbf9-164">*Xbox Wireless Controller*</span></span>

[<span data-ttu-id="8dbf9-165">將 Xbox 控制器與您的電腦配對</span><span class="sxs-lookup"><span data-stu-id="8dbf9-165">Pairing an Xbox controller with your PC</span></span>](hardware-accessories.md#pairing-bluetooth-accessories)


### <a name="head-gaze-and-xbox-adaptive-controller"></a><span data-ttu-id="8dbf9-166">頭部注視和 Xbox Adaptive Controller</span><span class="sxs-lookup"><span data-stu-id="8dbf9-166">Head-gaze and Xbox Adaptive Controller</span></span>
<span data-ttu-id="8dbf9-167">Xbox Adaptive Controller 是裝置的統一中樞，有助於更方便存取 Mixed Reality，其主要設計訴求是要透過有限的行動性來符合玩家的需求。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-167">Designed primarily to meet the needs of gamers with limited mobility, the Xbox Adaptive Controller is a unified hub for devices that helps make Mixed Reality more accessible.</span></span>

<span data-ttu-id="8dbf9-168">Xbox Adaptive Controller 允許使用 A 按鈕來執行 [按一下] 行動作為次要輸入。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-168">The Xbox Adaptive Controller allows to perform a "click" actuation as a secondary input by using the A button.</span></span> <span data-ttu-id="8dbf9-169">裝置會對應至一組預設動作，協助您導覽和控制系統。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-169">The device is mapped to a default set of actions that help navigate and controll the system.</span></span> <span data-ttu-id="8dbf9-170">如果您想要自訂控制器，請使用 Xbox Accesories 應用程式來設定 Xbox Adaptive Controller。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-170">If you want to customize the controller, use the Xbox Accesories App to configure your Xbox Adaptive Controller.</span></span>

<span data-ttu-id="8dbf9-171">![Xbox Adaptive Controller](images/xbox-adaptive-controller-devices.jpg)</span><span class="sxs-lookup"><span data-stu-id="8dbf9-171">![Xbox Adaptive Controller](images/xbox-adaptive-controller-devices.jpg)</span></span><br>
<span data-ttu-id="8dbf9-172">*Xbox Adaptive Controller*</span><span class="sxs-lookup"><span data-stu-id="8dbf9-172">*Xbox Adaptive Controller*</span></span>

<span data-ttu-id="8dbf9-173">連接外部裝置 (例如開關、按鈕、底座和搖桿)，建立您專屬的自訂控制站體驗。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-173">Connect external devices such as switches, buttons, mounts, and joysticks to create a custom controllers experience that is uniquely yours.</span></span> <span data-ttu-id="8dbf9-174">按鈕、搖桿和觸發器輸入都是使用透過 3.5mm 插口與 USB 連接埠連線的輔助裝置控制。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-174">Button, thumbstick and trigger inputs are controlled with assistive devices connected through 3.5mm jacks and USB ports.</span></span>

<span data-ttu-id="8dbf9-175">![Xbox Adaptive Controller 連接埠](images/xbox-adaptive-controller-ports.jpg)</span><span class="sxs-lookup"><span data-stu-id="8dbf9-175">![Xbox Adaptive Controller ports](images/xbox-adaptive-controller-ports.jpg)</span></span><br>
<span data-ttu-id="8dbf9-176">*Xbox Adaptive Controller 連接埠*</span><span class="sxs-lookup"><span data-stu-id="8dbf9-176">*Xbox Adaptive Controller ports*</span></span>

[<span data-ttu-id="8dbf9-177">裝置配對指示</span><span class="sxs-lookup"><span data-stu-id="8dbf9-177">Instructions to pair the device</span></span>](hardware-accessories.md#pairing-bluetooth-accessories)

<span data-ttu-id="8dbf9-178"><a href=https://www.xbox.com/en-US/xbox-one/accessories/controllers/xbox-adaptive-controller>在 Xbox 網站上可取得更多資訊</a></span><span class="sxs-lookup"><span data-stu-id="8dbf9-178"><a href=https://www.xbox.com/en-US/xbox-one/accessories/controllers/xbox-adaptive-controller>More info available on the Xbox site</a></span></span>


## <a name="design-guidelines"></a><span data-ttu-id="8dbf9-179">設計指導方針</span><span class="sxs-lookup"><span data-stu-id="8dbf9-179">Design guidelines</span></span>
> [!NOTE]
> <span data-ttu-id="8dbf9-180">[即將推出](index.md)注視設計專屬的詳細指引。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-180">More guidance specific to gaze design [coming soon](index.md).</span></span>

## <a name="head-gaze-targeting"></a><span data-ttu-id="8dbf9-181">頭部注視定向</span><span class="sxs-lookup"><span data-stu-id="8dbf9-181">Head-gaze targeting</span></span>
<span data-ttu-id="8dbf9-182">無論輸入形式為何，當使用者能夠瞄準他們想要進行互動的元素時，所有互動就已建立。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-182">All interactions are built upon the ability of a user to target the element they want to interact with, regardless of the input modality.</span></span> <span data-ttu-id="8dbf9-183">在 Windows Mixed Reality 中，這通常會使用使用者的注視進行。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-183">In Windows Mixed Reality, this is generally done using the user's gaze.</span></span>
<span data-ttu-id="8dbf9-184">若要讓使用者能夠順利體驗，系統導出的使用者意圖理解，以及使用者的實際意圖都必須儘可能相吻合。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-184">To enable a user to work with an experience successfully, the system's calculated understanding of a user's intent, and the user's actual intent, must align as closely as possible.</span></span> <span data-ttu-id="8dbf9-185">系統儘可能正確解譯使用者的預定動作，所以滿意度提升且效能改善。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-185">To the degree that the system interprets the user's intended actions correctly, satisfaction increases and performance improves.</span></span>


## <a name="target-sizing-and-feedback"></a><span data-ttu-id="8dbf9-186">目標大小調整和回饋</span><span class="sxs-lookup"><span data-stu-id="8dbf9-186">Target sizing and feedback</span></span>
<span data-ttu-id="8dbf9-187">雖已重複表示注視向量可用於細微定向，但通常最適合用於粗略定向 (取得較大的目標)。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-187">The gaze vector has been shown repeatedly to be usable for fine targeting, but often works best for gross targeting (acquiring somewhat larger targets).</span></span> <span data-ttu-id="8dbf9-188">在大部分情況下，1 到 1.5 度的最小目標大小應可達成成功的使用者動作，但是 3 度的目標通常可讓速度提升。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-188">Minimum target sizes of 1 to 1.5 degrees should allow successful user actions in most scenarios, though targets of 3 degrees often allow for greater speed.</span></span> <span data-ttu-id="8dbf9-189">請注意，使用者定向的大小實際上是 2D 區域 (即使是 3D 元素)，無論哪個投影面向他們都應該是可作為目標的區域。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-189">Note that the size that the user targets is effectively a 2D area even for 3D elements--whichever projection is facing them should be the targetable area.</span></span> <span data-ttu-id="8dbf9-190">提供元素為「作用中」(使用者以其為目標) 的一些明顯線索非常有用 - 這可能包括視覺「暫留」效果、音訊醒目提示或點按，或游標與元素的清楚比對等處理。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-190">Providing some salient cue that an element is "active" (that the user is targeting it) is extremely helpful - this can include treatments like visible "hover" effects, audio highlights or clicks, or clear alignment of a cursor with an element.</span></span>

<span data-ttu-id="8dbf9-191">![2 個計量表距離的最佳目標大小](images/gazetargeting-size-1000px.jpg)</span><span class="sxs-lookup"><span data-stu-id="8dbf9-191">![Optimal target size at 2 meter distance](images/gazetargeting-size-1000px.jpg)</span></span><br>
<span data-ttu-id="8dbf9-192">*2 個計量表距離的最佳目標大小*</span><span class="sxs-lookup"><span data-stu-id="8dbf9-192">*Optimal target size at 2 meter distance*</span></span>

<span data-ttu-id="8dbf9-193">![醒目提示注視目標物件的範例](images/gazetargeting-highlighting-640px.jpg)</span><span class="sxs-lookup"><span data-stu-id="8dbf9-193">![An example of highlighting a gaze targeted object](images/gazetargeting-highlighting-640px.jpg)</span></span><br>
<span data-ttu-id="8dbf9-194">*醒目提示注視目標物件的範例*</span><span class="sxs-lookup"><span data-stu-id="8dbf9-194">*An example of highlighting a gaze targeted object*</span></span>

## <a name="target-placement"></a><span data-ttu-id="8dbf9-195">目標位置</span><span class="sxs-lookup"><span data-stu-id="8dbf9-195">Target placement</span></span>
<span data-ttu-id="8dbf9-196">使用者通常找不到其視野中位於很高或很低的 UI 元素，而將其大部分的注意力放在其主要焦點的四周 (通常大約在眼部水平高度)。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-196">Users will often fail to find UI elements that are positioned very high or very low in their field of view, focusing most of their attention on areas around their main focus (usually roughly eye level).</span></span> <span data-ttu-id="8dbf9-197">將大部分的目標放在眼部水平周圍的合理頻帶會有所幫助。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-197">Placing most targets in some reasonable band around eye level can help.</span></span> <span data-ttu-id="8dbf9-198">假設使用者傾向於隨時將焦點放在相對較小的視覺區域 (視覺的注意視錐大約是 10 度)，將概念上相關的 UI 元素聚集在一起，可以在使用者目光掃過區域時運用逐一項目的注意鏈結行為。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-198">Given the tendency for users to focus on a relatively small visual area at any time (the attentional cone of vision is roughly 10 degrees), grouping UI elements together to the degree that they're related conceptually can leverage attention-chaining behaviors from item to item as a user moves their gaze through an area.</span></span> <span data-ttu-id="8dbf9-199">在設計 UI 時，請記住 HoloLens 與沉浸式頭戴裝置之間的視野可能有很大的變化。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-199">When designing UI, keep in mind the potential large variation in field of view between HoloLens and immersive headsets.</span></span>

<span data-ttu-id="8dbf9-200">![方便在 Galaxy Explorer 中進行注視定向的分組 UI 元素範例](images/gazetargeting-grouping-1000px.jpg)</span><span class="sxs-lookup"><span data-stu-id="8dbf9-200">![An example of grouped UI elements for easier gaze targeting in Galaxy Explorer](images/gazetargeting-grouping-1000px.jpg)</span></span><br>
<span data-ttu-id="8dbf9-201">*方便在 Galaxy Explorer 中進行注視定向的分組 UI 元素範例*</span><span class="sxs-lookup"><span data-stu-id="8dbf9-201">*An example of grouped UI elements for easier gaze targeting in Galaxy Explorer*</span></span>

## <a name="improving-targeting-behaviors"></a><span data-ttu-id="8dbf9-202">改善定向行為</span><span class="sxs-lookup"><span data-stu-id="8dbf9-202">Improving targeting behaviors</span></span>
<span data-ttu-id="8dbf9-203">如果可以判定使用者瞄準某物的意圖 (或極為近似)，則接受互動時的「近似差錯」嘗試 (彷彿已正確瞄準) 很有幫助。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-203">If user intent to target something can be determined (or approximated closely), it can be very helpful to accept "near miss" attempts at interaction as though they were targeted correctly.</span></span> <span data-ttu-id="8dbf9-204">有少數幾個成功方法可以納入混合實境體驗：</span><span class="sxs-lookup"><span data-stu-id="8dbf9-204">There are a handful of successful methods that can be incorporated in mixed reality experiences:</span></span>

### <a name="head-gaze-stabilization-gravity-wells"></a><span data-ttu-id="8dbf9-205">頭部注視穩定 (「重力穴」)</span><span class="sxs-lookup"><span data-stu-id="8dbf9-205">Head-gaze stabilization ("gravity wells")</span></span>
<span data-ttu-id="8dbf9-206">在大部分/所有的時間，應該開啟此功能。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-206">This should be turned on most/all of the time.</span></span> <span data-ttu-id="8dbf9-207">這項技術會消除使用者可能會有的頭部/頸部緊張情形。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-207">This technique removes the natural head/neck jitters that users may have.</span></span> <span data-ttu-id="8dbf9-208">以及由於觀看/說話行為而造成的移動。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-208">Also movement due to looking/speaking behaviors.</span></span>

### <a name="closest-link-algorithms"></a><span data-ttu-id="8dbf9-209">最接近的連結演算法</span><span class="sxs-lookup"><span data-stu-id="8dbf9-209">Closest link algorithms</span></span>
<span data-ttu-id="8dbf9-210">這些最適合用於具有疏鬆互動式內容的區域。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-210">These work best in areas with sparse interactive content.</span></span> <span data-ttu-id="8dbf9-211">如果您非常可能判定使用者嘗試進行互動的項目，則只要假定某些層級的意圖，即可補充其定向能力。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-211">If there is a high probability that you can determine what a user was attempting to interact with, you can supplement their targeting abilities by simply assuming some level of intent.</span></span>

### <a name="backdatingpostdating-actions"></a><span data-ttu-id="8dbf9-212">回溯記日/事後記日動作</span><span class="sxs-lookup"><span data-stu-id="8dbf9-212">Backdating/postdating actions</span></span>
<span data-ttu-id="8dbf9-213">這項機制對於要求速度的工作很實用。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-213">This mechanism is useful in tasks requiring speed.</span></span> <span data-ttu-id="8dbf9-214">當使用者快速掃過一系列的定向/啟用調動時，假定某個意圖並允許錯過的步驟在使用者於點選稍前或稍後聚焦的目標上起作用 (在早期測試中於前/後 50 毫秒生效)。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-214">When a user is moving through a series of targeting/activation maneuvers at speed, it can be useful to assume some intent and allow missed steps to act upon targets which the user had in focus slightly before or slightly after the tap (50ms before/after was effective in early testing).</span></span>

### <a name="smoothing"></a><span data-ttu-id="8dbf9-215">平滑處理</span><span class="sxs-lookup"><span data-stu-id="8dbf9-215">Smoothing</span></span>
<span data-ttu-id="8dbf9-216">這項機制可用於路徑移動，減少自然頭部移動特性所造成的些許抖動/搖晃。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-216">This mechanism is useful for pathing movements, reducing the slight jitter/wobble due to natural head movement characteristics.</span></span> <span data-ttu-id="8dbf9-217">平滑處理路徑移動時，請依照移動的大小/距離 (而非隨著時間) 進行平滑處理</span><span class="sxs-lookup"><span data-stu-id="8dbf9-217">When smoothing over pathing motions, smooth by size/distance of movements rather than over time</span></span>

### <a name="magnetism"></a><span data-ttu-id="8dbf9-218">磁性</span><span class="sxs-lookup"><span data-stu-id="8dbf9-218">Magnetism</span></span>
<span data-ttu-id="8dbf9-219">這項機制可以視為更普遍的「最接近連結」演算法版本 - 繪製指向目標的游標，或只要在使用者接近適當目標時增加命中框 (不論是否看得見)，使用互動式版面配置的一些知識更完善處理使用者意圖。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-219">This mechanism can be thought of as a more general version of "Closest link" algorithms - drawing a cursor toward a target, or simply increasing hitboxes (whether visibly or not) as users approach likely targets, using some knowledge of the interactive layout to better approach user intent.</span></span> <span data-ttu-id="8dbf9-220">這對於小型目標特別有效果。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-220">This can be particularly powerful for small targets.</span></span>

### <a name="focus-stickiness"></a><span data-ttu-id="8dbf9-221">焦點黏著度</span><span class="sxs-lookup"><span data-stu-id="8dbf9-221">Focus stickiness</span></span>
<span data-ttu-id="8dbf9-222">在判斷要聚焦在哪些附近互動式元素時，提供目前焦點所在元素的偏差。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-222">When determining which nearby interactive elements to give focus to, provide a bias to the element that is currently focused.</span></span> <span data-ttu-id="8dbf9-223">這有助於在浮動於兩個具有自然雜訊的元素間中點時，減少不穩定的焦點切換行為。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-223">This will help reduce erratic focus switching behaviours when floating at a midpoint between two elements with natural noise.</span></span>


## <a name="composite-gestures"></a><span data-ttu-id="8dbf9-224">複合手勢</span><span class="sxs-lookup"><span data-stu-id="8dbf9-224">Composite gestures</span></span>
<span data-ttu-id="8dbf9-225">應用程式不只可以辨識個別的點選動作。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-225">Apps can recognize more than just individual taps.</span></span> <span data-ttu-id="8dbf9-226">結合點選、按住和放開與手部移動，即可執行更複雜的複合手勢。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-226">By combining tap, hold and release with the movement of the hand, more complex composite gestures can be performed.</span></span> <span data-ttu-id="8dbf9-227">這些複合或高階手勢是以開發人員可以存取的低階空間輸入資料 (來自空中點選和綻開) 為建置基礎。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-227">These composite or high-level gestures build on the low-level spatial input data (from Air tap and Bloom) that developers have access to.</span></span>

### <a name="air-tap"></a><span data-ttu-id="8dbf9-228">空中點選</span><span class="sxs-lookup"><span data-stu-id="8dbf9-228">Air tap</span></span>
<span data-ttu-id="8dbf9-229">空中點選手勢 (以及下列其他手勢) 只會回應特定點選動作。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-229">The Air tap gesture (as well as the other gestures below) reacts only to a specific tap.</span></span> <span data-ttu-id="8dbf9-230">若要偵測其他點選動作 (例如功能表或抓握)，您的應用程式必須直接使用上面兩個主要元件手勢一節中所述的較低層級互動。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-230">To detect other taps, such as Menu or Grasp, your app must directly use the lower-level interactions described in two key component gestures section above.</span></span>

### <a name="tap-and-hold"></a><span data-ttu-id="8dbf9-231">Tap and hold</span><span class="sxs-lookup"><span data-stu-id="8dbf9-231">Tap and hold</span></span>
<span data-ttu-id="8dbf9-232">按住只是維持空中點選的手指朝下位置。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-232">Hold is simply maintaining the downward finger position of the air tap.</span></span> <span data-ttu-id="8dbf9-233">空中點選和按住的組合若搭配手臂移動 (例如拿起物件)，即可進行各種更複雜的「點擊並拖曳」互動，而不需加以啟動或以「滑鼠點擊」次要互動 (例如顯示快顯功能表)。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-233">The combination of air tap and hold allows for a variety of more complex "click and drag" interactions when combined with arm movement such as picking up an object instead of activating it or "mousedown" secondary interactions such as showing a context menu.</span></span>
<span data-ttu-id="8dbf9-234">不過，針對這個手勢進行設計時應格外小心，因為使用者很容易在任何延伸手勢的過程中放鬆其手勢。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-234">Caution should be used when designing for this gesture however, as users can be prone to relaxing their hand postures during the course of any extended gesture.</span></span>

### <a name="manipulation"></a><span data-ttu-id="8dbf9-235">操作</span><span class="sxs-lookup"><span data-stu-id="8dbf9-235">Manipulation</span></span>
<span data-ttu-id="8dbf9-236">當您希望全像投影可 1:1 回應使用者的手部移動時，操作手勢可用來移動、調整大小或旋轉全像投影。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-236">Manipulation gestures can be used to move, resize or rotate a hologram when you want the hologram to react 1:1 to the user's hand movements.</span></span> <span data-ttu-id="8dbf9-237">這類 1:1 移動的用途之一是要讓使用者可以實際繪圖。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-237">One use for such 1:1 movements is to let the user draw or paint in the world.</span></span>
<span data-ttu-id="8dbf9-238">操作手勢的初始定向應經由注視或指向來完成。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-238">The initial targeting for a manipulation gesture should be done by gaze or pointing.</span></span> <span data-ttu-id="8dbf9-239">一旦啟動點選並按住，任何物件操作都由手部移動接著處理，讓使用者在操作時有空四周環顧。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-239">Once the tap and hold starts, any manipulation of the object is then handled by hand movements, freeing the user to look around while they manipulate.</span></span>

### <a name="navigation"></a><span data-ttu-id="8dbf9-240">瀏覽</span><span class="sxs-lookup"><span data-stu-id="8dbf9-240">Navigation</span></span>
<span data-ttu-id="8dbf9-241">瀏覽手勢的運作方式如同虛擬搖桿，可用來瀏覽 UI 小工具，例如放射狀功能表。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-241">Navigation gestures operate like a virtual joystick, and can be used to navigate UI widgets, such as radial menus.</span></span> <span data-ttu-id="8dbf9-242">您可點選並按住來啟動手勢，然後在標準化 3D Cube (在初次按壓時置中) 中移動您的手。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-242">You tap and hold to start the gesture and then move your hand within a normalized 3D cube, centered around the initial press.</span></span> <span data-ttu-id="8dbf9-243">您可以將您的手沿著 X、 Y 或 Z 軸從值 -1 移到 1 (而 0 表示起點)。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-243">You can move your hand along the X, Y or Z axis from a value of -1 to 1, with 0 being the starting point.</span></span>
<span data-ttu-id="8dbf9-244">瀏覽可用來建置以速度為基礎的連續捲動或縮放手勢，類似於藉由按一下滑鼠中間按鈕，然後上下移動滑鼠來捲動 2D UI。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-244">Navigation can be used to build velocity-based continuous scrolling or zooming gestures, similar to scrolling a 2D UI by clicking the middle mouse button and then moving the mouse up and down.</span></span>

<span data-ttu-id="8dbf9-245">利用滑軌瀏覽就是指在達到特定座標軸上特定閾值前，辨識該座標軸內移動的功能。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-245">Navigation with rails refers to the ability of recognizing movements in certain axis until certain threshold is reached on that axis.</span></span> <span data-ttu-id="8dbf9-246">只有當開發人員在應用程式中啟用多個座標軸移動時，這項功能才有用，例如將應用程式設定為可辨識遍及 X、Y 軸的瀏覽手勢，但也包含採用滑軌的指定 X 軸。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-246">This is only useful, when movement in more than one axis is enabled in an application by the developer, e.g. if an application is configured to recognize navigation gestures across X, Y axis but also specified X axis with rails.</span></span> <span data-ttu-id="8dbf9-247">在此情況下，如果手部移動也會發生於 Y 軸，只要這些移動留在 X 軸上的虛構滑軌 (輔助線) 內，系統就會辨識遍及 X 軸的手部移動。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-247">In this case system will recognize hand movements across X axis as long as they remain within an imaginary rails (guide) on X axis, if hand movement also occurs Y axis.</span></span>

<span data-ttu-id="8dbf9-248">在 2D 應用程式內，使用者可以使用垂直瀏覽手勢在應用程式內捲動、縮放或拖曳。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-248">Within 2D apps, users can use vertical navigation gestures to scroll, zoom, or drag inside the app.</span></span> <span data-ttu-id="8dbf9-249">這會在應用程式中插入虛擬手指觸控，以模擬同類型的觸控手勢。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-249">This injects virtual finger touches to the app to simulate touch gestures of the same type.</span></span> <span data-ttu-id="8dbf9-250">在應用程式上方工具列中的工具之間切換 (藉由選取按鈕或說出「<捲動/拖曳/縮放> 工具」)，使用者即可選取發生哪個動作。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-250">Users can select which of these actions take place by toggling between the tools on the bar above the app, either by selecting the button or saying '<Scroll/Drag/Zoom> Tool'.</span></span>

[<span data-ttu-id="8dbf9-251">複合手勢的詳細資訊</span><span class="sxs-lookup"><span data-stu-id="8dbf9-251">More info on composite gestures</span></span>](gestures.md#composite-gestures)

## <a name="gesture-recognizers"></a><span data-ttu-id="8dbf9-252">手勢辨識器</span><span class="sxs-lookup"><span data-stu-id="8dbf9-252">Gesture recognizers</span></span>

<span data-ttu-id="8dbf9-253">使用手勢辨識的其中一個優勢，就是您可以只針對目前定向的全像投影可接受的手勢，設定手勢辨識器。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-253">One benefit of using gesture recognition is that you can configure a gesture recognizer just for the gestures the currently targeted hologram can accept.</span></span> <span data-ttu-id="8dbf9-254">此平台只會為了區分這些特定支援的手勢而進行必要的去除混淆。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-254">The platform will do only the disambiguation necessary to distinguish those particular supported gestures.</span></span> <span data-ttu-id="8dbf9-255">如此一來，只支援空中點選的全像投影可以接受在按下與放開之間的任何時間長度，而同時支援點選和按住的全像投影可以在按住時間閾值後將點選提升為按住。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-255">That way, a hologram that just supports air tap can accept any length of time between press and release, while a hologram that supports both tap and hold can promote the tap to a hold after the hold time threshold.</span></span>

## <a name="hand-recognition"></a><span data-ttu-id="8dbf9-256">手部辨識</span><span class="sxs-lookup"><span data-stu-id="8dbf9-256">Hand recognition</span></span>
<span data-ttu-id="8dbf9-257">HoloLens 可藉由追蹤裝置可見的任一手或雙手位置來辨識手勢。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-257">HoloLens recognizes hand gestures by tracking the position of either or both hands that are visible to the device.</span></span> <span data-ttu-id="8dbf9-258">當手部處於就緒狀態 (手背朝向您且食指朝上) 或按下狀態 (手背朝向您且食指朝下) 時，HoloLens 就會看見手部。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-258">HoloLens sees hands when they are in either the ready state (back of the hand facing you with index finger up) or the pressed state (back of the hand facing you with the index finger down).</span></span> <span data-ttu-id="8dbf9-259">當手部為其他姿勢時，HoloLens 就會忽略手部。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-259">When hands are in other poses, the HoloLens will ignore them.</span></span>
<span data-ttu-id="8dbf9-260">對於 HoloLens 偵測到的每隻手，您可以存取其位置 (不含方向) 及其按下狀態。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-260">For each hand that HoloLens detects, you can access its position (without orientation) and its pressed state.</span></span> <span data-ttu-id="8dbf9-261">當手部接近手勢框架邊緣時，您也會取得方向向量，而您可對使用者顯示該向量，讓他們知道如何移動其手部以回到 HoloLens 可看見手部的位置。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-261">As the hand nears the edge of the gesture frame, you're also provided with a direction vector, which you can show to the user so they know how to move their hand to get it back where HoloLens can see it.</span></span>

## <a name="gesture-frame"></a><span data-ttu-id="8dbf9-262">手勢框架</span><span class="sxs-lookup"><span data-stu-id="8dbf9-262">Gesture frame</span></span>
<span data-ttu-id="8dbf9-263">對於 HoloLens 上的手勢，手部必須在「手勢框架」內，也就是手勢感應攝影機可適度看見的範圍 (約略是從鼻子到腰部的範圍，且介於雙肩之間) 中。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-263">For gestures on HoloLens, the hand must be within a “gesture frame”, in a range that the gesture-sensing cameras can see appropriately (very roughly from nose to waist, and between the shoulders).</span></span> <span data-ttu-id="8dbf9-264">使用者必須同時針對動作成功與其本身的舒適度，接受這個辨識範圍的訓練 (許多使用者一開始都假定手勢框架必定在其 HoloLens 視野內，且為了進行互動而不自在地高舉其手臂)。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-264">Users need to be trained on this area of recognition both for success of action and for their own comfort (many users will initially assume that the gesture frame must be within their view through HoloLens, and hold their arms up uncomfortably in order to interact).</span></span> <span data-ttu-id="8dbf9-265">使用 HoloLens Clicker 時，您的手不需要在手勢框架內。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-265">When using the HoloLens Clicker, your hands do not need to be within the gesture frame.</span></span>

<span data-ttu-id="8dbf9-266">尤其在連續手勢的情況下，在手勢過程 (例如在移動某個全像攝影物件時) 中將手部移出手勢框架的使用者會有些風險，並且會失去其預期的結果。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-266">In the case of continuous gestures in particular, there is some risk of users moving their hands outside of the gesture frame while in mid-gesture (while moving some holographic object, for example), and losing their intended outcome.</span></span>

<span data-ttu-id="8dbf9-267">您應該考量下列三個事項：</span><span class="sxs-lookup"><span data-stu-id="8dbf9-267">There are three things that you should consider:</span></span>

- <span data-ttu-id="8dbf9-268">教育使用者有關手勢框架的存在性和大約界限 (這在 HoloLens 設定期間教導)。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-268">User education on the gesture frame's existence and approximate boundaries (this is taught during HoloLens setup).</span></span>

- <span data-ttu-id="8dbf9-269">當手勢接近/突破應用程式內的手勢框架界限時，通知使用者，因為遺失手勢會導致不想要的結果。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-269">Notifying users when their gestures are nearing/breaking the gesture frame boundaries within an application, to the degree that a lost gesture will lead to undesired outcomes.</span></span> <span data-ttu-id="8dbf9-270">研究已顯示這類通知系統的主要品質，而 HoloLens 殼層提供這類型通知的良好範例 (視覺化，位於中央游標，指出發生越界的方向)。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-270">Research has shown the key qualities of such a notification system, and the HoloLens shell provides a good example of this type of notification (visual, on the central cursor, indicating the direction in which boundary crossing is taking place).</span></span>

- <span data-ttu-id="8dbf9-271">您應該將突破手勢框架界限的後果最小化。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-271">Consequences of breaking the gesture frame boundaries should be minimized.</span></span> <span data-ttu-id="8dbf9-272">一般而言，這表示手勢的結果應止於界限，但不會反轉。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-272">In general, this means that the outcome of a gesture should be stopped at the boundary, but not reversed.</span></span> <span data-ttu-id="8dbf9-273">例如，如果使用者正在房間內移動某個全像攝影物件，則當手勢框架被突破時，就應該停止移動，但不會回到起點。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-273">For example, if a user is moving some holographic object across a room, movement should stop when the gesture frame is breached, but not be returned to the starting point.</span></span> <span data-ttu-id="8dbf9-274">使用者可能遭遇一些挫敗，但可以更快了解界限，而不必每次重新開始其完整的預定動作。</span><span class="sxs-lookup"><span data-stu-id="8dbf9-274">The user may experience some frustration then, but may more quickly understand the boundaries, and not have to restart their full intended actions each time.</span></span>


## <a name="see-also"></a><span data-ttu-id="8dbf9-275">請參閱</span><span class="sxs-lookup"><span data-stu-id="8dbf9-275">See also</span></span>
* [<span data-ttu-id="8dbf9-276">手部直接操作</span><span class="sxs-lookup"><span data-stu-id="8dbf9-276">Direct manipulation with hands</span></span>](direct-manipulation.md)
* [<span data-ttu-id="8dbf9-277">手部指向和行動</span><span class="sxs-lookup"><span data-stu-id="8dbf9-277">Point and commit with hands</span></span>](point-and-commit.md)
* [<span data-ttu-id="8dbf9-278">本能互動</span><span class="sxs-lookup"><span data-stu-id="8dbf9-278">Instinctual interactions</span></span>](interaction-fundamentals.md)
* [<span data-ttu-id="8dbf9-279">頭部目光和停駐</span><span class="sxs-lookup"><span data-stu-id="8dbf9-279">Head-gaze and dwell</span></span>](gaze-and-dwell.md)
* [<span data-ttu-id="8dbf9-280">語音命令</span><span class="sxs-lookup"><span data-stu-id="8dbf9-280">Voice commanding</span></span>](voice-design.md)





