---
title: 頭部注視並認可
description: 頭部注視並認可輸入模型的概觀
author: caseymeekhof
ms.author: cmeekhof
ms.date: 03/31/2019
ms.topic: article
keywords: Mixed Reality, 注視, 注視定向, 互動, 設計
ms.openlocfilehash: aeca5ceacf5ae350aa06cb58cc68162f885f6d78
ms.sourcegitcommit: b0b1b8e1182cce93929d409706cdaa99ff24fdee
ms.translationtype: MT
ms.contentlocale: zh-TW
ms.lasthandoff: 07/23/2019
ms.locfileid: "68387676"
---
# <a name="head-gaze-and-commit"></a><span data-ttu-id="95a5e-104">頭部注視並認可</span><span class="sxs-lookup"><span data-stu-id="95a5e-104">Head-gaze and commit</span></span>
<span data-ttu-id="95a5e-105">「前端注視」和「認可」是一種輸入模型, 其中牽涉到以您的頭向後 (head 方向) 方向為物件的目標, 然後使用次要輸入進行動作, 例如手勢碰點或語音命令選取。</span><span class="sxs-lookup"><span data-stu-id="95a5e-105">Head-gaze and commit is an input model that involves targeting an object with the direction of your head pointing forward (head-direction), and then acting on it with a secondary input, such as the hand gesture air tap or the voice command Select.</span></span> <span data-ttu-id="95a5e-106">它會被視為具有間接操作的輸入模型, 這表示它最適合用來與超越 arm 的內容互動。</span><span class="sxs-lookup"><span data-stu-id="95a5e-106">It is considered a far input model with indirect manipulation, meaning it is best used for interacting with content that is beyond arms reach.</span></span>

## <a name="device-support"></a><span data-ttu-id="95a5e-107">裝置支援</span><span class="sxs-lookup"><span data-stu-id="95a5e-107">Device support</span></span>

<table>
    <colgroup>
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    </colgroup>
    <tr>
        <td><span data-ttu-id="95a5e-108"><strong>輸入模型</strong></span><span class="sxs-lookup"><span data-stu-id="95a5e-108"><strong>Input model</strong></span></span></td>
        <td><span data-ttu-id="95a5e-109"><a href="hololens-hardware-details.md"><strong>HoloLens (第 1 代)</strong></a></span><span class="sxs-lookup"><span data-stu-id="95a5e-109"><a href="hololens-hardware-details.md"><strong>HoloLens (1st gen)</strong></a></span></span></td>
        <td><span data-ttu-id="95a5e-110"><strong>HoloLens 2</strong></span><span class="sxs-lookup"><span data-stu-id="95a5e-110"><strong>HoloLens 2</strong></span></span></td>
        <td><span data-ttu-id="95a5e-111"><a href="immersive-headset-hardware-details.md"><strong>沉浸式頭戴裝置</strong></a></span><span class="sxs-lookup"><span data-stu-id="95a5e-111"><a href="immersive-headset-hardware-details.md"><strong>Immersive headsets</strong></a></span></span></td>
    </tr>
     <tr>
        <td><span data-ttu-id="95a5e-112">頭部注視並認可</span><span class="sxs-lookup"><span data-stu-id="95a5e-112">Head-gaze and commit</span></span></td>
        <td><span data-ttu-id="95a5e-113">✔️ 建議使用</span><span class="sxs-lookup"><span data-stu-id="95a5e-113">✔️ Recommended</span></span></td>
        <td><span data-ttu-id="95a5e-114">✔️ 建議使用 (第三個選擇 - <a href="interaction-fundamentals.md">查看其他選項</a>)</span><span class="sxs-lookup"><span data-stu-id="95a5e-114">✔️ Recommended (third choice - <a href="interaction-fundamentals.md">See the other options</a>)</span></span></td>
        <td><span data-ttu-id="95a5e-115">➕ 替代選項</span><span class="sxs-lookup"><span data-stu-id="95a5e-115">➕ Alternate option</span></span></td>
    </tr>
</table>

## <a name="head-gaze"></a><span data-ttu-id="95a5e-116">頭部注視</span><span class="sxs-lookup"><span data-stu-id="95a5e-116">Head-gaze</span></span>
<span data-ttu-id="95a5e-117">混合實境頭戴式裝置使用使用者頭部的位置和方向來判斷其頭部方向向量。</span><span class="sxs-lookup"><span data-stu-id="95a5e-117">Mixed reality headsets use the position and orientation of the user's head to determine their head direction vector.</span></span> <span data-ttu-id="95a5e-118">您可以將此視為直接從使用者的雙眼之間向前直指的雷射。</span><span class="sxs-lookup"><span data-stu-id="95a5e-118">You can think of this as a laser that points straight ahead from directly between the user's eyes.</span></span> <span data-ttu-id="95a5e-119">這是相當粗略的使用者觀看位置概算。</span><span class="sxs-lookup"><span data-stu-id="95a5e-119">This is a fairly coarse approximation of where the user is looking.</span></span> <span data-ttu-id="95a5e-120">您的應用程式可以將此光線與虛擬或真實世界的物件相交, 並在該位置繪製游標, 讓使用者知道它們目前的目標為何。</span><span class="sxs-lookup"><span data-stu-id="95a5e-120">Your application can intersect this ray with virtual or real-world objects, and draw a cursor at that location to let the user know what they are currently targeting.</span></span>

<span data-ttu-id="95a5e-121">除了眼睛外, 某些混合現實耳機 (如 HoloLens 2) 包含可產生眼睛向量的監看式追蹤系統。</span><span class="sxs-lookup"><span data-stu-id="95a5e-121">In addition to head gaze, some mixed reality headsets, like HoloLens 2, include eye tracking systems that produce an eye-gaze vector.</span></span> <span data-ttu-id="95a5e-122">這會對使用者觀看的位置提供精細的測量。</span><span class="sxs-lookup"><span data-stu-id="95a5e-122">This provides a fine-grained measurement of where the user is looking.</span></span> <span data-ttu-id="95a5e-123">您可以使用眼睛來建立注視和認可互動。</span><span class="sxs-lookup"><span data-stu-id="95a5e-123">It is possible to build gaze and commit interactions using eye gaze.</span></span> <span data-ttu-id="95a5e-124">但是, 這是一組非常不同的設計條件約束, 會在[眼睛眼文章](eye-tracking.md)中另行討論。</span><span class="sxs-lookup"><span data-stu-id="95a5e-124">But this comes with a very different set of design constraints, which will be covered separately in the [eye-gaze article](eye-tracking.md).</span></span>

## <a name="commit"></a><span data-ttu-id="95a5e-125">認可</span><span class="sxs-lookup"><span data-stu-id="95a5e-125">Commit</span></span>
<span data-ttu-id="95a5e-126">以物件或 UI 元素為目標之後, 使用者可以使用次要輸入進行互動或按一下。</span><span class="sxs-lookup"><span data-stu-id="95a5e-126">After targeting an object or UI element, the user can interact or click on it using a secondary input.</span></span> <span data-ttu-id="95a5e-127">這也稱為模型的認可步驟。</span><span class="sxs-lookup"><span data-stu-id="95a5e-127">This is known as the commit step of the model.</span></span> <span data-ttu-id="95a5e-128">支援的認可方法如下：</span><span class="sxs-lookup"><span data-stu-id="95a5e-128">The following commit methods are supported:</span></span>

- <span data-ttu-id="95a5e-129">空中碰手勢</span><span class="sxs-lookup"><span data-stu-id="95a5e-129">Air tap gesture</span></span>
- <span data-ttu-id="95a5e-130">說出語音命令、選取或其中一個目標語音命令</span><span class="sxs-lookup"><span data-stu-id="95a5e-130">Speak the voice command, Select, or one of the targeted voice commands</span></span>
- <span data-ttu-id="95a5e-131">在[HoloLens Clicker](hardware-accessories.md#hololens-clicker)上按一個按鈕</span><span class="sxs-lookup"><span data-stu-id="95a5e-131">Press a single button on a [HoloLens Clicker](hardware-accessories.md#hololens-clicker)</span></span>
- <span data-ttu-id="95a5e-132">按下 Xbox 遊戲台上的 [A] 按鈕</span><span class="sxs-lookup"><span data-stu-id="95a5e-132">Press the 'A' button on an Xbox gamepad</span></span>
- <span data-ttu-id="95a5e-133">按 Xbox 調適型控制器上的 [A] 按鈕</span><span class="sxs-lookup"><span data-stu-id="95a5e-133">Press the 'A' button on an Xbox adaptive controller</span></span>

### <a name="head-gaze-and-air-tap-gesture"></a><span data-ttu-id="95a5e-134">頭部注視和空中點選手勢</span><span class="sxs-lookup"><span data-stu-id="95a5e-134">Head-gaze and air tap gesture</span></span>
<span data-ttu-id="95a5e-135">空中點選是手部直立的點選手勢。</span><span class="sxs-lookup"><span data-stu-id="95a5e-135">Air tap is a tapping gesture with the hand held upright.</span></span> <span data-ttu-id="95a5e-136">若要執行點一下, 請將您的索引指向準備好的位置, 然後將您的 thumb 縮小, 然後將索引手指的備份提升至發行。</span><span class="sxs-lookup"><span data-stu-id="95a5e-136">To perform an air tap, raise your index finger to the ready position, then pinch with your thumb, and raise your index finger back up to release.</span></span> <span data-ttu-id="95a5e-137">在 HoloLens (第1代) 上, 空中碰是最常見的次要輸入。</span><span class="sxs-lookup"><span data-stu-id="95a5e-137">On HoloLens (1st Gen), air tap is the most common secondary input.</span></span>

![將手指放在就緒位置，然後點選或按一下移動](images/readyandpress.jpg)<br>

<span data-ttu-id="95a5e-139">您也可以在 HoloLens 2 上使用空中按鍵功能。</span><span class="sxs-lookup"><span data-stu-id="95a5e-139">Air tap is also available on HoloLens 2.</span></span> <span data-ttu-id="95a5e-140">它已從原始版本中放寬。</span><span class="sxs-lookup"><span data-stu-id="95a5e-140">It has been relaxed from the original version.</span></span> <span data-ttu-id="95a5e-141">幾乎所有類型的 pinches 現在都可支援, 只要手是直立的, 而且仍然保留。</span><span class="sxs-lookup"><span data-stu-id="95a5e-141">Nearly all types of pinches are now supported as long as the hand is upright and holding still.</span></span> <span data-ttu-id="95a5e-142">這可讓使用者更容易了解和執行手勢。</span><span class="sxs-lookup"><span data-stu-id="95a5e-142">This makes it much easier for users to learn and perform the gesture.</span></span> <span data-ttu-id="95a5e-143">這個新的空中點會透過相同的 API 取代舊的, 因此現有的應用程式會在重新編譯 HoloLens 2 之後自動擁有新的行為。</span><span class="sxs-lookup"><span data-stu-id="95a5e-143">This new air tap replaces the old one through the same API, so existing applications will have the new behavior automatically after recompiling for HoloLens 2.</span></span>

### <a name="head-gaze-and-select-voice-command"></a><span data-ttu-id="95a5e-144">頭部注視和 "Select" 語音命令</span><span class="sxs-lookup"><span data-stu-id="95a5e-144">Head-gaze and "Select" voice command</span></span>
<span data-ttu-id="95a5e-145">語音命令是混合現實中的其中一種主要互動方法。</span><span class="sxs-lookup"><span data-stu-id="95a5e-145">Voice commanding is one of the primary interaction methods in mixed reality.</span></span> <span data-ttu-id="95a5e-146">它提供了一種非常強大的無人參與機制來控制系統。</span><span class="sxs-lookup"><span data-stu-id="95a5e-146">It provides a very powerful hands-free mechanism to control the system.</span></span> <span data-ttu-id="95a5e-147">語音互動模型有不同的類型：</span><span class="sxs-lookup"><span data-stu-id="95a5e-147">There are diferent types of voice interaction models:</span></span>

- <span data-ttu-id="95a5e-148">執行 click actuation 或 commit 做為次要輸入的一般命令選取。</span><span class="sxs-lookup"><span data-stu-id="95a5e-148">The generic command Select that performs a click actuation or commit as a secondary input.</span></span>
- <span data-ttu-id="95a5e-149">像關閉或變得更大的物件命令會將動作執行並認可為次要輸入。</span><span class="sxs-lookup"><span data-stu-id="95a5e-149">Object commands like Close or Make it bigger performs and commits to an action as a secondary input.</span></span>
- <span data-ttu-id="95a5e-150">「移至開始」之類的全域 commnads 不需要目標。</span><span class="sxs-lookup"><span data-stu-id="95a5e-150">Global commnads like Go to start don't require a target.</span></span>
- <span data-ttu-id="95a5e-151">對話使用者介面或 Cortana 等實體具有 AI 自然語言功能。</span><span class="sxs-lookup"><span data-stu-id="95a5e-151">Conversation user interfaces or entities like Cortana have an AI natural language capability.</span></span>
- <span data-ttu-id="95a5e-152">自訂命令</span><span class="sxs-lookup"><span data-stu-id="95a5e-152">Custom commnads</span></span>

<span data-ttu-id="95a5e-153">若要尋找更多詳細資料以及可用命令的 comprenhesive 清單, 以及如何使用它們, 請參閱我們的[語音命令](voice-design.md)指引。</span><span class="sxs-lookup"><span data-stu-id="95a5e-153">To find more details as well as a comprenhesive list of available commands and how to use them, check out our [voice commanding](voice-design.md) guidance.</span></span>


### <a name="head-gaze-and-hololens-clicker"></a><span data-ttu-id="95a5e-154">頭部注視和 HoloLens Clicker</span><span class="sxs-lookup"><span data-stu-id="95a5e-154">Head-gaze and HoloLens Clicker</span></span>
<span data-ttu-id="95a5e-155">HoloLens Clicker 是專為 HoloLens 建立的第一個週邊裝置。</span><span class="sxs-lookup"><span data-stu-id="95a5e-155">The HoloLens Clicker is the first peripheral device built specifically for HoloLens.</span></span> <span data-ttu-id="95a5e-156">它隨附在 HoloLens (第1代) 開發版本中。</span><span class="sxs-lookup"><span data-stu-id="95a5e-156">It is included with HoloLens (1st Gen) Development Edition.</span></span> <span data-ttu-id="95a5e-157">HoloLens Clicker 可讓使用者按一下最少的手運動, 並認可為次要輸入。</span><span class="sxs-lookup"><span data-stu-id="95a5e-157">The HoloLens Clicker lets a user click with minimal hand motion, and commit as a secondary input.</span></span> <span data-ttu-id="95a5e-158">HoloLens Clicker 會使用藍牙低功耗 (BTLE) 連接到 HoloLens (第1代) 或 HoloLens 2。</span><span class="sxs-lookup"><span data-stu-id="95a5e-158">The HoloLens Clicker connects to HoloLens (1st Gen) or HoloLens 2 using Bluetooth Low Energy (BTLE).</span></span>

<span data-ttu-id="95a5e-159">![HoloLens Clicker](images/hololens-clicker-500px.jpg)</span><span class="sxs-lookup"><span data-stu-id="95a5e-159">![HoloLens Clicker](images/hololens-clicker-500px.jpg)</span></span><br>
<span data-ttu-id="95a5e-160">*HoloLens Clicker*</span><span class="sxs-lookup"><span data-stu-id="95a5e-160">*HoloLens Clicker*</span></span>

<span data-ttu-id="95a5e-161">您可以在[這裡](hardware-accessories.md#pairing-bluetooth-accessories)找到裝置配對的詳細資訊和指示。</span><span class="sxs-lookup"><span data-stu-id="95a5e-161">More information and instructions to pair the device can be found [here](hardware-accessories.md#pairing-bluetooth-accessories)</span></span>




### <a name="head-gaze-and-xbox-wireless-controller"></a><span data-ttu-id="95a5e-162">頭部注視和 Xbox 無線控制器</span><span class="sxs-lookup"><span data-stu-id="95a5e-162">Head-gaze and Xbox Wireless Controller</span></span>
<span data-ttu-id="95a5e-163">Xbox 無線控制器會使用 [A] 按鈕, 以次要輸入的形式執行按一下 actuation。</span><span class="sxs-lookup"><span data-stu-id="95a5e-163">The Xbox Wireless Controller performs a click actuation as a secondary input by using the 'A' button.</span></span> <span data-ttu-id="95a5e-164">裝置會對應至一組預設動作，協助您導覽和控制系統。</span><span class="sxs-lookup"><span data-stu-id="95a5e-164">The device is mapped to a default set of actions that help navigate and controll the system.</span></span> <span data-ttu-id="95a5e-165">如果您想要自訂控制器, 請使用 Xbox Accesories 應用程式來設定您的 Xbox 無線控制器。</span><span class="sxs-lookup"><span data-stu-id="95a5e-165">If you want to customize the controller, use the Xbox Accesories application to configure your Xbox Wireless Controller.</span></span>

<span data-ttu-id="95a5e-166">![Xbox 無線控制器](images/xboxcontroller.jpg)</span><span class="sxs-lookup"><span data-stu-id="95a5e-166">![Xbox Wireless Controller](images/xboxcontroller.jpg)</span></span><br>
<span data-ttu-id="95a5e-167">*Xbox 無線控制器*</span><span class="sxs-lookup"><span data-stu-id="95a5e-167">*Xbox Wireless Controller*</span></span>

[<span data-ttu-id="95a5e-168">將 Xbox 控制器與您的電腦配對</span><span class="sxs-lookup"><span data-stu-id="95a5e-168">Pairing an Xbox controller with your PC</span></span>](hardware-accessories.md#pairing-bluetooth-accessories)


### <a name="head-gaze-and-xbox-adaptive-controller"></a><span data-ttu-id="95a5e-169">頭部注視和 Xbox Adaptive Controller</span><span class="sxs-lookup"><span data-stu-id="95a5e-169">Head-gaze and Xbox Adaptive Controller</span></span>
<span data-ttu-id="95a5e-170">Xbox 調調適型控制器是主要為了滿足行動裝置的需求, 而這是一種整合式集線器, 可協助讓混合現實更容易存取。</span><span class="sxs-lookup"><span data-stu-id="95a5e-170">Designed primarily to meet the needs of gamers with limited mobility, the Xbox Adaptive Controller is a unified hub for devices that helps make mixed reality more accessible.</span></span>

<span data-ttu-id="95a5e-171">Xbox 調適型控制器會使用 [A] 按鈕, 以次要輸入的形式執行按一下 actuation。</span><span class="sxs-lookup"><span data-stu-id="95a5e-171">The Xbox Adaptive Controller performs a click actuation as a secondary input by using the 'A' button.</span></span> <span data-ttu-id="95a5e-172">裝置會對應至一組預設的動作, 以協助流覽和控制系統。</span><span class="sxs-lookup"><span data-stu-id="95a5e-172">The device is mapped to a default set of actions that help navigate and control the system.</span></span> <span data-ttu-id="95a5e-173">如果您想要自訂控制器, 請使用 Xbox Accesories 應用程式來設定 Xbox 調適型控制器。</span><span class="sxs-lookup"><span data-stu-id="95a5e-173">If you want to customize the controller, use the Xbox Accesories application to configure your Xbox Adaptive Controller.</span></span>

<span data-ttu-id="95a5e-174">![Xbox Adaptive Controller](images/xbox-adaptive-controller-devices.jpg)</span><span class="sxs-lookup"><span data-stu-id="95a5e-174">![Xbox Adaptive Controller](images/xbox-adaptive-controller-devices.jpg)</span></span><br>
<span data-ttu-id="95a5e-175">*Xbox Adaptive Controller*</span><span class="sxs-lookup"><span data-stu-id="95a5e-175">*Xbox Adaptive Controller*</span></span>

<span data-ttu-id="95a5e-176">連接外部裝置 (例如交換器、按鈕、掛接和搖桿), 以建立唯一的自訂控制器體驗。</span><span class="sxs-lookup"><span data-stu-id="95a5e-176">Connect external devices such as switches, buttons, mounts, and joysticks to create a custom controller experience that is uniquely yours.</span></span> <span data-ttu-id="95a5e-177">按鈕、操縱杆和觸發程式輸入都是由透過 3.5 mm 插座和 USB 埠連線的輔助裝置所控制。</span><span class="sxs-lookup"><span data-stu-id="95a5e-177">Button, thumbstick, and trigger inputs are controlled with assistive devices connected through 3.5mm jacks and USB ports.</span></span>

<span data-ttu-id="95a5e-178">![Xbox Adaptive Controller 連接埠](images/xbox-adaptive-controller-ports.jpg)</span><span class="sxs-lookup"><span data-stu-id="95a5e-178">![Xbox Adaptive Controller ports](images/xbox-adaptive-controller-ports.jpg)</span></span><br>
<span data-ttu-id="95a5e-179">*Xbox Adaptive Controller 連接埠*</span><span class="sxs-lookup"><span data-stu-id="95a5e-179">*Xbox Adaptive Controller ports*</span></span>

[<span data-ttu-id="95a5e-180">裝置配對指示</span><span class="sxs-lookup"><span data-stu-id="95a5e-180">Instructions to pair the device</span></span>](hardware-accessories.md#pairing-bluetooth-accessories)

<span data-ttu-id="95a5e-181"><a href=https://www.xbox.com/en-US/xbox-one/accessories/controllers/xbox-adaptive-controller>在 Xbox 網站上可取得更多資訊</a></span><span class="sxs-lookup"><span data-stu-id="95a5e-181"><a href=https://www.xbox.com/en-US/xbox-one/accessories/controllers/xbox-adaptive-controller>More info available on the Xbox site</a></span></span>


## <a name="design-guidelines"></a><span data-ttu-id="95a5e-182">設計指導方針</span><span class="sxs-lookup"><span data-stu-id="95a5e-182">Design guidelines</span></span>
> [!NOTE]
> <span data-ttu-id="95a5e-183">[即將推出](index.md)注視設計專屬的詳細指引。</span><span class="sxs-lookup"><span data-stu-id="95a5e-183">More guidance specific to gaze design [coming soon](index.md).</span></span>

## <a name="head-gaze-targeting"></a><span data-ttu-id="95a5e-184">頭部注視定向</span><span class="sxs-lookup"><span data-stu-id="95a5e-184">Head-gaze targeting</span></span>
<span data-ttu-id="95a5e-185">無論輸入形式為何，當使用者能夠瞄準他們想要進行互動的元素時，所有互動就已建立。</span><span class="sxs-lookup"><span data-stu-id="95a5e-185">All interactions are built upon the ability of a user to target the element they want to interact with, regardless of the input modality.</span></span> <span data-ttu-id="95a5e-186">在 Windows Mixed Reality 中，這通常會使用使用者的注視進行。</span><span class="sxs-lookup"><span data-stu-id="95a5e-186">In Windows Mixed Reality, this is generally done using the user's gaze.</span></span>
<span data-ttu-id="95a5e-187">為了讓使用者能夠順利使用經驗, 系統對於使用者的意圖和使用者的實際意圖的瞭解, 必須盡可能地對齊。</span><span class="sxs-lookup"><span data-stu-id="95a5e-187">To enable a user to work with an experience successfully, the system's calculated understanding of a user's intent and the user's actual intent must align as closely as possible.</span></span> <span data-ttu-id="95a5e-188">系統儘可能正確解譯使用者的預定動作，所以滿意度提升且效能改善。</span><span class="sxs-lookup"><span data-stu-id="95a5e-188">To the degree that the system interprets the user's intended actions correctly, satisfaction increases and performance improves.</span></span>


## <a name="target-sizing-and-feedback"></a><span data-ttu-id="95a5e-189">目標大小調整和回饋</span><span class="sxs-lookup"><span data-stu-id="95a5e-189">Target sizing and feedback</span></span>
<span data-ttu-id="95a5e-190">注視向量已重複顯示, 可用於適當的目標, 但通常最適合用於總目標--取得較大的目標。</span><span class="sxs-lookup"><span data-stu-id="95a5e-190">The gaze vector has been shown repeatedly to be usable for fine targeting, but often works best for gross targeting--acquiring somewhat larger targets.</span></span> <span data-ttu-id="95a5e-191">最小的目標大小為1到1.5 度, 在大多數情況下允許成功的使用者動作, 不過, 3 度的目標通常允許更快的速度。</span><span class="sxs-lookup"><span data-stu-id="95a5e-191">Minimum target sizes of 1 to 1.5 degrees allows successful user actions in most scenarios, though targets of 3 degrees often allow for greater speed.</span></span> <span data-ttu-id="95a5e-192">請注意，使用者定向的大小實際上是 2D 區域 (即使是 3D 元素)，無論哪個投影面向他們都應該是可作為目標的區域。</span><span class="sxs-lookup"><span data-stu-id="95a5e-192">Note that the size that the user targets is effectively a 2D area even for 3D elements--whichever projection is facing them should be the targetable area.</span></span> <span data-ttu-id="95a5e-193">提供某個元素為「作用中」的一些顯著提示 (使用者以其為目標) 非常有用。</span><span class="sxs-lookup"><span data-stu-id="95a5e-193">Providing some salient cue that an element is "active" (that the user is targeting it) is extremely helpful.</span></span> <span data-ttu-id="95a5e-194">這可能包括如可見的「暫留」效果、音訊反白顯示或點擊, 或清除游標與專案的對齊。</span><span class="sxs-lookup"><span data-stu-id="95a5e-194">This can include treatments like visible "hover" effects, audio highlights or clicks, or clear alignment of a cursor with an element.</span></span>

<span data-ttu-id="95a5e-195">![距離 2 公尺的最佳目標大小](images/gazetargeting-size-1000px.jpg)</span><span class="sxs-lookup"><span data-stu-id="95a5e-195">![Optimal target size at 2 meter distance](images/gazetargeting-size-1000px.jpg)</span></span><br>
<span data-ttu-id="95a5e-196">*2 個計量表距離的最佳目標大小*</span><span class="sxs-lookup"><span data-stu-id="95a5e-196">*Optimal target size at 2 meter distance*</span></span>

<span data-ttu-id="95a5e-197">![醒目提示注視目標物件的範例](images/gazetargeting-highlighting-640px.jpg)</span><span class="sxs-lookup"><span data-stu-id="95a5e-197">![An example of highlighting a gaze targeted object](images/gazetargeting-highlighting-640px.jpg)</span></span><br>
<span data-ttu-id="95a5e-198">*醒目提示注視目標物件的範例*</span><span class="sxs-lookup"><span data-stu-id="95a5e-198">*An example of highlighting a gaze targeted object*</span></span>

## <a name="target-placement"></a><span data-ttu-id="95a5e-199">目標位置</span><span class="sxs-lookup"><span data-stu-id="95a5e-199">Target placement</span></span>
<span data-ttu-id="95a5e-200">使用者通常無法在其視野中找到位置非常高或非常低的 UI 元素, 著重于其主要焦點附近的區域, 這大約是眼睛。</span><span class="sxs-lookup"><span data-stu-id="95a5e-200">Users often fail to find UI elements that are positioned very high or very low in their field of view, focusing most of their attention on areas around their main focus, which is approximately at eye level.</span></span> <span data-ttu-id="95a5e-201">將大部分的目標放在眼部水平周圍的合理頻帶會有所幫助。</span><span class="sxs-lookup"><span data-stu-id="95a5e-201">Placing most targets in some reasonable band around eye level can help.</span></span> <span data-ttu-id="95a5e-202">假設使用者傾向於隨時將焦點放在相對較小的視覺區域 (視覺的注意視錐大約是 10 度)，將概念上相關的 UI 元素聚集在一起，可以在使用者目光掃過區域時運用逐一項目的注意鏈結行為。</span><span class="sxs-lookup"><span data-stu-id="95a5e-202">Given the tendency for users to focus on a relatively small visual area at any time (the attentional cone of vision is roughly 10 degrees), grouping UI elements together to the degree that they're related conceptually can leverage attention-chaining behaviors from item to item as a user moves their gaze through an area.</span></span> <span data-ttu-id="95a5e-203">在設計 UI 時，請記住 HoloLens 與沉浸式頭戴裝置之間的視野可能有很大的變化。</span><span class="sxs-lookup"><span data-stu-id="95a5e-203">When designing UI, keep in mind the potential large variation in field of view between HoloLens and immersive headsets.</span></span>

<span data-ttu-id="95a5e-204">![方便在 Galaxy Explorer 中進行注視定向的分組 UI 元素範例](images/gazetargeting-grouping-1000px.jpg)</span><span class="sxs-lookup"><span data-stu-id="95a5e-204">![An example of grouped UI elements for easier gaze targeting in Galaxy Explorer](images/gazetargeting-grouping-1000px.jpg)</span></span><br>
<span data-ttu-id="95a5e-205">*方便在 Galaxy Explorer 中進行注視定向的分組 UI 元素範例*</span><span class="sxs-lookup"><span data-stu-id="95a5e-205">*An example of grouped UI elements for easier gaze targeting in Galaxy Explorer*</span></span>

## <a name="improving-targeting-behaviors"></a><span data-ttu-id="95a5e-206">改善定向行為</span><span class="sxs-lookup"><span data-stu-id="95a5e-206">Improving targeting behaviors</span></span>
<span data-ttu-id="95a5e-207">如果使用者意圖是以某個專案為目標 (或接近), 則在互動時接受接近遺漏的嘗試, 可能會很有説明, 如同其目標正確。</span><span class="sxs-lookup"><span data-stu-id="95a5e-207">If user intent to target something can be determined (or approximated closely), it can be very helpful to accept near miss attempts at interaction as though they were targeted correctly.</span></span> <span data-ttu-id="95a5e-208">以下是幾個成功的方法, 可以併入混合現實體驗中:</span><span class="sxs-lookup"><span data-stu-id="95a5e-208">Here are a handful of successful methods that can be incorporated in mixed reality experiences:</span></span>

### <a name="head-gaze-stabilization-gravity-wells"></a><span data-ttu-id="95a5e-209">頭部注視穩定 (「重力穴」)</span><span class="sxs-lookup"><span data-stu-id="95a5e-209">Head-gaze stabilization ("gravity wells")</span></span>
<span data-ttu-id="95a5e-210">這應該會在大部分或全時間開啟。</span><span class="sxs-lookup"><span data-stu-id="95a5e-210">This should be turned on most or all of the time.</span></span> <span data-ttu-id="95a5e-211">這項技術會移除使用者可能因外觀和說話行為而進行移動的自然頭和頸部起伏快速變換。</span><span class="sxs-lookup"><span data-stu-id="95a5e-211">This technique removes the natural head and neck jitters that users might have as well movement due to looking and speaking behaviors.</span></span>

### <a name="closest-link-algorithms"></a><span data-ttu-id="95a5e-212">最接近的連結演算法</span><span class="sxs-lookup"><span data-stu-id="95a5e-212">Closest link algorithms</span></span>
<span data-ttu-id="95a5e-213">這些最適合用於具有疏鬆互動式內容的區域。</span><span class="sxs-lookup"><span data-stu-id="95a5e-213">These work best in areas with sparse interactive content.</span></span> <span data-ttu-id="95a5e-214">如果您可以判斷使用者嘗試與之互動的機率很高, 則可以假設某種程度的意圖來補充其目標功能。</span><span class="sxs-lookup"><span data-stu-id="95a5e-214">If there is a high probability that you can determine what a user was attempting to interact with, you can supplement their targeting abilities by assuming some level of intent.</span></span>

### <a name="backdating-and-postdating-actions"></a><span data-ttu-id="95a5e-215">Backdating 和 postdating 動作</span><span class="sxs-lookup"><span data-stu-id="95a5e-215">Backdating and postdating actions</span></span>
<span data-ttu-id="95a5e-216">這項機制對於要求速度的工作很實用。</span><span class="sxs-lookup"><span data-stu-id="95a5e-216">This mechanism is useful in tasks requiring speed.</span></span> <span data-ttu-id="95a5e-217">當使用者透過一系列的目標和啟用調動快速移動時, 假設有一些意圖, 並允許遺漏的步驟, 以使用者在點在點前後的焦點 (50 毫秒之前/之後) 來採取目標rly 測試)。</span><span class="sxs-lookup"><span data-stu-id="95a5e-217">When a user is moving through a series of targeting and activation maneuvers at speed, it is useful to assume some intent, and allow missed steps to act upon targets that the user had in focus slightly before or slightly after the tap (50 ms before/after was effective in early testing).</span></span>

### <a name="smoothing"></a><span data-ttu-id="95a5e-218">平滑處理</span><span class="sxs-lookup"><span data-stu-id="95a5e-218">Smoothing</span></span>
<span data-ttu-id="95a5e-219">這種機制對於路徑移動很有用, 因為自然的頭移動特性, 減少輕微的抖動和 wobble。</span><span class="sxs-lookup"><span data-stu-id="95a5e-219">This mechanism is useful for pathing movements, reducing the slight jitter and wobble due to natural head movement characteristics.</span></span> <span data-ttu-id="95a5e-220">平滑處理路徑動作時, 會以移動的大小和距離來平滑, 而不是一段時間。</span><span class="sxs-lookup"><span data-stu-id="95a5e-220">When smoothing over pathing motions, smooth by the size and distance of movements rather than over time.</span></span>

### <a name="magnetism"></a><span data-ttu-id="95a5e-221">磁性</span><span class="sxs-lookup"><span data-stu-id="95a5e-221">Magnetism</span></span>
<span data-ttu-id="95a5e-222">這項機制可以視為較通用的最接近連結演算法版本--將游標向目標繪製, 或只是以明顯的方式增加 hitboxes (不論是否可見), 因為使用者可能會藉由使用某些互動式版面配置知識更好方法使用者意圖。</span><span class="sxs-lookup"><span data-stu-id="95a5e-222">This mechanism can be thought of as a more general version of closest link algorithms--drawing a cursor toward a target or simply increasing hitboxes, whether visibly or not, as users approach likely targets by using some knowledge of the interactive layout to better approach user intent.</span></span> <span data-ttu-id="95a5e-223">這對於小型目標特別有效果。</span><span class="sxs-lookup"><span data-stu-id="95a5e-223">This can be particularly powerful for small targets.</span></span>

### <a name="focus-stickiness"></a><span data-ttu-id="95a5e-224">焦點黏著度</span><span class="sxs-lookup"><span data-stu-id="95a5e-224">Focus stickiness</span></span>
<span data-ttu-id="95a5e-225">在決定要將焦點放在哪些鄰近的互動式元素時, [焦點] 會向目前焦點的元素提供偏差。</span><span class="sxs-lookup"><span data-stu-id="95a5e-225">When determining which nearby interactive elements to give focus to, focus stickiness provides a bias to the element that is currently focused.</span></span> <span data-ttu-id="95a5e-226">這有助於減少不穩定的焦點切換行為, 而在兩個專案之間的點浮動時, 會發生自然雜訊。</span><span class="sxs-lookup"><span data-stu-id="95a5e-226">This helps reduce erratic focus switching behaviours when floating at a midpoint between two elements with natural noise.</span></span>


## <a name="composite-gestures"></a><span data-ttu-id="95a5e-227">複合手勢</span><span class="sxs-lookup"><span data-stu-id="95a5e-227">Composite gestures</span></span>

### <a name="air-tap"></a><span data-ttu-id="95a5e-228">空中點選</span><span class="sxs-lookup"><span data-stu-id="95a5e-228">Air tap</span></span>
<span data-ttu-id="95a5e-229">[空中] 手勢 (以及下面的其他手勢) 只會對特定點碰做出回應。</span><span class="sxs-lookup"><span data-stu-id="95a5e-229">The air tap gesture (as well as the other gestures below) reacts only to a specific tap.</span></span> <span data-ttu-id="95a5e-230">您的應用程式必須直接使用上述兩個主要元件手勢一節中所述的較低層級互動, 以偵測其他功能表或抓住。</span><span class="sxs-lookup"><span data-stu-id="95a5e-230">To detect other taps, such as Menu or Grasp, your application must directly use the lower-level interactions described in the two key component gestures section above.</span></span>

### <a name="tap-and-hold"></a><span data-ttu-id="95a5e-231">Tap and hold</span><span class="sxs-lookup"><span data-stu-id="95a5e-231">Tap and hold</span></span>
<span data-ttu-id="95a5e-232">按住只是維持空中點選的手指朝下位置。</span><span class="sxs-lookup"><span data-stu-id="95a5e-232">Hold is simply maintaining the downward finger position of the air tap.</span></span> <span data-ttu-id="95a5e-233">結合 [按下] 和 [按住], 可讓您在結合 arm 動作 (例如, 挑選物件, 而不是啟動它或 mousedown 次要互動, 例如顯示操作功能表) 時, 使用各種較複雜的「按一下並拖曳」互動。</span><span class="sxs-lookup"><span data-stu-id="95a5e-233">The combination of air tap and hold allows for a variety of more complex "click and drag" interactions when combined with arm movement such as picking up an object instead of activating it or mousedown secondary interactions such as showing a context menu.</span></span>
<span data-ttu-id="95a5e-234">不過，針對這個手勢進行設計時應格外小心，因為使用者很容易在任何延伸手勢的過程中放鬆其手勢。</span><span class="sxs-lookup"><span data-stu-id="95a5e-234">Caution should be used when designing for this gesture however, as users can be prone to relaxing their hand postures during the course of any extended gesture.</span></span>

### <a name="manipulation"></a><span data-ttu-id="95a5e-235">操作</span><span class="sxs-lookup"><span data-stu-id="95a5e-235">Manipulation</span></span>
<span data-ttu-id="95a5e-236">當您想要讓全像投影對使用者的移動進行1:1 回應時, 可以使用操作手勢來移動、調整大小或旋轉全息形狀。</span><span class="sxs-lookup"><span data-stu-id="95a5e-236">Manipulation gestures can be used to move, resize, or rotate a hologram when you want the hologram to react 1:1 to the user's hand movements.</span></span> <span data-ttu-id="95a5e-237">這類 1:1 移動的用途之一是要讓使用者可以實際繪圖。</span><span class="sxs-lookup"><span data-stu-id="95a5e-237">One use for such 1:1 movements is to let the user draw or paint in the world.</span></span>
<span data-ttu-id="95a5e-238">操作手勢的初始定向應經由注視或指向來完成。</span><span class="sxs-lookup"><span data-stu-id="95a5e-238">The initial targeting for a manipulation gesture should be done by gaze or pointing.</span></span> <span data-ttu-id="95a5e-239">當點一下和按住開始時, 物件的任何操作都是由手動移動處理, 讓使用者在操作時能夠四處尋找。</span><span class="sxs-lookup"><span data-stu-id="95a5e-239">Once the tap and hold starts, any manipulation of the object is handled by hand movements, freeing the user to look around while they manipulate.</span></span>

### <a name="navigation"></a><span data-ttu-id="95a5e-240">巡覽</span><span class="sxs-lookup"><span data-stu-id="95a5e-240">Navigation</span></span>
<span data-ttu-id="95a5e-241">瀏覽手勢的運作方式如同虛擬搖桿，可用來瀏覽 UI 小工具，例如放射狀功能表。</span><span class="sxs-lookup"><span data-stu-id="95a5e-241">Navigation gestures operate like a virtual joystick, and can be used to navigate UI widgets, such as radial menus.</span></span> <span data-ttu-id="95a5e-242">您可點選並按住來啟動手勢，然後在標準化 3D Cube (在初次按壓時置中) 中移動您的手。</span><span class="sxs-lookup"><span data-stu-id="95a5e-242">You tap and hold to start the gesture and then move your hand within a normalized 3D cube, centered around the initial press.</span></span> <span data-ttu-id="95a5e-243">您可以將您的手沿著 X、 Y 或 Z 軸從值 -1 移到 1 (而 0 表示起點)。</span><span class="sxs-lookup"><span data-stu-id="95a5e-243">You can move your hand along the X, Y or Z axis from a value of -1 to 1, with 0 being the starting point.</span></span>
<span data-ttu-id="95a5e-244">瀏覽可用來建置以速度為基礎的連續捲動或縮放手勢，類似於藉由按一下滑鼠中間按鈕，然後上下移動滑鼠來捲動 2D UI。</span><span class="sxs-lookup"><span data-stu-id="95a5e-244">Navigation can be used to build velocity-based continuous scrolling or zooming gestures, similar to scrolling a 2D UI by clicking the middle mouse button and then moving the mouse up and down.</span></span>

<span data-ttu-id="95a5e-245">與 rails 的導覽指的是在特定軸中辨識移動的能力, 直到達到該軸上的特定臨界值為止。</span><span class="sxs-lookup"><span data-stu-id="95a5e-245">Navigation with rails refers to the ability of recognizing movements in certain axis until a certain threshold is reached on that axis.</span></span> <span data-ttu-id="95a5e-246">這僅適用于開發人員在應用程式中啟用多個軸的移動時, 例如, 如果應用程式設定為在 X、Y 軸上辨識導覽手勢, 但也使用 rails 指定 X 軸。</span><span class="sxs-lookup"><span data-stu-id="95a5e-246">This is only useful when movement in more than one axis is enabled in an application by the developer, such as if an application is configured to recognize navigation gestures across X, Y axis but also specified X axis with rails.</span></span> <span data-ttu-id="95a5e-247">在此情況下, 如果 Y 軸上也發生手移動, 系統將會辨識 X 軸上的手上移動, 前提是它們會保留在 X 軸上的虛數滑軌 (guide) 中。</span><span class="sxs-lookup"><span data-stu-id="95a5e-247">In this case the system will recognize hand movements across X axis as long as they remain within an imaginary rails (guide) on the X axis, if hand movement also occurs on the Y axis.</span></span>

<span data-ttu-id="95a5e-248">在 2D 應用程式內，使用者可以使用垂直瀏覽手勢在應用程式內捲動、縮放或拖曳。</span><span class="sxs-lookup"><span data-stu-id="95a5e-248">Within 2D apps, users can use vertical navigation gestures to scroll, zoom, or drag inside the app.</span></span> <span data-ttu-id="95a5e-249">這會在應用程式中插入虛擬手指觸控，以模擬同類型的觸控手勢。</span><span class="sxs-lookup"><span data-stu-id="95a5e-249">This injects virtual finger touches to the app to simulate touch gestures of the same type.</span></span> <span data-ttu-id="95a5e-250">使用者可以藉由選取按鈕或說「< Scroll/拖曳/縮放 > 工具」, 在應用程式上方的工具之間切換, 藉以選取要執行的動作。</span><span class="sxs-lookup"><span data-stu-id="95a5e-250">Users can select which of these actions take place by toggling between the tools on the bar above the application, either by selecting the button or saying '<Scroll/Drag/Zoom> Tool'.</span></span>

[<span data-ttu-id="95a5e-251">複合手勢的詳細資訊</span><span class="sxs-lookup"><span data-stu-id="95a5e-251">More info on composite gestures</span></span>](gestures.md#composite-gestures)

## <a name="gesture-recognizers"></a><span data-ttu-id="95a5e-252">手勢辨識器</span><span class="sxs-lookup"><span data-stu-id="95a5e-252">Gesture recognizers</span></span>

<span data-ttu-id="95a5e-253">使用手勢辨識的其中一個優點是, 您可以只針對目前目標的全息影像可以接受的手勢設定手勢辨識器。</span><span class="sxs-lookup"><span data-stu-id="95a5e-253">One benefit of using gesture recognition is that you can configure a gesture recognizer only for the gestures the currently targeted hologram can accept.</span></span> <span data-ttu-id="95a5e-254">平臺只會視需要去除混淆, 以區別那些特定支援的手勢。</span><span class="sxs-lookup"><span data-stu-id="95a5e-254">The platform only does disambiguation as necessary to distinguish those particular supported gestures.</span></span> <span data-ttu-id="95a5e-255">如此一來, 只支援「點按」的全像投影可以接受按下和放開之間的任何時間長度, 而支援兩個點按和按住的全像投影則可以在按住時間臨界值之後, 將點擊次數提升至保留。</span><span class="sxs-lookup"><span data-stu-id="95a5e-255">In this way, a hologram that just supports air tap can accept any length of time between press and release, while a hologram that supports both tap and hold can promote the tap to a hold after the hold time threshold.</span></span>

## <a name="hand-recognition"></a><span data-ttu-id="95a5e-256">手部辨識</span><span class="sxs-lookup"><span data-stu-id="95a5e-256">Hand recognition</span></span>
<span data-ttu-id="95a5e-257">HoloLens 可藉由追蹤裝置可見的任一手或雙手位置來辨識手勢。</span><span class="sxs-lookup"><span data-stu-id="95a5e-257">HoloLens recognizes hand gestures by tracking the position of either or both hands that are visible to the device.</span></span> <span data-ttu-id="95a5e-258">當手部處於就緒狀態 (手背朝向您且食指朝上) 或按下狀態 (手背朝向您且食指朝下) 時，HoloLens 就會看見手部。</span><span class="sxs-lookup"><span data-stu-id="95a5e-258">HoloLens sees hands when they are in either the ready state (back of the hand facing you with index finger up) or the pressed state (back of the hand facing you with the index finger down).</span></span> <span data-ttu-id="95a5e-259">當手上有其他人時, HoloLens 會忽略 themz。</span><span class="sxs-lookup"><span data-stu-id="95a5e-259">When hands are in other poses, HoloLens ignore themz.</span></span>
<span data-ttu-id="95a5e-260">對於 HoloLens 偵測到的每一手勢, 您都可以存取其位置, 而不需要方向和其按下狀態。</span><span class="sxs-lookup"><span data-stu-id="95a5e-260">For each hand that HoloLens detects, you can access its position without orientation and its pressed state.</span></span> <span data-ttu-id="95a5e-261">當手部接近手勢框架邊緣時，您也會取得方向向量，而您可對使用者顯示該向量，讓他們知道如何移動其手部以回到 HoloLens 可看見手部的位置。</span><span class="sxs-lookup"><span data-stu-id="95a5e-261">As the hand nears the edge of the gesture frame, you're also provided with a direction vector, which you can show to the user so they know how to move their hand to get it back where HoloLens can see it.</span></span>

## <a name="gesture-frame"></a><span data-ttu-id="95a5e-262">手勢框架</span><span class="sxs-lookup"><span data-stu-id="95a5e-262">Gesture frame</span></span>
<span data-ttu-id="95a5e-263">對於 HoloLens 上的手勢, 手必須位於手勢框架內, 筆勢檢測攝影機可以適當地查看, 從鼻子到 waist, 以及在肩膀之間。</span><span class="sxs-lookup"><span data-stu-id="95a5e-263">For gestures on HoloLens, the hand must be within a gesture frame, in a range that the gesture-sensing cameras can see appropriately,  from nose to waist and between the shoulders.</span></span> <span data-ttu-id="95a5e-264">使用者必須在此辨識區域上訓練, 以進行動作的成功並讓自己的緩和。</span><span class="sxs-lookup"><span data-stu-id="95a5e-264">Users need to be trained on this area of recognition both for success of action and for their own comfort.</span></span> <span data-ttu-id="95a5e-265">許多使用者一開始會假設筆勢框架必須透過 HoloLens 在其觀看範圍內, 並將其 uncomfortably 以進行互動。</span><span class="sxs-lookup"><span data-stu-id="95a5e-265">Many users will initially assume that the gesture frame must be within their view through HoloLens, and hold their arms up uncomfortably in order to interact.</span></span> <span data-ttu-id="95a5e-266">使用 HoloLens Clicker 時, 不需要將手放在筆勢框架中。</span><span class="sxs-lookup"><span data-stu-id="95a5e-266">When using the HoloLens Clicker, it's not necessary for hands to be within the gesture frame.</span></span>

<span data-ttu-id="95a5e-267">特別是在連續手勢的情況下, 使用者在移動全像投影物件時, 會有一些風險會將其手移至手勢框架外, 例如, 並失去其預期的結果。</span><span class="sxs-lookup"><span data-stu-id="95a5e-267">In the case of continuous gestures in particular, there is some risk of users moving their hands outside of the gesture frame while in mid-gesture when moving a holographic object, for example, and losing their intended outcome.</span></span>

<span data-ttu-id="95a5e-268">您應該考量下列三個事項：</span><span class="sxs-lookup"><span data-stu-id="95a5e-268">There are three things that you should consider:</span></span>

- <span data-ttu-id="95a5e-269">筆勢框架的存在和大致界限的使用者教育。</span><span class="sxs-lookup"><span data-stu-id="95a5e-269">User education on the gesture frame's existence and approximate boundaries.</span></span> <span data-ttu-id="95a5e-270">這會在 HoloLens 設定期間進行講授。</span><span class="sxs-lookup"><span data-stu-id="95a5e-270">This is taught during HoloLens setup.</span></span>

- <span data-ttu-id="95a5e-271">當使用者的手勢接近或中斷應用程式內的手勢框架邊界時, 會通知他們, 而失去的手勢會導致不想要的結果。</span><span class="sxs-lookup"><span data-stu-id="95a5e-271">Notifying users when their gestures are nearing or breaking the gesture frame boundaries within an application to the degree that a lost gesture leads to undesired outcomes.</span></span> <span data-ttu-id="95a5e-272">研究已顯示這類通知系統的重要品質。</span><span class="sxs-lookup"><span data-stu-id="95a5e-272">Research has shown the key qualities of such a notification system.</span></span> <span data-ttu-id="95a5e-273">HoloLens shell 會在中央游標上提供這種類型通知的良好範例--視覺效果, 指出發生邊界相交的方向。</span><span class="sxs-lookup"><span data-stu-id="95a5e-273">The HoloLens shell provides a good example of this type of notification--visual, on the central cursor, indicating the direction in which boundary crossing is taking place.</span></span>

- <span data-ttu-id="95a5e-274">您應該將突破手勢框架界限的後果最小化。</span><span class="sxs-lookup"><span data-stu-id="95a5e-274">Consequences of breaking the gesture frame boundaries should be minimized.</span></span> <span data-ttu-id="95a5e-275">一般來說, 這表示手勢的結果應該在界限停止, 而不是反轉。</span><span class="sxs-lookup"><span data-stu-id="95a5e-275">In general, this means that the outcome of a gesture should be stopped at the boundary, and not reversed.</span></span> <span data-ttu-id="95a5e-276">例如, 如果使用者在房間內移動一些全像攝影物件, 則在軌跡框架遭到入侵時, 移動應該會停止, 而不會傳回至起點。</span><span class="sxs-lookup"><span data-stu-id="95a5e-276">For example, if a user is moving some holographic object across a room, the movement should stop when the gesture frame is breached, and not returned to the starting point.</span></span> <span data-ttu-id="95a5e-277">使用者可能會遇到一些挫折, 但可能會更快速地瞭解界限, 而不必每次都重新開機其完整的預期動作。</span><span class="sxs-lookup"><span data-stu-id="95a5e-277">The user might experience some frustration, but might more quickly understand the boundaries, and not have to restart their full intended actions each time.</span></span>


## <a name="see-also"></a><span data-ttu-id="95a5e-278">另請參閱</span><span class="sxs-lookup"><span data-stu-id="95a5e-278">See also</span></span>
* [<span data-ttu-id="95a5e-279">手部直接操作</span><span class="sxs-lookup"><span data-stu-id="95a5e-279">Direct manipulation with hands</span></span>](direct-manipulation.md)
* [<span data-ttu-id="95a5e-280">手部指向和行動</span><span class="sxs-lookup"><span data-stu-id="95a5e-280">Point and commit with hands</span></span>](point-and-commit.md)
* [<span data-ttu-id="95a5e-281">本能互動</span><span class="sxs-lookup"><span data-stu-id="95a5e-281">Instinctual interactions</span></span>](interaction-fundamentals.md)
* [<span data-ttu-id="95a5e-282">頭部目光和停駐</span><span class="sxs-lookup"><span data-stu-id="95a5e-282">Head-gaze and dwell</span></span>](gaze-and-dwell.md)
* [<span data-ttu-id="95a5e-283">語音命令</span><span class="sxs-lookup"><span data-stu-id="95a5e-283">Voice commanding</span></span>](voice-design.md)





